{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a2ed10a-10d1-4734-bbdf-1d54a99fd33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PYTHON\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pyspark\n",
    "\n",
    "#SPARK\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import *\n",
    "from operator import add\n",
    "\n",
    "import sys\n",
    "\n",
    "# Append the path to Pydoop to sys.path\n",
    "#sys.path.append(\"/usr/local/lib/python3.8/dist-packages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3096f2-39bc-4025-9c2c-a216255bdf3f",
   "metadata": {},
   "source": [
    "Spark Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fb6d6aa-4b8d-4c65-8dc1-a61c5d94018d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/14 20:31:04 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n",
      "/home/hadoop/.local/lib/python3.8/site-packages/pyspark/sql/context.py:113: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Spark Session - 2 CORE - imporvement CONFIGURATION!!\n",
    "# spark_session = SparkSession.builder\\\n",
    "#     .master(\"local[2]\")\\\n",
    "#     .appName(\"pseudo_spark_nora\")\\\n",
    "#     .getOrCreate()\n",
    "\n",
    "# Set Hadoop configuration directory\n",
    "#os.environ['HADOOP_CONF_DIR'] = '/path/to/hadoop/conf'\n",
    "#spark_session.stop()\n",
    "#os.environ['HDF5_USE_FILE_LOCKING'] = 'FALSE'\n",
    "\n",
    "spark_session = SparkSession.builder \\\n",
    "    .appName(\"HDFS_Connection_Test_nora\") \\\n",
    "    .master(\"yarn\") \\\n",
    "    .config(\"spark.executor.instances\", \"2\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# num executors \n",
    "# executor memory RAM \n",
    "\n",
    "\n",
    "# spark_session = SparkSession.builder \\\n",
    "#     .appName(\"HDFS_Connection_Test_nora\") \\\n",
    "#     .master(\"yarn\") \\\n",
    "#     .config(\"spark.executor.instances\", \"2\") \\\n",
    "#     .config(\"spark.hadoop.fs.default.name\", \"hdfs://master-node:9000\") \\\n",
    "#     .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://master-node:9000\") \\\n",
    "#     .config(\"spark.hadoop.fs.hdfs.impl\", \"org.apache.hadoop.hdfs.DistributedFileSystem\") \\\n",
    "#     .config(\"spark.hadoop.dfs.server.namenode.class\", \"org.apache.hadoop.hdfs.server.namenode.NameNode\") \\\n",
    "#     .config(\"spark.hadoop.conf\", \"org.apache.hadoop.hdfs.HdfsConfiguration\") \\\n",
    "#     .getOrCreate()\n",
    "\n",
    "#.config(\"spark.dynamicAllocation.enabled\", False)\\\n",
    "#.config(\"spark.cores.max\", 4)\\\n",
    "\n",
    "\n",
    "#.config(\"spark.jars.packages\", \"LLNL:spark-hdf5:0.0.4\") \\\n",
    "# RDD API\n",
    "spark_context = spark_session.sparkContext\n",
    "spark_context.setLogLevel(\"INFO\")\n",
    "\n",
    "sqlContext = SQLContext(spark_session.sparkContext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44667861-4446-4677-adf9-5acf17142cc4",
   "metadata": {},
   "source": [
    "File Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "85b6e7bf-1a3a-4aab-af97-04bad4192b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_roots = ['hdfs://130.238.29.183:9000//input/millionsongsubset.tar.gz']\n",
    "directory_path = \"file://data/B/A/A\"\n",
    "#directory_path = \"data_AZ\"\n",
    "#Path300\n",
    "#directory_path = \"/user/hadoop/MillionSongSubset/A/A/\"\n",
    "#directory_path = \"MillionSongSubset/A/A\"\n",
    "path = 'hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_songs/TRAAAAW128F429D538_songs.asci'\n",
    "directory_path = \"hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_songs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "04c5dac8-cb18-4e27-adfd-b1df873ce1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 21:04:42 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 358.7 KiB, free 362.9 MiB)\n",
      "24/03/14 21:04:42 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 33.1 KiB, free 362.9 MiB)\n",
      "24/03/14 21:04:42 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on master-node:35375 (size: 33.1 KiB, free: 366.0 MiB)\n",
      "24/03/14 21:04:42 INFO SparkContext: Created broadcast 84 from textFile at NativeMethodAccessorImpl.java:0\n"
     ]
    }
   ],
   "source": [
    "rdd = spark_context.textFile(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "825d4d6d-4b01-42ce-93f0-e45ae9f5f5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      {\n",
      "         22050,\n",
      "         \"a222795e07cd65b7a530f1346f520649\",\n",
      "         0,\n",
      "         218.932,\n",
      "         0.247,\n",
      "         0,\n",
      "         0,\n",
      "         0,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 21:04:44 INFO FileInputFormat: Total input files to process : 1\n",
      "24/03/14 21:04:44 INFO SparkContext: Starting job: runJob at PythonRDD.scala:181\n",
      "24/03/14 21:04:44 INFO DAGScheduler: Got job 49 (runJob at PythonRDD.scala:181) with 1 output partitions\n",
      "24/03/14 21:04:44 INFO DAGScheduler: Final stage: ResultStage 54 (runJob at PythonRDD.scala:181)\n",
      "24/03/14 21:04:44 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 21:04:44 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 21:04:44 INFO DAGScheduler: Submitting ResultStage 54 (PythonRDD[261] at RDD at PythonRDD.scala:53), which has no missing parents\n",
      "24/03/14 21:04:44 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 7.9 KiB, free 362.9 MiB)\n",
      "24/03/14 21:04:44 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 362.9 MiB)\n",
      "24/03/14 21:04:44 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on master-node:35375 (size: 4.9 KiB, free: 366.0 MiB)\n",
      "24/03/14 21:04:44 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 21:04:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (PythonRDD[261] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))\n",
      "24/03/14 21:04:44 INFO YarnScheduler: Adding task set 54.0 with 1 tasks resource profile 0\n",
      "24/03/14 21:04:44 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 60) (worker-node-1, executor 1, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 21:04:44 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on worker-node-1:45391 (size: 4.9 KiB, free: 366.1 MiB)\n",
      "24/03/14 21:04:44 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on worker-node-1:45391 (size: 33.1 KiB, free: 366.1 MiB)\n",
      "24/03/14 21:04:44 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 60) in 79 ms on worker-node-1 (executor 1) (1/1)\n",
      "24/03/14 21:04:44 INFO YarnScheduler: Removed TaskSet 54.0, whose tasks have all completed, from pool \n",
      "24/03/14 21:04:44 INFO DAGScheduler: ResultStage 54 (runJob at PythonRDD.scala:181) finished in 0.092 s\n",
      "24/03/14 21:04:44 INFO DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 21:04:44 INFO YarnScheduler: Killing all running tasks in stage 54: Stage finished\n",
      "24/03/14 21:04:44 INFO DAGScheduler: Job 49 finished: runJob at PythonRDD.scala:181, took 0.098351 s\n"
     ]
    }
   ],
   "source": [
    "for line in rdd.take(10):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aad3b0e0-6f8f-42e9-84bb-7377131b53d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 21:19:14 INFO SparkContext: Starting job: collect at /tmp/ipykernel_112987/1208031561.py:1\n",
      "24/03/14 21:19:14 INFO DAGScheduler: Got job 62 (collect at /tmp/ipykernel_112987/1208031561.py:1) with 2 output partitions\n",
      "24/03/14 21:19:14 INFO DAGScheduler: Final stage: ResultStage 67 (collect at /tmp/ipykernel_112987/1208031561.py:1)\n",
      "24/03/14 21:19:14 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 21:19:14 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 21:19:14 INFO DAGScheduler: Submitting ResultStage 67 (PythonRDD[299] at collect at /tmp/ipykernel_112987/1208031561.py:1), which has no missing parents\n",
      "24/03/14 21:19:14 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 7.7 KiB, free 362.6 MiB)\n",
      "24/03/14 21:19:14 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 362.6 MiB)\n",
      "24/03/14 21:19:14 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on master-node:35375 (size: 4.8 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:19:14 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 21:19:14 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 67 (PythonRDD[299] at collect at /tmp/ipykernel_112987/1208031561.py:1) (first 15 tasks are for partitions Vector(0, 1))\n",
      "24/03/14 21:19:14 INFO YarnScheduler: Adding task set 67.0 with 2 tasks resource profile 0\n",
      "24/03/14 21:19:14 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 75) (worker-node-1, executor 1, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 21:19:14 INFO TaskSetManager: Starting task 1.0 in stage 67.0 (TID 76) (worker-node-2, executor 2, partition 1, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 21:19:14 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on worker-node-1:45391 (size: 4.8 KiB, free: 366.0 MiB)\n",
      "24/03/14 21:19:14 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on worker-node-2:39037 (size: 4.8 KiB, free: 366.0 MiB)\n",
      "24/03/14 21:19:14 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 75) in 50 ms on worker-node-1 (executor 1) (1/2)\n",
      "24/03/14 21:19:14 INFO TaskSetManager: Finished task 1.0 in stage 67.0 (TID 76) in 60 ms on worker-node-2 (executor 2) (2/2)\n",
      "24/03/14 21:19:14 INFO YarnScheduler: Removed TaskSet 67.0, whose tasks have all completed, from pool \n",
      "24/03/14 21:19:14 INFO DAGScheduler: ResultStage 67 (collect at /tmp/ipykernel_112987/1208031561.py:1) finished in 0.071 s\n",
      "24/03/14 21:19:14 INFO DAGScheduler: Job 62 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 21:19:14 INFO YarnScheduler: Killing all running tasks in stage 67: Stage finished\n",
      "24/03/14 21:19:14 INFO DAGScheduler: Job 62 finished: collect at /tmp/ipykernel_112987/1208031561.py:1, took 0.073764 s\n"
     ]
    }
   ],
   "source": [
    "content = rdd.map(lambda line: line.replace('\\n', '').replace(' ', '').replace(',', '')).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4475281c-d3b5-444b-9419-3ecf4b5f7765",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = content[4:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "172756f5-530d-47f4-8791-0da60ce26b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+\n",
      "|column1|column2|column3|column4|column5|\n",
      "+-------+-------+-------+-------+-------+\n",
      "|218.932|  0.247|-11.197|218.932| 92.198|\n",
      "+-------+-------+-------+-------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 21:19:17 INFO SparkContext: Starting job: showString at <unknown>:0\n",
      "24/03/14 21:19:17 INFO DAGScheduler: Got job 63 (showString at <unknown>:0) with 1 output partitions\n",
      "24/03/14 21:19:17 INFO DAGScheduler: Final stage: ResultStage 68 (showString at <unknown>:0)\n",
      "24/03/14 21:19:17 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 21:19:17 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 21:19:17 INFO DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[306] at showString at <unknown>:0), which has no missing parents\n",
      "24/03/14 21:19:17 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 13.6 KiB, free 362.6 MiB)\n",
      "24/03/14 21:19:17 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 362.6 MiB)\n",
      "24/03/14 21:19:17 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on master-node:35375 (size: 6.7 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:19:17 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 21:19:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 68 (MapPartitionsRDD[306] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/03/14 21:19:17 INFO YarnScheduler: Adding task set 68.0 with 1 tasks resource profile 0\n",
      "24/03/14 21:19:17 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 77) (worker-node-2, executor 2, partition 0, PROCESS_LOCAL, 7606 bytes) \n",
      "24/03/14 21:19:17 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on worker-node-2:39037 (size: 6.7 KiB, free: 366.0 MiB)\n",
      "24/03/14 21:19:17 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 77) in 37 ms on worker-node-2 (executor 2) (1/1)\n",
      "24/03/14 21:19:17 INFO YarnScheduler: Removed TaskSet 68.0, whose tasks have all completed, from pool \n",
      "24/03/14 21:19:17 INFO DAGScheduler: ResultStage 68 (showString at <unknown>:0) finished in 0.047 s\n",
      "24/03/14 21:19:17 INFO DAGScheduler: Job 63 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 21:19:17 INFO YarnScheduler: Killing all running tasks in stage 68: Stage finished\n",
      "24/03/14 21:19:17 INFO DAGScheduler: Job 63 finished: showString at <unknown>:0, took 0.050733 s\n",
      "24/03/14 21:19:17 INFO SparkContext: Starting job: showString at <unknown>:0\n",
      "24/03/14 21:19:17 INFO DAGScheduler: Got job 64 (showString at <unknown>:0) with 1 output partitions\n",
      "24/03/14 21:19:17 INFO DAGScheduler: Final stage: ResultStage 69 (showString at <unknown>:0)\n",
      "24/03/14 21:19:17 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 21:19:17 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 21:19:17 INFO DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[306] at showString at <unknown>:0), which has no missing parents\n",
      "24/03/14 21:19:17 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 13.6 KiB, free 362.6 MiB)\n",
      "24/03/14 21:19:17 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 362.6 MiB)\n",
      "24/03/14 21:19:17 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on master-node:35375 (size: 6.8 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:19:17 INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 21:19:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[306] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(1))\n",
      "24/03/14 21:19:17 INFO YarnScheduler: Adding task set 69.0 with 1 tasks resource profile 0\n",
      "24/03/14 21:19:17 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 78) (worker-node-1, executor 1, partition 1, PROCESS_LOCAL, 7681 bytes) \n",
      "24/03/14 21:19:17 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on worker-node-1:45391 (size: 6.8 KiB, free: 366.0 MiB)\n",
      "24/03/14 21:19:17 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 78) in 37 ms on worker-node-1 (executor 1) (1/1)\n",
      "24/03/14 21:19:17 INFO YarnScheduler: Removed TaskSet 69.0, whose tasks have all completed, from pool \n",
      "24/03/14 21:19:17 INFO DAGScheduler: ResultStage 69 (showString at <unknown>:0) finished in 0.053 s\n",
      "24/03/14 21:19:17 INFO DAGScheduler: Job 64 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 21:19:17 INFO YarnScheduler: Killing all running tasks in stage 69: Stage finished\n",
      "24/03/14 21:19:17 INFO DAGScheduler: Job 64 finished: showString at <unknown>:0, took 0.062943 s\n"
     ]
    }
   ],
   "source": [
    "rows = [Row(column1=data[5], column2=data[6], column3=data[25], column4=data[28], column5=data[29]) for data in [content]]\n",
    "\n",
    "# Create DataFrame schema\n",
    "schema = sqlContext.createDataFrame(rows)\n",
    "\n",
    "# Register the DataFrame as a table\n",
    "schema.registerTempTable(\"data_table\")\n",
    "\n",
    "# You can now perform SQL operations on the data\n",
    "result = sqlContext.sql(\"SELECT * FROM data_table\")\n",
    "\n",
    "# Show the result\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7de33fa-a46b-45c4-800e-25bd1f117669",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned_rdd = rdd.map(lambda line: line.strip().replace('{', '').replace('}', '').split(','))\n",
    "cleaned_rdd = rdd.map(lambda line: [value.strip('\"').strip() for value in line.strip().replace('{', '').replace('}', '').split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c53d44f-27ad-491b-a4e0-832ed0874e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['']\n",
      "['']\n",
      "['22050', '']\n",
      "['a222795e07cd65b7a530f1346f520649', '']\n",
      "['0', '']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 20:41:39 INFO SparkContext: Starting job: runJob at PythonRDD.scala:181\n",
      "24/03/14 20:41:39 INFO DAGScheduler: Got job 9 (runJob at PythonRDD.scala:181) with 1 output partitions\n",
      "24/03/14 20:41:39 INFO DAGScheduler: Final stage: ResultStage 9 (runJob at PythonRDD.scala:181)\n",
      "24/03/14 20:41:39 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 20:41:39 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 20:41:39 INFO DAGScheduler: Submitting ResultStage 9 (PythonRDD[13] at RDD at PythonRDD.scala:53), which has no missing parents\n",
      "24/03/14 20:41:39 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 8.7 KiB, free 365.4 MiB)\n",
      "24/03/14 20:41:39 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 365.4 MiB)\n",
      "24/03/14 20:41:39 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on master-node:35375 (size: 5.4 KiB, free: 366.2 MiB)\n",
      "24/03/14 20:41:39 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 20:41:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (PythonRDD[13] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))\n",
      "24/03/14 20:41:39 INFO YarnScheduler: Adding task set 9.0 with 1 tasks resource profile 0\n",
      "24/03/14 20:41:39 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9) (worker-node-1, executor 1, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 20:41:39 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on worker-node-1:45391 (size: 5.4 KiB, free: 366.2 MiB)\n",
      "24/03/14 20:41:39 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 71 ms on worker-node-1 (executor 1) (1/1)\n",
      "24/03/14 20:41:39 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool \n",
      "24/03/14 20:41:39 INFO DAGScheduler: ResultStage 9 (runJob at PythonRDD.scala:181) finished in 0.083 s\n",
      "24/03/14 20:41:39 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 20:41:39 INFO YarnScheduler: Killing all running tasks in stage 9: Stage finished\n",
      "24/03/14 20:41:39 INFO DAGScheduler: Job 9 finished: runJob at PythonRDD.scala:181, took 0.087531 s\n"
     ]
    }
   ],
   "source": [
    "for line in cleaned_rdd.take(5):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4829a5f7-d4b2-4613-be18-512c6d7a43e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 20:44:30 INFO SparkContext: Starting job: runJob at PythonRDD.scala:181\n",
      "24/03/14 20:44:30 INFO DAGScheduler: Got job 11 (runJob at PythonRDD.scala:181) with 1 output partitions\n",
      "24/03/14 20:44:30 INFO DAGScheduler: Final stage: ResultStage 11 (runJob at PythonRDD.scala:181)\n",
      "24/03/14 20:44:30 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 20:44:30 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 20:44:30 INFO DAGScheduler: Submitting ResultStage 11 (PythonRDD[19] at RDD at PythonRDD.scala:53), which has no missing parents\n",
      "24/03/14 20:44:30 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 9.2 KiB, free 365.5 MiB)\n",
      "24/03/14 20:44:30 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 365.5 MiB)\n",
      "24/03/14 20:44:30 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on master-node:35375 (size: 5.6 KiB, free: 366.2 MiB)\n",
      "24/03/14 20:44:30 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 20:44:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (PythonRDD[19] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))\n",
      "24/03/14 20:44:30 INFO YarnScheduler: Adding task set 11.0 with 1 tasks resource profile 0\n",
      "24/03/14 20:44:30 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11) (worker-node-1, executor 1, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 20:44:30 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on worker-node-1:45391 (size: 5.6 KiB, free: 366.3 MiB)\n",
      "24/03/14 20:44:30 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 87 ms on worker-node-1 (executor 1) (1/1)\n",
      "24/03/14 20:44:30 INFO YarnScheduler: Removed TaskSet 11.0, whose tasks have all completed, from pool \n",
      "24/03/14 20:44:30 INFO DAGScheduler: ResultStage 11 (runJob at PythonRDD.scala:181) finished in 0.103 s\n",
      "24/03/14 20:44:30 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 20:44:30 INFO YarnScheduler: Killing all running tasks in stage 11: Stage finished\n",
      "24/03/14 20:44:30 INFO DAGScheduler: Job 11 finished: runJob at PythonRDD.scala:181, took 0.110546 s\n"
     ]
    }
   ],
   "source": [
    "df = cleaned_rdd.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "929552bd-5815-4006-be61-7048a50a8482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 20:44:36 INFO BlockManagerInfo: Removed broadcast_13_piece0 on master-node:35375 in memory (size: 5.6 KiB, free: 366.2 MiB)\n",
      "24/03/14 20:44:36 INFO BlockManagerInfo: Removed broadcast_13_piece0 on worker-node-1:45391 in memory (size: 5.6 KiB, free: 366.3 MiB)\n",
      "24/03/14 20:44:36 INFO CodeGenerator: Code generated in 313.163821 ms\n",
      "24/03/14 20:44:36 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "24/03/14 20:44:36 INFO DAGScheduler: Got job 12 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/03/14 20:44:36 INFO DAGScheduler: Final stage: ResultStage 12 (showString at NativeMethodAccessorImpl.java:0)\n",
      "24/03/14 20:44:36 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 20:44:36 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 20:44:36 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[25] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/03/14 20:44:36 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 16.6 KiB, free 365.5 MiB)\n",
      "24/03/14 20:44:36 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 8.9 KiB, free 365.5 MiB)\n",
      "24/03/14 20:44:36 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on master-node:35375 (size: 8.9 KiB, free: 366.2 MiB)\n",
      "24/03/14 20:44:36 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 20:44:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[25] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/03/14 20:44:36 INFO YarnScheduler: Adding task set 12.0 with 1 tasks resource profile 0\n",
      "24/03/14 20:44:36 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12) (worker-node-1, executor 1, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 20:44:37 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on worker-node-1:45391 (size: 8.9 KiB, free: 366.3 MiB)\n",
      "24/03/14 20:44:37 WARN TaskSetManager: Lost task 0.0 in stage 12.0 (TID 12) (worker-node-1 executor 1): java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "24/03/14 20:44:37 INFO TaskSetManager: Starting task 0.1 in stage 12.0 (TID 13) (worker-node-1, executor 1, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 20:44:37 INFO TaskSetManager: Lost task 0.1 in stage 12.0 (TID 13) on worker-node-1, executor 1: java.lang.IllegalStateException (Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.) [duplicate 1]\n",
      "24/03/14 20:44:37 INFO TaskSetManager: Starting task 0.2 in stage 12.0 (TID 14) (worker-node-2, executor 2, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 20:44:37 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on worker-node-2:39037 (size: 8.9 KiB, free: 366.2 MiB)\n",
      "24/03/14 20:44:38 INFO TaskSetManager: Lost task 0.2 in stage 12.0 (TID 14) on worker-node-2, executor 2: java.lang.IllegalStateException (Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.) [duplicate 2]\n",
      "24/03/14 20:44:38 INFO TaskSetManager: Starting task 0.3 in stage 12.0 (TID 15) (worker-node-2, executor 2, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 20:44:38 INFO TaskSetManager: Lost task 0.3 in stage 12.0 (TID 15) on worker-node-2, executor 2: java.lang.IllegalStateException (Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.) [duplicate 3]\n",
      "24/03/14 20:44:38 ERROR TaskSetManager: Task 0 in stage 12.0 failed 4 times; aborting job\n",
      "24/03/14 20:44:38 INFO YarnScheduler: Removed TaskSet 12.0, whose tasks have all completed, from pool \n",
      "24/03/14 20:44:38 INFO YarnScheduler: Cancelling stage 12\n",
      "24/03/14 20:44:38 INFO YarnScheduler: Killing all running tasks in stage 12: Stage cancelled: Job aborted due to stage failure: Task 0 in stage 12.0 failed 4 times, most recent failure: Lost task 0.3 in stage 12.0 (TID 15) (worker-node-2 executor 2): java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "Driver stacktrace:\n",
      "24/03/14 20:44:38 INFO DAGScheduler: ResultStage 12 (showString at NativeMethodAccessorImpl.java:0) failed in 1.635 s due to Job aborted due to stage failure: Task 0 in stage 12.0 failed 4 times, most recent failure: Lost task 0.3 in stage 12.0 (TID 15) (worker-node-2 executor 2): java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "Driver stacktrace:\n",
      "24/03/14 20:44:38 INFO DAGScheduler: Job 12 failed: showString at NativeMethodAccessorImpl.java:0, took 1.651048 s\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o227.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 12.0 failed 4 times, most recent failure: Lost task 0.3 in stage 12.0 (TID 15) (worker-node-2 executor 2): java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4332)\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3314)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4322)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4320)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4320)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:3314)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:3537)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:280)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:315)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/dataframe.py:945\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow\u001b[39m(\u001b[38;5;28mself\u001b[39m, n: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, truncate: Union[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, vertical: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    886\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prints the first ``n`` rows to the console.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \n\u001b[1;32m    888\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;124;03m    name | Bob\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 945\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/dataframe.py:963\u001b[0m, in \u001b[0;36mDataFrame._show_string\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m    958\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    959\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(vertical)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m    960\u001b[0m     )\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[0;32m--> 963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o227.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 12.0 failed 4 times, most recent failure: Lost task 0.3 in stage 12.0 (TID 15) (worker-node-2 executor 2): java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4332)\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3314)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4322)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4320)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4320)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:3314)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:3537)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:280)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:315)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "085e0a1d-67a6-4f85-87be-cfddb05a6d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "536af008-1c77-4250-bad6-5ab2e37426e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 20:38:04 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 358.3 KiB, free 365.6 MiB)\n",
      "24/03/14 20:38:04 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 365.5 MiB)\n",
      "24/03/14 20:38:04 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on master-node:35375 (size: 32.9 KiB, free: 366.2 MiB)\n",
      "24/03/14 20:38:04 INFO SparkContext: Created broadcast 4 from textFile at NativeMethodAccessorImpl.java:0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'PipelinedRDD' object has no attribute '_jdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Wende den Tokenizer auf jede Zeile an\u001b[39;00m\n\u001b[1;32m      4\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m Tokenizer(inputCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, outputCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwords\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m tokenized_rdd \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Zeige die ersten 10 Zeilen des tokenisierten RDDs an\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m tokenized_rdd\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m10\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/ml/base.py:262\u001b[0m, in \u001b[0;36mTransformer.transform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_transform(dataset)\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be a param map but got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/ml/wrapper.py:398\u001b[0m, in \u001b[0;36mJavaTransformer._transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[0;32m--> 398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj\u001b[38;5;241m.\u001b[39mtransform(\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m), dataset\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PipelinedRDD' object has no attribute '_jdf'"
     ]
    }
   ],
   "source": [
    "rdd = spark_context.textFile(path)\n",
    "\n",
    "# Wende den Tokenizer auf jede Zeile an\n",
    "tokenizer = Tokenizer(inputCol=\"value\", outputCol=\"words\")\n",
    "tokenized_rdd = tokenizer.transform(rdd.map(lambda line: (line, )))\n",
    "\n",
    "# Zeige die ersten 10 Zeilen des tokenisierten RDDs an\n",
    "for row in tokenized_rdd.take(10):\n",
    "    print(row.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f233087a-eec3-404f-8216-54160ee67374",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_songs/TRAAAAW128F429D538_songs.asci'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m values \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Datei ffnen und Zeilen lesen\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m file:\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;66;03m# Entferne fhrende und abschlieende Leerzeichen und Zeilenumbrche\u001b[39;00m\n\u001b[1;32m      7\u001b[0m         line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_songs/TRAAAAW128F429D538_songs.asci'"
     ]
    }
   ],
   "source": [
    "values = []\n",
    "\n",
    "# Datei ffnen und Zeilen lesen\n",
    "with open(path, 'r') as file:\n",
    "    for line in file:\n",
    "        # Entferne fhrende und abschlieende Leerzeichen und Zeilenumbrche\n",
    "        line = line.strip()\n",
    "        # Entferne die geschweiften Klammern\n",
    "        line = line.replace('{', '').replace('}', '')\n",
    "        # Teile die Zeile an Kommas und fge die Werte zur Liste hinzu\n",
    "        values.extend(line.split(','))\n",
    "\n",
    "# Erstelle eine Zeile mit den Werten, getrennt durch Kommas\n",
    "csv_line = ','.join(values)\n",
    "\n",
    "# Zeige die CSV-Zeile an\n",
    "print(csv_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2412345-7bee-4b11-902e-ada12dac4097",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"my_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cc91ea5-ffb4-48c1-bebb-d3fc50fd6b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 19:39:34 INFO FileSourceStrategy: Pushed Filters: \n",
      "24/03/14 19:39:34 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "24/03/14 19:39:34 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 353.4 KiB, free 364.3 MiB)\n",
      "24/03/14 19:39:34 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 35.5 KiB, free 364.3 MiB)\n",
      "24/03/14 19:39:34 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on master-node:33151 (size: 35.5 KiB, free: 366.1 MiB)\n",
      "24/03/14 19:39:34 INFO SparkContext: Created broadcast 9 from showString at NativeMethodAccessorImpl.java:0\n",
      "24/03/14 19:39:34 INFO BlockManagerInfo: Removed broadcast_7_piece0 on master-node:33151 in memory (size: 35.7 KiB, free: 366.1 MiB)\n",
      "24/03/14 19:39:34 INFO BlockManagerInfo: Removed broadcast_7_piece0 on worker-node-2:34115 in memory (size: 35.7 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:39:34 INFO BlockManagerInfo: Removed broadcast_7_piece0 on worker-node-1:44403 in memory (size: 35.7 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:39:34 INFO BlockManagerInfo: Removed broadcast_5_piece0 on worker-node-1:44403 in memory (size: 7.1 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:39:34 INFO BlockManagerInfo: Removed broadcast_5_piece0 on worker-node-2:34115 in memory (size: 7.1 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:39:34 INFO BlockManagerInfo: Removed broadcast_5_piece0 on master-node:33151 in memory (size: 7.1 KiB, free: 366.1 MiB)\n",
      "24/03/14 19:39:34 INFO BlockManagerInfo: Removed broadcast_8_piece0 on worker-node-1:44403 in memory (size: 8.1 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:39:34 INFO BlockManagerInfo: Removed broadcast_8_piece0 on worker-node-2:34115 in memory (size: 8.1 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:39:34 INFO BlockManagerInfo: Removed broadcast_8_piece0 on master-node:33151 in memory (size: 8.1 KiB, free: 366.1 MiB)\n",
      "24/03/14 19:39:34 INFO BlockManagerInfo: Removed broadcast_0_piece0 on worker-node-2:34115 in memory (size: 35.7 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:39:34 INFO BlockManagerInfo: Removed broadcast_0_piece0 on master-node:33151 in memory (size: 35.7 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:39:34 INFO BlockManagerInfo: Removed broadcast_1_piece0 on worker-node-2:34115 in memory (size: 6.4 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:39:34 INFO BlockManagerInfo: Removed broadcast_1_piece0 on master-node:33151 in memory (size: 6.4 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:39:34 INFO BlockManagerInfo: Removed broadcast_6_piece0 on worker-node-1:44403 in memory (size: 8.9 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:39:34 INFO BlockManagerInfo: Removed broadcast_6_piece0 on master-node:33151 in memory (size: 8.9 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:39:34 INFO BlockManagerInfo: Removed broadcast_3_piece0 on master-node:33151 in memory (size: 13.1 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:39:34 INFO BlockManagerInfo: Removed broadcast_3_piece0 on worker-node-1:44403 in memory (size: 13.1 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:39:34 INFO BlockManagerInfo: Removed broadcast_3_piece0 on worker-node-2:34115 in memory (size: 13.1 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:39:34 INFO BlockManagerInfo: Removed broadcast_2_piece0 on worker-node-2:34115 in memory (size: 35.7 KiB, free: 366.3 MiB)\n",
      "24/03/14 19:39:34 INFO BlockManagerInfo: Removed broadcast_2_piece0 on worker-node-1:44403 in memory (size: 35.7 KiB, free: 366.3 MiB)\n",
      "24/03/14 19:39:34 INFO BlockManagerInfo: Removed broadcast_2_piece0 on master-node:33151 in memory (size: 35.7 KiB, free: 366.2 MiB)\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "Since Spark 2.3, the queries from raw JSON/CSV files are disallowed when the\nreferenced columns only include the internal corrupt record column\n(named _corrupt_record by default). For example:\nspark.read.schema(schema).csv(file).filter($\"_corrupt_record\".isNotNull).count()\nand spark.read.schema(schema).csv(file).select(\"_corrupt_record\").show().\nInstead, you can cache or save the parsed results and then send the same query.\nFor example, val df = spark.read.schema(schema).csv(file).cache() and then\ndf.filter($\"_corrupt_record\".isNotNull).count().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msqlContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSELECT * FROM my_table\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/dataframe.py:945\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow\u001b[39m(\u001b[38;5;28mself\u001b[39m, n: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, truncate: Union[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, vertical: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    886\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prints the first ``n`` rows to the console.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \n\u001b[1;32m    888\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;124;03m    name | Bob\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 945\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/dataframe.py:963\u001b[0m, in \u001b[0;36mDataFrame._show_string\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m    958\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    959\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(vertical)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m    960\u001b[0m     )\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[0;32m--> 963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Since Spark 2.3, the queries from raw JSON/CSV files are disallowed when the\nreferenced columns only include the internal corrupt record column\n(named _corrupt_record by default). For example:\nspark.read.schema(schema).csv(file).filter($\"_corrupt_record\".isNotNull).count()\nand spark.read.schema(schema).csv(file).select(\"_corrupt_record\").show().\nInstead, you can cache or save the parsed results and then send the same query.\nFor example, val df = spark.read.schema(schema).csv(file).cache() and then\ndf.filter($\"_corrupt_record\".isNotNull).count()."
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"SELECT * FROM my_table\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "60fff22c-0e27-410e-a472-1690206a2e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "columns = [\"column_{}\".format(i) for i in range(1, 31 + 1)]  # Hier musst du die Anzahl der Spalten angeben\n",
    "\n",
    "# Erstelle ein StructType-Schema fr den DataFrame\n",
    "schema = StructType([StructField(col, StringType(), True) for col in columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ffec5336-6e2d-4aa1-8081-696c9a585a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 20:54:46 INFO InMemoryFileIndex: It took 11 ms to list leaf files for 1 paths.\n",
      "24/03/14 20:54:46 INFO InMemoryFileIndex: It took 12 ms to list leaf files for 11 paths.\n",
      "24/03/14 20:54:46 INFO FileSourceStrategy: Pushed Filters: \n",
      "24/03/14 20:54:46 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#690, None)) > 0)\n",
      "24/03/14 20:54:46 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 353.8 KiB, free 362.9 MiB)\n",
      "24/03/14 20:54:46 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 35.7 KiB, free 362.8 MiB)\n",
      "24/03/14 20:54:46 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on master-node:35375 (size: 35.7 KiB, free: 366.0 MiB)\n",
      "24/03/14 20:54:46 INFO SparkContext: Created broadcast 72 from csv at NativeMethodAccessorImpl.java:0\n",
      "24/03/14 20:54:46 INFO FileSourceScanExec: Planning scan with bin packing, max size: 23071304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "24/03/14 20:54:46 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0\n",
      "24/03/14 20:54:46 INFO DAGScheduler: Got job 44 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/03/14 20:54:46 INFO DAGScheduler: Final stage: ResultStage 49 (csv at NativeMethodAccessorImpl.java:0)\n",
      "24/03/14 20:54:46 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 20:54:46 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 20:54:46 INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[228] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/03/14 20:54:46 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 13.5 KiB, free 362.8 MiB)\n",
      "24/03/14 20:54:46 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 362.8 MiB)\n",
      "24/03/14 20:54:46 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on master-node:35375 (size: 6.4 KiB, free: 366.0 MiB)\n",
      "24/03/14 20:54:46 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 20:54:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[228] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/03/14 20:54:46 INFO YarnScheduler: Adding task set 49.0 with 1 tasks resource profile 0\n",
      "24/03/14 20:54:46 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 54) (worker-node-1, executor 1, partition 0, NODE_LOCAL, 9092 bytes) \n",
      "24/03/14 20:54:46 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on worker-node-1:45391 (size: 6.4 KiB, free: 366.1 MiB)\n",
      "24/03/14 20:54:46 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on worker-node-1:45391 (size: 35.7 KiB, free: 366.1 MiB)\n",
      "24/03/14 20:54:46 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 54) in 75 ms on worker-node-1 (executor 1) (1/1)\n",
      "24/03/14 20:54:46 INFO YarnScheduler: Removed TaskSet 49.0, whose tasks have all completed, from pool \n",
      "24/03/14 20:54:46 INFO DAGScheduler: ResultStage 49 (csv at NativeMethodAccessorImpl.java:0) finished in 0.083 s\n",
      "24/03/14 20:54:46 INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 20:54:46 INFO YarnScheduler: Killing all running tasks in stage 49: Stage finished\n",
      "24/03/14 20:54:46 INFO DAGScheduler: Job 44 finished: csv at NativeMethodAccessorImpl.java:0, took 0.087155 s\n",
      "24/03/14 20:54:46 INFO FileSourceStrategy: Pushed Filters: \n",
      "24/03/14 20:54:46 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "24/03/14 20:54:46 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 353.8 KiB, free 362.5 MiB)\n",
      "24/03/14 20:54:46 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 35.7 KiB, free 362.4 MiB)\n",
      "24/03/14 20:54:46 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on master-node:35375 (size: 35.7 KiB, free: 365.9 MiB)\n",
      "24/03/14 20:54:46 INFO SparkContext: Created broadcast 74 from csv at NativeMethodAccessorImpl.java:0\n",
      "24/03/14 20:54:46 INFO FileSourceScanExec: Planning scan with bin packing, max size: 23071304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "24/03/14 20:54:46 WARN CacheManager: Asked to cache already cached data.\n",
      "24/03/14 20:54:47 INFO InMemoryFileIndex: It took 11 ms to list leaf files for 1 paths.\n",
      "24/03/14 20:54:47 INFO InMemoryFileIndex: It took 14 ms to list leaf files for 11 paths.\n",
      "24/03/14 20:54:47 INFO FileSourceStrategy: Pushed Filters: \n",
      "24/03/14 20:54:47 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#709, None)) > 0)\n",
      "24/03/14 20:54:47 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 353.5 KiB, free 362.1 MiB)\n",
      "24/03/14 20:54:47 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 35.7 KiB, free 362.0 MiB)\n",
      "24/03/14 20:54:47 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on master-node:35375 (size: 35.7 KiB, free: 365.9 MiB)\n",
      "24/03/14 20:54:47 INFO SparkContext: Created broadcast 75 from csv at NativeMethodAccessorImpl.java:0\n",
      "24/03/14 20:54:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 23071304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "24/03/14 20:54:47 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0\n",
      "24/03/14 20:54:47 INFO DAGScheduler: Got job 45 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/03/14 20:54:47 INFO DAGScheduler: Final stage: ResultStage 50 (csv at NativeMethodAccessorImpl.java:0)\n",
      "24/03/14 20:54:47 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 20:54:47 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 20:54:47 INFO DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[238] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/03/14 20:54:47 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 13.5 KiB, free 362.0 MiB)\n",
      "24/03/14 20:54:47 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 362.0 MiB)\n",
      "24/03/14 20:54:47 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on master-node:35375 (size: 6.4 KiB, free: 365.9 MiB)\n",
      "24/03/14 20:54:47 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 20:54:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[238] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/03/14 20:54:47 INFO YarnScheduler: Adding task set 50.0 with 1 tasks resource profile 0\n",
      "24/03/14 20:54:47 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 55) (worker-node-1, executor 1, partition 0, NODE_LOCAL, 9092 bytes) \n",
      "24/03/14 20:54:47 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on worker-node-1:45391 (size: 6.4 KiB, free: 366.1 MiB)\n",
      "24/03/14 20:54:47 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on worker-node-1:45391 (size: 35.7 KiB, free: 366.1 MiB)\n",
      "24/03/14 20:54:47 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 55) in 48 ms on worker-node-1 (executor 1) (1/1)\n",
      "24/03/14 20:54:47 INFO YarnScheduler: Removed TaskSet 50.0, whose tasks have all completed, from pool \n",
      "24/03/14 20:54:47 INFO DAGScheduler: ResultStage 50 (csv at NativeMethodAccessorImpl.java:0) finished in 0.057 s\n",
      "24/03/14 20:54:47 INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 20:54:47 INFO YarnScheduler: Killing all running tasks in stage 50: Stage finished\n",
      "24/03/14 20:54:47 INFO DAGScheduler: Job 45 finished: csv at NativeMethodAccessorImpl.java:0, took 0.064615 s\n",
      "24/03/14 20:54:47 INFO FileSourceStrategy: Pushed Filters: \n",
      "24/03/14 20:54:47 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "24/03/14 20:54:47 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 353.5 KiB, free 361.7 MiB)\n",
      "24/03/14 20:54:47 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 35.7 KiB, free 361.6 MiB)\n",
      "24/03/14 20:54:47 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on master-node:35375 (size: 35.7 KiB, free: 365.9 MiB)\n",
      "24/03/14 20:54:47 INFO SparkContext: Created broadcast 77 from csv at NativeMethodAccessorImpl.java:0\n",
      "24/03/14 20:54:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 23071304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "24/03/14 20:54:47 INFO FileSourceStrategy: Pushed Filters: \n",
      "24/03/14 20:54:47 INFO FileSourceStrategy: Post-Scan Filters: \n"
     ]
    }
   ],
   "source": [
    "# read the csv from hdfs\n",
    "#df = sqlContext.read.csv(directory_path, header=False, delimiter=,, inferSchema=True).cache()\n",
    "#df = sqlContext.read.csv(\"hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI/\", header=True, inferSchema=True).cache()\n",
    "#path = 'hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_songs/TRAAAAW128F429D538_songs.asci'\n",
    "path = 'hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_songs'\n",
    "df = sqlContext.read.option(\"delimiter\", \",\").csv(path).cache()\n",
    "df = sqlContext.read.csv(path).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6550b880-68dc-47a5-9988-7a7929982f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 20:54:49 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 353.4 KiB, free 361.3 MiB)\n",
      "24/03/14 20:54:49 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 35.5 KiB, free 361.3 MiB)\n",
      "24/03/14 20:54:49 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on master-node:35375 (size: 35.5 KiB, free: 365.8 MiB)\n",
      "24/03/14 20:54:49 INFO SparkContext: Created broadcast 78 from showString at NativeMethodAccessorImpl.java:0\n",
      "24/03/14 20:54:49 INFO FileSourceScanExec: Planning scan with bin packing, max size: 23071304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "24/03/14 20:54:49 INFO DAGScheduler: Got job 46 (showString at NativeMethodAccessorImpl.java:0) with 2 output partitions\n",
      "24/03/14 20:54:49 INFO DAGScheduler: Final stage: ResultStage 51 (showString at NativeMethodAccessorImpl.java:0)\n",
      "24/03/14 20:54:49 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 20:54:49 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 20:54:49 INFO DAGScheduler: Submitting ResultStage 51 (FileScan csv [_c0#726] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_so..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<_c0:string>\n",
      " MapPartitionsRDD[248] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/03/14 20:54:49 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 13.7 KiB, free 361.3 MiB)\n",
      "24/03/14 20:54:49 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 361.2 MiB)\n",
      "24/03/14 20:54:49 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on master-node:35375 (size: 7.1 KiB, free: 365.8 MiB)\n",
      "24/03/14 20:54:49 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 20:54:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 51 (FileScan csv [_c0#726] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_so..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<_c0:string>\n",
      " MapPartitionsRDD[248] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))\n",
      "24/03/14 20:54:49 INFO YarnScheduler: Adding task set 51.0 with 2 tasks resource profile 0\n",
      "24/03/14 20:54:49 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 56) (worker-node-2, executor 2, partition 0, NODE_LOCAL, 9092 bytes) \n",
      "24/03/14 20:54:49 INFO TaskSetManager: Starting task 1.0 in stage 51.0 (TID 57) (worker-node-1, executor 1, partition 1, NODE_LOCAL, 8932 bytes) \n",
      "24/03/14 20:54:49 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on worker-node-1:45391 (size: 7.1 KiB, free: 366.1 MiB)\n",
      "24/03/14 20:54:49 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on worker-node-2:39037 (size: 7.1 KiB, free: 366.0 MiB)\n",
      "24/03/14 20:54:49 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on worker-node-1:45391 (size: 35.5 KiB, free: 366.0 MiB)\n",
      "24/03/14 20:54:49 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on worker-node-2:39037 (size: 35.5 KiB, free: 366.0 MiB)\n",
      "24/03/14 20:54:49 INFO BlockManagerInfo: Added rdd_248_1 in memory on worker-node-1:45391 (size: 1808.0 B, free: 366.0 MiB)\n",
      "24/03/14 20:54:49 INFO TaskSetManager: Finished task 1.0 in stage 51.0 (TID 57) in 110 ms on worker-node-1 (executor 1) (1/2)\n",
      "24/03/14 20:54:49 INFO BlockManagerInfo: Added rdd_248_0 in memory on worker-node-2:39037 (size: 2.2 KiB, free: 366.0 MiB)\n",
      "24/03/14 20:54:49 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 56) in 162 ms on worker-node-2 (executor 2) (2/2)\n",
      "24/03/14 20:54:49 INFO YarnScheduler: Removed TaskSet 51.0, whose tasks have all completed, from pool \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                 _c0|\n",
      "+--------------------+\n",
      "|                   {|\n",
      "|               22050|\n",
      "|         \"a222795...|\n",
      "|                   0|\n",
      "|             218.932|\n",
      "|               0.247|\n",
      "|                   0|\n",
      "|                   0|\n",
      "|                   0|\n",
      "|                   0|\n",
      "|                   0|\n",
      "|                   0|\n",
      "|                   0|\n",
      "|                   0|\n",
      "|                   0|\n",
      "|                   0|\n",
      "|                   0|\n",
      "|                   0|\n",
      "|                   0|\n",
      "|                   0|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 20:54:49 INFO DAGScheduler: ResultStage 51 (showString at NativeMethodAccessorImpl.java:0) finished in 0.171 s\n",
      "24/03/14 20:54:49 INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 20:54:49 INFO YarnScheduler: Killing all running tasks in stage 51: Stage finished\n",
      "24/03/14 20:54:49 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "24/03/14 20:54:49 INFO DAGScheduler: Got job 47 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/03/14 20:54:49 INFO DAGScheduler: Final stage: ResultStage 52 (showString at NativeMethodAccessorImpl.java:0)\n",
      "24/03/14 20:54:49 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 20:54:49 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 20:54:49 INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[253] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/03/14 20:54:49 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 18.9 KiB, free 361.2 MiB)\n",
      "24/03/14 20:54:49 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 8.9 KiB, free 361.2 MiB)\n",
      "24/03/14 20:54:49 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on master-node:35375 (size: 8.9 KiB, free: 365.8 MiB)\n",
      "24/03/14 20:54:49 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 20:54:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[253] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/03/14 20:54:49 INFO YarnScheduler: Adding task set 52.0 with 1 tasks resource profile 0\n",
      "24/03/14 20:54:49 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 58) (worker-node-2, executor 2, partition 0, PROCESS_LOCAL, 9092 bytes) \n",
      "24/03/14 20:54:49 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on worker-node-2:39037 (size: 8.9 KiB, free: 366.0 MiB)\n",
      "24/03/14 20:54:49 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 58) in 34 ms on worker-node-2 (executor 2) (1/1)\n",
      "24/03/14 20:54:49 INFO YarnScheduler: Removed TaskSet 52.0, whose tasks have all completed, from pool \n",
      "24/03/14 20:54:49 INFO DAGScheduler: ResultStage 52 (showString at NativeMethodAccessorImpl.java:0) finished in 0.043 s\n",
      "24/03/14 20:54:49 INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 20:54:49 INFO YarnScheduler: Killing all running tasks in stage 52: Stage finished\n",
      "24/03/14 20:54:49 INFO DAGScheduler: Job 47 finished: showString at NativeMethodAccessorImpl.java:0, took 0.048518 s\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c8ee405-b975-47d0-bf4e-7771656f1d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 20:52:04 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.\n",
      "24/03/14 20:52:04 INFO InMemoryFileIndex: It took 17 ms to list leaf files for 11 paths.\n",
      "24/03/14 20:52:04 INFO FileSourceStrategy: Pushed Filters: \n",
      "24/03/14 20:52:04 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#472, None)) > 0)\n",
      "24/03/14 20:52:04 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 353.8 KiB, free 362.8 MiB)\n",
      "24/03/14 20:52:04 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 35.7 KiB, free 362.7 MiB)\n",
      "24/03/14 20:52:04 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on master-node:35375 (size: 35.7 KiB, free: 366.0 MiB)\n",
      "24/03/14 20:52:04 INFO SparkContext: Created broadcast 52 from csv at NativeMethodAccessorImpl.java:0\n",
      "24/03/14 20:52:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 23071304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "24/03/14 20:52:04 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0\n",
      "24/03/14 20:52:04 INFO DAGScheduler: Got job 34 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/03/14 20:52:04 INFO DAGScheduler: Final stage: ResultStage 39 (csv at NativeMethodAccessorImpl.java:0)\n",
      "24/03/14 20:52:04 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 20:52:04 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 20:52:04 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[159] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/03/14 20:52:04 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 13.5 KiB, free 362.7 MiB)\n",
      "24/03/14 20:52:04 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 362.7 MiB)\n",
      "24/03/14 20:52:04 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on master-node:35375 (size: 6.4 KiB, free: 365.9 MiB)\n",
      "24/03/14 20:52:04 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 20:52:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[159] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/03/14 20:52:04 INFO YarnScheduler: Adding task set 39.0 with 1 tasks resource profile 0\n",
      "24/03/14 20:52:04 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 41) (worker-node-1, executor 1, partition 0, NODE_LOCAL, 9092 bytes) \n",
      "24/03/14 20:52:04 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on worker-node-1:45391 (size: 6.4 KiB, free: 366.2 MiB)\n",
      "24/03/14 20:52:04 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on worker-node-1:45391 (size: 35.7 KiB, free: 366.1 MiB)\n",
      "24/03/14 20:52:04 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 41) in 71 ms on worker-node-1 (executor 1) (1/1)\n",
      "24/03/14 20:52:04 INFO YarnScheduler: Removed TaskSet 39.0, whose tasks have all completed, from pool \n",
      "24/03/14 20:52:04 INFO DAGScheduler: ResultStage 39 (csv at NativeMethodAccessorImpl.java:0) finished in 0.077 s\n",
      "24/03/14 20:52:04 INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 20:52:04 INFO YarnScheduler: Killing all running tasks in stage 39: Stage finished\n",
      "24/03/14 20:52:04 INFO DAGScheduler: Job 34 finished: csv at NativeMethodAccessorImpl.java:0, took 0.081298 s\n",
      "24/03/14 20:52:04 INFO FileSourceStrategy: Pushed Filters: \n",
      "24/03/14 20:52:04 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "24/03/14 20:52:04 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 353.8 KiB, free 362.4 MiB)\n",
      "24/03/14 20:52:04 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 35.7 KiB, free 362.3 MiB)\n",
      "24/03/14 20:52:04 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on master-node:35375 (size: 35.7 KiB, free: 365.9 MiB)\n",
      "24/03/14 20:52:04 INFO SparkContext: Created broadcast 54 from csv at NativeMethodAccessorImpl.java:0\n",
      "24/03/14 20:52:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 23071304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "24/03/14 20:52:04 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 353.5 KiB, free 362.0 MiB)\n",
      "24/03/14 20:52:04 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 35.6 KiB, free 362.0 MiB)\n",
      "24/03/14 20:52:04 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on master-node:35375 (size: 35.6 KiB, free: 365.9 MiB)\n",
      "24/03/14 20:52:04 INFO SparkContext: Created broadcast 55 from showString at NativeMethodAccessorImpl.java:0\n",
      "24/03/14 20:52:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 23071304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "24/03/14 20:52:04 INFO DAGScheduler: Got job 35 (showString at NativeMethodAccessorImpl.java:0) with 2 output partitions\n",
      "24/03/14 20:52:04 INFO DAGScheduler: Final stage: ResultStage 40 (showString at NativeMethodAccessorImpl.java:0)\n",
      "24/03/14 20:52:04 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 20:52:04 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 20:52:04 INFO DAGScheduler: Submitting ResultStage 40 (FileScan csv [_c0#465] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_so..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<_c0:string>\n",
      " MapPartitionsRDD[169] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/03/14 20:52:04 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 13.6 KiB, free 362.0 MiB)\n",
      "24/03/14 20:52:04 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 361.9 MiB)\n",
      "24/03/14 20:52:04 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on master-node:35375 (size: 7.1 KiB, free: 365.9 MiB)\n",
      "24/03/14 20:52:04 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 20:52:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 40 (FileScan csv [_c0#465] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_so..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<_c0:string>\n",
      " MapPartitionsRDD[169] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))\n",
      "24/03/14 20:52:04 INFO YarnScheduler: Adding task set 40.0 with 2 tasks resource profile 0\n",
      "24/03/14 20:52:04 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 42) (worker-node-1, executor 1, partition 0, NODE_LOCAL, 9092 bytes) \n",
      "24/03/14 20:52:04 INFO TaskSetManager: Starting task 1.0 in stage 40.0 (TID 43) (worker-node-2, executor 2, partition 1, NODE_LOCAL, 8932 bytes) \n",
      "24/03/14 20:52:04 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on worker-node-1:45391 (size: 7.1 KiB, free: 366.1 MiB)\n",
      "24/03/14 20:52:04 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on worker-node-2:39037 (size: 7.1 KiB, free: 366.1 MiB)\n",
      "24/03/14 20:52:04 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on worker-node-2:39037 (size: 35.6 KiB, free: 366.1 MiB)\n",
      "24/03/14 20:52:04 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on worker-node-1:45391 (size: 35.6 KiB, free: 366.1 MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|                 _c0|filename|\n",
      "+--------------------+--------+\n",
      "|                   {|        |\n",
      "|               22050|        |\n",
      "|         \"a222795...|        |\n",
      "|                   0|        |\n",
      "|             218.932|        |\n",
      "|               0.247|        |\n",
      "|                   0|        |\n",
      "|                   0|        |\n",
      "|                   0|        |\n",
      "|                   0|        |\n",
      "|                   0|        |\n",
      "|                   0|        |\n",
      "|                   0|        |\n",
      "|                   0|        |\n",
      "|                   0|        |\n",
      "|                   0|        |\n",
      "|                   0|        |\n",
      "|                   0|        |\n",
      "|                   0|        |\n",
      "|                   0|        |\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 20:52:05 INFO BlockManagerInfo: Added rdd_169_0 in memory on worker-node-1:45391 (size: 2.2 KiB, free: 366.1 MiB)\n",
      "24/03/14 20:52:05 INFO BlockManagerInfo: Added rdd_169_1 in memory on worker-node-2:39037 (size: 1808.0 B, free: 366.1 MiB)\n",
      "24/03/14 20:52:05 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 42) in 143 ms on worker-node-1 (executor 1) (1/2)\n",
      "24/03/14 20:52:05 INFO TaskSetManager: Finished task 1.0 in stage 40.0 (TID 43) in 149 ms on worker-node-2 (executor 2) (2/2)\n",
      "24/03/14 20:52:05 INFO YarnScheduler: Removed TaskSet 40.0, whose tasks have all completed, from pool \n",
      "24/03/14 20:52:05 INFO DAGScheduler: ResultStage 40 (showString at NativeMethodAccessorImpl.java:0) finished in 0.160 s\n",
      "24/03/14 20:52:05 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 20:52:05 INFO YarnScheduler: Killing all running tasks in stage 40: Stage finished\n",
      "24/03/14 20:52:05 INFO DAGScheduler: Got job 36 (showString at NativeMethodAccessorImpl.java:0) with 2 output partitions\n",
      "24/03/14 20:52:05 INFO DAGScheduler: Final stage: ResultStage 41 (showString at NativeMethodAccessorImpl.java:0)\n",
      "24/03/14 20:52:05 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 20:52:05 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 20:52:05 INFO DAGScheduler: Submitting ResultStage 41 (AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Project [_c0#489, input_file_name() AS filename#491]\n",
      "   +- InMemoryTableScan [_c0#489]\n",
      "         +- InMemoryRelation [_c0#489], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "               +- FileScan csv [_c0#465] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_so..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<_c0:string>\n",
      " MapPartitionsRDD[175] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/03/14 20:52:05 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 20.1 KiB, free 361.9 MiB)\n",
      "24/03/14 20:52:05 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 9.4 KiB, free 361.9 MiB)\n",
      "24/03/14 20:52:05 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on master-node:35375 (size: 9.4 KiB, free: 365.9 MiB)\n",
      "24/03/14 20:52:05 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 20:52:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 41 (AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Project [_c0#489, input_file_name() AS filename#491]\n",
      "   +- InMemoryTableScan [_c0#489]\n",
      "         +- InMemoryRelation [_c0#489], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "               +- FileScan csv [_c0#465] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_so..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<_c0:string>\n",
      " MapPartitionsRDD[175] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))\n",
      "24/03/14 20:52:05 INFO YarnScheduler: Adding task set 41.0 with 2 tasks resource profile 0\n",
      "24/03/14 20:52:05 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 44) (worker-node-1, executor 1, partition 0, PROCESS_LOCAL, 9092 bytes) \n",
      "24/03/14 20:52:05 INFO TaskSetManager: Starting task 1.0 in stage 41.0 (TID 45) (worker-node-2, executor 2, partition 1, PROCESS_LOCAL, 8932 bytes) \n",
      "24/03/14 20:52:05 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on worker-node-1:45391 (size: 9.4 KiB, free: 366.1 MiB)\n",
      "24/03/14 20:52:05 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on worker-node-2:39037 (size: 9.4 KiB, free: 366.1 MiB)\n",
      "24/03/14 20:52:05 INFO BlockManagerInfo: Added rdd_175_0 in memory on worker-node-1:45391 (size: 2.4 KiB, free: 366.1 MiB)\n",
      "24/03/14 20:52:05 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 44) in 32 ms on worker-node-1 (executor 1) (1/2)\n",
      "24/03/14 20:52:05 INFO BlockManagerInfo: Added rdd_175_1 in memory on worker-node-2:39037 (size: 1992.0 B, free: 366.1 MiB)\n",
      "24/03/14 20:52:05 INFO TaskSetManager: Finished task 1.0 in stage 41.0 (TID 45) in 39 ms on worker-node-2 (executor 2) (2/2)\n",
      "24/03/14 20:52:05 INFO YarnScheduler: Removed TaskSet 41.0, whose tasks have all completed, from pool \n",
      "24/03/14 20:52:05 INFO DAGScheduler: ResultStage 41 (showString at NativeMethodAccessorImpl.java:0) finished in 0.045 s\n",
      "24/03/14 20:52:05 INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 20:52:05 INFO YarnScheduler: Killing all running tasks in stage 41: Stage finished\n",
      "24/03/14 20:52:05 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "24/03/14 20:52:05 INFO DAGScheduler: Got job 37 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/03/14 20:52:05 INFO DAGScheduler: Final stage: ResultStage 42 (showString at NativeMethodAccessorImpl.java:0)\n",
      "24/03/14 20:52:05 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 20:52:05 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 20:52:05 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[180] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/03/14 20:52:05 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 23.3 KiB, free 361.9 MiB)\n",
      "24/03/14 20:52:05 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 10.0 KiB, free 361.9 MiB)\n",
      "24/03/14 20:52:05 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on master-node:35375 (size: 10.0 KiB, free: 365.9 MiB)\n",
      "24/03/14 20:52:05 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 20:52:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[180] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/03/14 20:52:05 INFO YarnScheduler: Adding task set 42.0 with 1 tasks resource profile 0\n",
      "24/03/14 20:52:05 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 46) (worker-node-1, executor 1, partition 0, PROCESS_LOCAL, 9092 bytes) \n",
      "24/03/14 20:52:05 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on worker-node-1:45391 (size: 10.0 KiB, free: 366.1 MiB)\n",
      "24/03/14 20:52:05 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 46) in 37 ms on worker-node-1 (executor 1) (1/1)\n",
      "24/03/14 20:52:05 INFO YarnScheduler: Removed TaskSet 42.0, whose tasks have all completed, from pool \n",
      "24/03/14 20:52:05 INFO DAGScheduler: ResultStage 42 (showString at NativeMethodAccessorImpl.java:0) finished in 0.044 s\n",
      "24/03/14 20:52:05 INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 20:52:05 INFO YarnScheduler: Killing all running tasks in stage 42: Stage finished\n",
      "24/03/14 20:52:05 INFO DAGScheduler: Job 37 finished: showString at NativeMethodAccessorImpl.java:0, took 0.051045 s\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import input_file_name\n",
    "\n",
    "df = (sqlContext.read.option(\"delimiter\", \",\").csv(path)\n",
    "      .withColumn(\"filename\", input_file_name())\n",
    "      .cache())\n",
    "\n",
    "df.show()\n",
    "\n",
    "# Erstellen einer Spalte fr jede Datei\n",
    "#df_pivoted = df.groupBy().pivot(\"filename\").agg({\"_c0\": \"first\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "73c3f5a3-bff4-491d-9f5f-cfaab3dcced9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 20:51:24 INFO DAGScheduler: Registering RDD 127 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 2\n",
      "24/03/14 20:51:24 INFO DAGScheduler: Got map stage job 29 (showString at NativeMethodAccessorImpl.java:0) with 2 output partitions\n",
      "24/03/14 20:51:24 INFO DAGScheduler: Final stage: ShuffleMapStage 33 (showString at NativeMethodAccessorImpl.java:0)\n",
      "24/03/14 20:51:24 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 20:51:24 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 20:51:24 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[127] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/03/14 20:51:24 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 33.6 KiB, free 362.1 MiB)\n",
      "24/03/14 20:51:24 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 362.1 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on master-node:35375 (size: 15.5 KiB, free: 365.8 MiB)\n",
      "24/03/14 20:51:24 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 20:51:24 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[127] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))\n",
      "24/03/14 20:51:24 INFO YarnScheduler: Adding task set 33.0 with 2 tasks resource profile 0\n",
      "24/03/14 20:51:24 INFO TaskSetManager: Starting task 1.0 in stage 33.0 (TID 35) (worker-node-1, executor 1, partition 1, PROCESS_LOCAL, 8921 bytes) \n",
      "24/03/14 20:51:24 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 36) (worker-node-2, executor 2, partition 0, PROCESS_LOCAL, 9081 bytes) \n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on worker-node-2:39037 (size: 15.5 KiB, free: 366.0 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on worker-node-1:45391 (size: 15.5 KiB, free: 366.1 MiB)\n",
      "24/03/14 20:51:24 INFO TaskSetManager: Finished task 1.0 in stage 33.0 (TID 35) in 207 ms on worker-node-1 (executor 1) (1/2)\n",
      "24/03/14 20:51:24 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 36) in 302 ms on worker-node-2 (executor 2) (2/2)\n",
      "24/03/14 20:51:24 INFO YarnScheduler: Removed TaskSet 33.0, whose tasks have all completed, from pool \n",
      "24/03/14 20:51:24 INFO DAGScheduler: ShuffleMapStage 33 (showString at NativeMethodAccessorImpl.java:0) finished in 0.330 s\n",
      "24/03/14 20:51:24 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/03/14 20:51:24 INFO DAGScheduler: running: Set()\n",
      "24/03/14 20:51:24 INFO DAGScheduler: waiting: Set()\n",
      "24/03/14 20:51:24 INFO DAGScheduler: failed: Set()\n",
      "24/03/14 20:51:24 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "24/03/14 20:51:24 INFO DAGScheduler: Got job 30 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/03/14 20:51:24 INFO DAGScheduler: Final stage: ResultStage 35 (showString at NativeMethodAccessorImpl.java:0)\n",
      "24/03/14 20:51:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)\n",
      "24/03/14 20:51:24 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_29_piece0 on master-node:35375 in memory (size: 35.7 KiB, free: 365.9 MiB)\n",
      "24/03/14 20:51:24 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[130] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/03/14 20:51:24 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 39.5 KiB, free 362.4 MiB)\n",
      "24/03/14 20:51:24 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 18.5 KiB, free 362.4 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on master-node:35375 (size: 18.5 KiB, free: 365.8 MiB)\n",
      "24/03/14 20:51:24 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 20:51:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[130] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/03/14 20:51:24 INFO YarnScheduler: Adding task set 35.0 with 1 tasks resource profile 0\n",
      "24/03/14 20:51:24 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 37) (worker-node-1, executor 1, partition 0, NODE_LOCAL, 7626 bytes) \n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_26_piece0 on master-node:35375 in memory (size: 8.9 KiB, free: 365.8 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_26_piece0 on worker-node-2:39037 in memory (size: 8.9 KiB, free: 366.0 MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|       |\n",
      "+-------+\n",
      "|      {|\n",
      "+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_36_piece0 on master-node:35375 in memory (size: 6.4 KiB, free: 365.8 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on worker-node-1:45391 (size: 18.5 KiB, free: 366.1 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_36_piece0 on worker-node-1:45391 in memory (size: 6.4 KiB, free: 366.1 MiB)\n",
      "24/03/14 20:51:24 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 192.168.2.124:41156\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_42_piece0 on master-node:35375 in memory (size: 4.2 KiB, free: 365.9 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_42_piece0 on worker-node-2:39037 in memory (size: 4.2 KiB, free: 366.0 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_38_piece0 on master-node:35375 in memory (size: 9.4 KiB, free: 365.9 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_38_piece0 on worker-node-2:39037 in memory (size: 9.4 KiB, free: 366.0 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_38_piece0 on worker-node-1:45391 in memory (size: 9.4 KiB, free: 366.1 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_40_piece0 on master-node:35375 in memory (size: 22.4 KiB, free: 365.9 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_40_piece0 on worker-node-1:45391 in memory (size: 22.4 KiB, free: 366.1 MiB)\n",
      "24/03/14 20:51:24 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 37) in 123 ms on worker-node-1 (executor 1) (1/1)\n",
      "24/03/14 20:51:24 INFO YarnScheduler: Removed TaskSet 35.0, whose tasks have all completed, from pool \n",
      "24/03/14 20:51:24 INFO DAGScheduler: ResultStage 35 (showString at NativeMethodAccessorImpl.java:0) finished in 0.134 s\n",
      "24/03/14 20:51:24 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 20:51:24 INFO YarnScheduler: Killing all running tasks in stage 35: Stage finished\n",
      "24/03/14 20:51:24 INFO DAGScheduler: Job 30 finished: showString at NativeMethodAccessorImpl.java:0, took 0.155527 s\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_35_piece0 on worker-node-1:45391 in memory (size: 35.7 KiB, free: 366.2 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_35_piece0 on master-node:35375 in memory (size: 35.7 KiB, free: 365.9 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_28_piece0 on master-node:35375 in memory (size: 6.4 KiB, free: 365.9 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_28_piece0 on worker-node-2:39037 in memory (size: 6.4 KiB, free: 366.0 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_25_piece0 on master-node:35375 in memory (size: 7.1 KiB, free: 365.9 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_25_piece0 on worker-node-2:39037 in memory (size: 7.1 KiB, free: 366.0 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_25_piece0 on worker-node-1:45391 in memory (size: 7.1 KiB, free: 366.2 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_37_piece0 on master-node:35375 in memory (size: 35.7 KiB, free: 366.0 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_33_piece0 on master-node:35375 in memory (size: 35.7 KiB, free: 366.0 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_39_piece0 on master-node:35375 in memory (size: 15.6 KiB, free: 366.0 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_39_piece0 on worker-node-2:39037 in memory (size: 15.6 KiB, free: 366.0 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_39_piece0 on worker-node-1:45391 in memory (size: 15.6 KiB, free: 366.2 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_32_piece0 on master-node:35375 in memory (size: 6.4 KiB, free: 366.0 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_32_piece0 on worker-node-2:39037 in memory (size: 6.4 KiB, free: 366.0 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_30_piece0 on master-node:35375 in memory (size: 9.0 KiB, free: 366.0 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_30_piece0 on worker-node-2:39037 in memory (size: 9.0 KiB, free: 366.0 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_43_piece0 on master-node:35375 in memory (size: 15.5 KiB, free: 366.0 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_43_piece0 on worker-node-2:39037 in memory (size: 15.5 KiB, free: 366.1 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_43_piece0 on worker-node-1:45391 in memory (size: 15.5 KiB, free: 366.2 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_31_piece0 on master-node:35375 in memory (size: 35.7 KiB, free: 366.1 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_31_piece0 on worker-node-2:39037 in memory (size: 35.7 KiB, free: 366.1 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_41_piece0 on master-node:35375 in memory (size: 22.7 KiB, free: 366.1 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_41_piece0 on worker-node-2:39037 in memory (size: 22.7 KiB, free: 366.1 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_27_piece0 on master-node:35375 in memory (size: 35.7 KiB, free: 366.1 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_27_piece0 on worker-node-2:39037 in memory (size: 35.7 KiB, free: 366.2 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_34_piece0 on master-node:35375 in memory (size: 9.0 KiB, free: 366.1 MiB)\n",
      "24/03/14 20:51:24 INFO BlockManagerInfo: Removed broadcast_34_piece0 on worker-node-2:39037 in memory (size: 9.0 KiB, free: 366.2 MiB)\n"
     ]
    }
   ],
   "source": [
    "df_pivoted.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dd2778c3-891a-42e4-bf9c-9dacda6c0a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(split(df[\"_c0\"], \",\").alias(\"columns\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "894a3278-b9e5-4217-8ad2-61d1228b1b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             columns|\n",
      "+--------------------+\n",
      "|           [      {]|\n",
      "|    [         22050]|\n",
      "|[         \"a22279...|\n",
      "|        [         0]|\n",
      "|  [         218.932]|\n",
      "|    [         0.247]|\n",
      "|        [         0]|\n",
      "|        [         0]|\n",
      "|        [         0]|\n",
      "|        [         0]|\n",
      "|        [         0]|\n",
      "|        [         0]|\n",
      "|        [         0]|\n",
      "|        [         0]|\n",
      "|        [         0]|\n",
      "|        [         0]|\n",
      "|        [         0]|\n",
      "|        [         0]|\n",
      "|        [         0]|\n",
      "|        [         0]|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 20:07:20 INFO CodeGenerator: Code generated in 18.867003 ms\n",
      "24/03/14 20:07:20 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "24/03/14 20:07:20 INFO DAGScheduler: Got job 29 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/03/14 20:07:20 INFO DAGScheduler: Final stage: ResultStage 29 (showString at NativeMethodAccessorImpl.java:0)\n",
      "24/03/14 20:07:20 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 20:07:20 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 20:07:20 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[121] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/03/14 20:07:20 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 20.2 KiB, free 362.2 MiB)\n",
      "24/03/14 20:07:20 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 9.5 KiB, free 362.2 MiB)\n",
      "24/03/14 20:07:20 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on master-node:33151 (size: 9.5 KiB, free: 365.9 MiB)\n",
      "24/03/14 20:07:20 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 20:07:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[121] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/03/14 20:07:20 INFO YarnScheduler: Adding task set 29.0 with 1 tasks resource profile 0\n",
      "24/03/14 20:07:20 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 106) (worker-node-1, executor 2, partition 0, PROCESS_LOCAL, 8292 bytes) \n",
      "24/03/14 20:07:20 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on worker-node-1:44403 (size: 9.5 KiB, free: 366.0 MiB)\n",
      "24/03/14 20:07:20 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 106) in 48 ms on worker-node-1 (executor 2) (1/1)\n",
      "24/03/14 20:07:20 INFO YarnScheduler: Removed TaskSet 29.0, whose tasks have all completed, from pool \n",
      "24/03/14 20:07:20 INFO DAGScheduler: ResultStage 29 (showString at NativeMethodAccessorImpl.java:0) finished in 0.061 s\n",
      "24/03/14 20:07:20 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 20:07:20 INFO YarnScheduler: Killing all running tasks in stage 29: Stage finished\n",
      "24/03/14 20:07:20 INFO DAGScheduler: Job 29 finished: showString at NativeMethodAccessorImpl.java:0, took 0.069505 s\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "777fb5d8-3ae5-49d7-9a1e-3c64e6d8a6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 20:01:20 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 358.7 KiB, free 363.1 MiB)\n",
      "24/03/14 20:01:20 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 33.1 KiB, free 363.1 MiB)\n",
      "24/03/14 20:01:20 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on master-node:33151 (size: 33.1 KiB, free: 366.0 MiB)\n",
      "24/03/14 20:01:20 INFO SparkContext: Created broadcast 29 from textFile at NativeMethodAccessorImpl.java:0\n",
      "24/03/14 20:01:21 INFO FileInputFormat: Total input files to process : 11\n",
      "24/03/14 20:01:21 INFO SparkContext: Starting job: runJob at PythonRDD.scala:181\n",
      "24/03/14 20:01:21 INFO DAGScheduler: Got job 18 (runJob at PythonRDD.scala:181) with 1 output partitions\n",
      "24/03/14 20:01:21 INFO DAGScheduler: Final stage: ResultStage 18 (runJob at PythonRDD.scala:181)\n",
      "24/03/14 20:01:21 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 20:01:21 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 20:01:21 INFO DAGScheduler: Submitting ResultStage 18 (PythonRDD[76] at RDD at PythonRDD.scala:53), which has no missing parents\n",
      "24/03/14 20:01:21 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 9.0 KiB, free 363.1 MiB)\n",
      "24/03/14 20:01:21 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 363.1 MiB)\n",
      "24/03/14 20:01:21 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on master-node:33151 (size: 5.5 KiB, free: 366.0 MiB)\n",
      "24/03/14 20:01:21 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 20:01:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (PythonRDD[76] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))\n",
      "24/03/14 20:01:21 INFO YarnScheduler: Adding task set 18.0 with 1 tasks resource profile 0\n",
      "24/03/14 20:01:21 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 49) (worker-node-2, executor 1, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 20:01:21 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on worker-node-2:34115 (size: 5.5 KiB, free: 366.0 MiB)\n",
      "24/03/14 20:01:21 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on worker-node-2:34115 (size: 33.1 KiB, free: 366.0 MiB)\n",
      "24/03/14 20:01:21 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 49) in 96 ms on worker-node-2 (executor 1) (1/1)\n",
      "24/03/14 20:01:21 INFO YarnScheduler: Removed TaskSet 18.0, whose tasks have all completed, from pool \n",
      "24/03/14 20:01:21 INFO DAGScheduler: ResultStage 18 (runJob at PythonRDD.scala:181) finished in 0.107 s\n",
      "24/03/14 20:01:21 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 20:01:21 INFO YarnScheduler: Killing all running tasks in stage 18: Stage finished\n",
      "24/03/14 20:01:21 INFO DAGScheduler: Job 18 finished: runJob at PythonRDD.scala:181, took 0.113358 s\n",
      "24/03/14 20:01:21 INFO CodeGenerator: Code generated in 13.488491 ms\n",
      "24/03/14 20:01:21 INFO DAGScheduler: Got job 19 (showString at NativeMethodAccessorImpl.java:0) with 11 output partitions\n",
      "24/03/14 20:01:21 INFO DAGScheduler: Final stage: ResultStage 19 (showString at NativeMethodAccessorImpl.java:0)\n",
      "24/03/14 20:01:21 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 20:01:21 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 20:01:21 INFO DAGScheduler: Submitting ResultStage 19 (*(1) Project [_1#1167 AS column_1#1169]\n",
      "+- *(1) Scan ExistingRDD[_1#1167]\n",
      " MapPartitionsRDD[83] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/03/14 20:01:21 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 18.4 KiB, free 363.0 MiB)\n",
      "24/03/14 20:01:21 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 9.6 KiB, free 363.0 MiB)\n",
      "24/03/14 20:01:21 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on master-node:33151 (size: 9.6 KiB, free: 366.0 MiB)\n",
      "24/03/14 20:01:21 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 20:01:21 INFO DAGScheduler: Submitting 11 missing tasks from ResultStage 19 (*(1) Project [_1#1167 AS column_1#1169]\n",
      "+- *(1) Scan ExistingRDD[_1#1167]\n",
      " MapPartitionsRDD[83] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))\n",
      "24/03/14 20:01:21 INFO YarnScheduler: Adding task set 19.0 with 11 tasks resource profile 0\n",
      "24/03/14 20:01:21 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 50) (worker-node-1, executor 2, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 20:01:21 INFO TaskSetManager: Starting task 1.0 in stage 19.0 (TID 51) (worker-node-2, executor 1, partition 1, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 20:01:21 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on worker-node-2:34115 (size: 9.6 KiB, free: 366.0 MiB)\n",
      "24/03/14 20:01:21 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on worker-node-1:44403 (size: 9.6 KiB, free: 366.0 MiB)\n",
      "24/03/14 20:01:21 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on worker-node-1:44403 (size: 33.1 KiB, free: 366.0 MiB)\n",
      "24/03/14 20:01:21 INFO TaskSetManager: Starting task 2.0 in stage 19.0 (TID 52) (worker-node-2, executor 1, partition 2, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 20:01:21 WARN TaskSetManager: Lost task 1.0 in stage 19.0 (TID 51) (worker-node-2 executor 1): java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:88)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:290)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:287)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1597)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "24/03/14 20:01:21 INFO TaskSetManager: Starting task 1.1 in stage 19.0 (TID 53) (worker-node-1, executor 2, partition 1, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 20:01:21 INFO TaskSetManager: Lost task 0.0 in stage 19.0 (TID 50) on worker-node-1, executor 2: java.lang.IllegalStateException (Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.) [duplicate 1]\n",
      "24/03/14 20:01:21 INFO TaskSetManager: Starting task 0.1 in stage 19.0 (TID 54) (worker-node-2, executor 1, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 20:01:21 INFO TaskSetManager: Starting task 3.0 in stage 19.0 (TID 55) (worker-node-1, executor 2, partition 3, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 20:01:21 INFO TaskSetManager: Lost task 1.1 in stage 19.0 (TID 53) on worker-node-1, executor 2: java.lang.IllegalStateException (Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.) [duplicate 2]\n",
      "24/03/14 20:01:21 INFO TaskSetManager: Lost task 2.0 in stage 19.0 (TID 52) on worker-node-2, executor 1: java.lang.IllegalStateException (Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.) [duplicate 3]\n",
      "24/03/14 20:01:21 INFO TaskSetManager: Starting task 2.1 in stage 19.0 (TID 56) (worker-node-2, executor 1, partition 2, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 20:01:21 INFO TaskSetManager: Lost task 0.1 in stage 19.0 (TID 54) on worker-node-2, executor 1: java.lang.IllegalStateException (Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.) [duplicate 4]\n",
      "24/03/14 20:01:21 INFO TaskSetManager: Starting task 0.2 in stage 19.0 (TID 57) (worker-node-1, executor 2, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 20:01:21 INFO TaskSetManager: Lost task 3.0 in stage 19.0 (TID 55) on worker-node-1, executor 2: java.lang.IllegalStateException (Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.) [duplicate 5]\n",
      "24/03/14 20:01:21 INFO TaskSetManager: Starting task 3.1 in stage 19.0 (TID 58) (worker-node-2, executor 1, partition 3, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 20:01:21 INFO TaskSetManager: Lost task 2.1 in stage 19.0 (TID 56) on worker-node-2, executor 1: java.lang.IllegalStateException (Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.) [duplicate 6]\n",
      "24/03/14 20:01:21 INFO TaskSetManager: Starting task 2.2 in stage 19.0 (TID 59) (worker-node-1, executor 2, partition 2, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 20:01:21 INFO TaskSetManager: Lost task 0.2 in stage 19.0 (TID 57) on worker-node-1, executor 2: java.lang.IllegalStateException (Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.) [duplicate 7]\n",
      "24/03/14 20:01:21 INFO TaskSetManager: Lost task 3.1 in stage 19.0 (TID 58) on worker-node-2, executor 1: java.lang.IllegalStateException (Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.) [duplicate 8]\n",
      "24/03/14 20:01:21 INFO TaskSetManager: Starting task 3.2 in stage 19.0 (TID 60) (worker-node-2, executor 1, partition 3, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 20:01:21 INFO TaskSetManager: Starting task 0.3 in stage 19.0 (TID 61) (worker-node-1, executor 2, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 20:01:21 INFO TaskSetManager: Lost task 2.2 in stage 19.0 (TID 59) on worker-node-1, executor 2: java.lang.IllegalStateException (Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.) [duplicate 9]\n",
      "24/03/14 20:01:21 INFO TaskSetManager: Starting task 2.3 in stage 19.0 (TID 62) (worker-node-2, executor 1, partition 2, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 20:01:21 INFO TaskSetManager: Lost task 3.2 in stage 19.0 (TID 60) on worker-node-2, executor 1: java.lang.IllegalStateException (Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.) [duplicate 10]\n",
      "24/03/14 20:01:21 INFO TaskSetManager: Starting task 3.3 in stage 19.0 (TID 63) (worker-node-2, executor 1, partition 3, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 20:01:21 INFO TaskSetManager: Lost task 2.3 in stage 19.0 (TID 62) on worker-node-2, executor 1: java.lang.IllegalStateException (Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.) [duplicate 11]\n",
      "24/03/14 20:01:21 ERROR TaskSetManager: Task 2 in stage 19.0 failed 4 times; aborting job\n",
      "24/03/14 20:01:21 INFO YarnScheduler: Cancelling stage 19\n",
      "24/03/14 20:01:21 INFO YarnScheduler: Killing all running tasks in stage 19: Stage cancelled: Job aborted due to stage failure: Task 2 in stage 19.0 failed 4 times, most recent failure: Lost task 2.3 in stage 19.0 (TID 62) (worker-node-2 executor 1): java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:88)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:290)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:287)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1597)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "Driver stacktrace:\n",
      "24/03/14 20:01:21 INFO YarnScheduler: Stage 19 was cancelled\n",
      "24/03/14 20:01:21 INFO DAGScheduler: ResultStage 19 (showString at NativeMethodAccessorImpl.java:0) failed in 0.381 s due to Job aborted due to stage failure: Task 2 in stage 19.0 failed 4 times, most recent failure: Lost task 2.3 in stage 19.0 (TID 62) (worker-node-2 executor 1): java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:88)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:290)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:287)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1597)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "Driver stacktrace:\n",
      "24/03/14 20:01:21 INFO TaskSetManager: Lost task 0.3 in stage 19.0 (TID 61) on worker-node-1, executor 2: java.lang.IllegalStateException (Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.) [duplicate 12]\n",
      "24/03/14 20:01:21 WARN TaskSetManager: Lost task 3.3 in stage 19.0 (TID 63) (worker-node-2 executor 1): TaskKilled (Stage cancelled: Job aborted due to stage failure: Task 2 in stage 19.0 failed 4 times, most recent failure: Lost task 2.3 in stage 19.0 (TID 62) (worker-node-2 executor 1): java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:88)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:290)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:287)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1597)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "Driver stacktrace:)\n",
      "24/03/14 20:01:21 INFO YarnScheduler: Removed TaskSet 19.0, whose tasks have all completed, from pool \n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o350.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 19.0 failed 4 times, most recent failure: Lost task 2.3 in stage 19.0 (TID 62) (worker-node-2 executor 1): java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:88)\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:290)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:287)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1597)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\nCaused by: java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:88)\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:290)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:287)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1597)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m df\u001b[38;5;241m.\u001b[39mcache()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Show DataFrame\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/dataframe.py:945\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow\u001b[39m(\u001b[38;5;28mself\u001b[39m, n: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, truncate: Union[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, vertical: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    886\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prints the first ``n`` rows to the console.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \n\u001b[1;32m    888\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;124;03m    name | Bob\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 945\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/dataframe.py:963\u001b[0m, in \u001b[0;36mDataFrame._show_string\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m    958\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    959\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(vertical)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m    960\u001b[0m     )\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[0;32m--> 963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o350.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 19.0 failed 4 times, most recent failure: Lost task 2.3 in stage 19.0 (TID 62) (worker-node-2 executor 1): java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:88)\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:290)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:287)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1597)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\nCaused by: java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:88)\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:290)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:287)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1597)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split, regexp_replace\n",
    "\n",
    "# Read the text file as RDD\n",
    "rdd = spark_context.textFile(directory_path)\n",
    "\n",
    "# Remove braces {} and split the lines by comma\n",
    "rdd = rdd.map(lambda line: line.strip('{}').split(','))\n",
    "\n",
    "# Convert RDD to DataFrame\n",
    "df = rdd.toDF()\n",
    "\n",
    "# Rename columns\n",
    "num_columns = len(df.columns)\n",
    "columns = [\"column_{}\".format(i) for i in range(1, num_columns + 1)]\n",
    "df = df.toDF(*columns)\n",
    "\n",
    "# Cache the DataFrame\n",
    "df.cache()\n",
    "\n",
    "# Show DataFrame\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca2deffa-3b0f-4a6c-9b65-9856154a3d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = rdd.map(lambda line: line.strip('{}').split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d8c2cfe-7500-4dd3-ba19-e22194dca848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each element of the RDD to a string\n",
    "rdd = rdd.map(lambda row: [str(elem) for elem in row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2272a110-03f1-4b3b-aa66-f99028084688",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 19:47:21 INFO SparkContext: Starting job: runJob at PythonRDD.scala:181\n",
      "24/03/14 19:47:21 INFO DAGScheduler: Got job 9 (runJob at PythonRDD.scala:181) with 1 output partitions\n",
      "24/03/14 19:47:21 INFO DAGScheduler: Final stage: ResultStage 9 (runJob at PythonRDD.scala:181)\n",
      "24/03/14 19:47:21 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 19:47:21 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 19:47:21 INFO DAGScheduler: Submitting ResultStage 9 (PythonRDD[34] at RDD at PythonRDD.scala:53), which has no missing parents\n",
      "24/03/14 19:47:21 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 9.3 KiB, free 365.1 MiB)\n",
      "24/03/14 19:47:21 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 365.1 MiB)\n",
      "24/03/14 19:47:21 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on master-node:33151 (size: 5.5 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:47:21 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 19:47:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (PythonRDD[34] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))\n",
      "24/03/14 19:47:21 INFO YarnScheduler: Adding task set 9.0 with 1 tasks resource profile 0\n",
      "24/03/14 19:47:21 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 32) (worker-node-2, executor 1, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 19:47:21 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on worker-node-2:34115 (size: 5.5 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:47:21 WARN TaskSetManager: Lost task 0.0 in stage 9.0 (TID 32) (worker-node-2 executor 1): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/worker.py\", line 1247, in main\n",
      "    process()\n",
      "  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/worker.py\", line 1239, in process\n",
      "    serializer.dump_stream(out_iter, outfile)\n",
      "  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n",
      "    vs = list(itertools.islice(iterator, batch))\n",
      "  File \"/home/hadoop/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 2849, in takeUpToNumLeft\n",
      "  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/util.py\", line 83, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_110122/1105035867.py\", line 1, in <lambda>\n",
      "AttributeError: 'list' object has no attribute 'strip'\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n",
      "\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n",
      "\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n",
      "\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n",
      "\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n",
      "\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n",
      "\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:181)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "24/03/14 19:47:21 INFO TaskSetManager: Starting task 0.1 in stage 9.0 (TID 33) (worker-node-2, executor 1, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 19:47:21 INFO TaskSetManager: Lost task 0.1 in stage 9.0 (TID 33) on worker-node-2, executor 1: org.apache.spark.api.python.PythonException (Traceback (most recent call last):\n",
      "  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/worker.py\", line 1247, in main\n",
      "    process()\n",
      "  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/worker.py\", line 1239, in process\n",
      "    serializer.dump_stream(out_iter, outfile)\n",
      "  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n",
      "    vs = list(itertools.islice(iterator, batch))\n",
      "  File \"/home/hadoop/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 2849, in takeUpToNumLeft\n",
      "  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/util.py\", line 83, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_110122/1105035867.py\", line 1, in <lambda>\n",
      "AttributeError: 'list' object has no attribute 'strip'\n",
      ") [duplicate 1]\n",
      "24/03/14 19:47:21 INFO TaskSetManager: Starting task 0.2 in stage 9.0 (TID 34) (worker-node-2, executor 1, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 19:47:21 INFO TaskSetManager: Lost task 0.2 in stage 9.0 (TID 34) on worker-node-2, executor 1: org.apache.spark.api.python.PythonException (Traceback (most recent call last):\n",
      "  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/worker.py\", line 1247, in main\n",
      "    process()\n",
      "  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/worker.py\", line 1239, in process\n",
      "    serializer.dump_stream(out_iter, outfile)\n",
      "  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n",
      "    vs = list(itertools.islice(iterator, batch))\n",
      "  File \"/home/hadoop/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 2849, in takeUpToNumLeft\n",
      "  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/util.py\", line 83, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_110122/1105035867.py\", line 1, in <lambda>\n",
      "AttributeError: 'list' object has no attribute 'strip'\n",
      ") [duplicate 2]\n",
      "24/03/14 19:47:21 INFO TaskSetManager: Starting task 0.3 in stage 9.0 (TID 35) (worker-node-2, executor 1, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 19:47:21 INFO TaskSetManager: Lost task 0.3 in stage 9.0 (TID 35) on worker-node-2, executor 1: org.apache.spark.api.python.PythonException (Traceback (most recent call last):\n",
      "  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/worker.py\", line 1247, in main\n",
      "    process()\n",
      "  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/worker.py\", line 1239, in process\n",
      "    serializer.dump_stream(out_iter, outfile)\n",
      "  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n",
      "    vs = list(itertools.islice(iterator, batch))\n",
      "  File \"/home/hadoop/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 2849, in takeUpToNumLeft\n",
      "  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/util.py\", line 83, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_110122/1105035867.py\", line 1, in <lambda>\n",
      "AttributeError: 'list' object has no attribute 'strip'\n",
      ") [duplicate 3]\n",
      "24/03/14 19:47:21 ERROR TaskSetManager: Task 0 in stage 9.0 failed 4 times; aborting job\n",
      "24/03/14 19:47:21 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool \n",
      "24/03/14 19:47:21 INFO YarnScheduler: Cancelling stage 9\n",
      "24/03/14 19:47:21 INFO YarnScheduler: Killing all running tasks in stage 9: Stage cancelled: Job aborted due to stage failure: Task 0 in stage 9.0 failed 4 times, most recent failure: Lost task 0.3 in stage 9.0 (TID 35) (worker-node-2 executor 1): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/worker.py\", line 1247, in main\n",
      "    process()\n",
      "  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/worker.py\", line 1239, in process\n",
      "    serializer.dump_stream(out_iter, outfile)\n",
      "  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n",
      "    vs = list(itertools.islice(iterator, batch))\n",
      "  File \"/home/hadoop/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 2849, in takeUpToNumLeft\n",
      "  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/util.py\", line 83, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_110122/1105035867.py\", line 1, in <lambda>\n",
      "AttributeError: 'list' object has no attribute 'strip'\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n",
      "\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n",
      "\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n",
      "\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n",
      "\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n",
      "\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n",
      "\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:181)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "Driver stacktrace:\n",
      "24/03/14 19:47:21 INFO DAGScheduler: ResultStage 9 (runJob at PythonRDD.scala:181) failed in 0.214 s due to Job aborted due to stage failure: Task 0 in stage 9.0 failed 4 times, most recent failure: Lost task 0.3 in stage 9.0 (TID 35) (worker-node-2 executor 1): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/worker.py\", line 1247, in main\n",
      "    process()\n",
      "  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/worker.py\", line 1239, in process\n",
      "    serializer.dump_stream(out_iter, outfile)\n",
      "  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n",
      "    vs = list(itertools.islice(iterator, batch))\n",
      "  File \"/home/hadoop/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 2849, in takeUpToNumLeft\n",
      "  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/util.py\", line 83, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_110122/1105035867.py\", line 1, in <lambda>\n",
      "AttributeError: 'list' object has no attribute 'strip'\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n",
      "\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n",
      "\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n",
      "\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n",
      "\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n",
      "\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n",
      "\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:181)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "Driver stacktrace:\n",
      "24/03/14 19:47:21 INFO DAGScheduler: Job 9 failed: runJob at PythonRDD.scala:181, took 0.220725 s\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 9.0 failed 4 times, most recent failure: Lost task 0.3 in stage 9.0 (TID 35) (worker-node-2 executor 1): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/worker.py\", line 1247, in main\n    process()\n  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/worker.py\", line 1239, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/home/hadoop/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 2849, in takeUpToNumLeft\n  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/util.py\", line 83, in wrapper\n    return f(*args, **kwargs)\n  File \"/tmp/ipykernel_110122/1105035867.py\", line 1, in <lambda>\nAttributeError: 'list' object has no attribute 'strip'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:181)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:181)\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/worker.py\", line 1247, in main\n    process()\n  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/worker.py\", line 1239, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/home/hadoop/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 2849, in takeUpToNumLeft\n  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/util.py\", line 83, in wrapper\n    return f(*args, **kwargs)\n  File \"/tmp/ipykernel_110122/1105035867.py\", line 1, in <lambda>\nAttributeError: 'list' object has no attribute 'strip'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:181)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Collect a sample of the RDD and print it\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[43mrdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Take 5 records as a sample\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m sample:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(row)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/rdd.py:2855\u001b[0m, in \u001b[0;36mRDD.take\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m   2852\u001b[0m         taken \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2854\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(partsScanned, \u001b[38;5;28mmin\u001b[39m(partsScanned \u001b[38;5;241m+\u001b[39m numPartsToTry, totalParts))\n\u001b[0;32m-> 2855\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunJob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeUpToNumLeft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2857\u001b[0m items \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m res\n\u001b[1;32m   2858\u001b[0m partsScanned \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m numPartsToTry\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/context.py:2510\u001b[0m, in \u001b[0;36mSparkContext.runJob\u001b[0;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[1;32m   2508\u001b[0m mappedRDD \u001b[38;5;241m=\u001b[39m rdd\u001b[38;5;241m.\u001b[39mmapPartitions(partitionFunc)\n\u001b[1;32m   2509\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2510\u001b[0m sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonRDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunJob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmappedRDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jrdd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartitions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2511\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, mappedRDD\u001b[38;5;241m.\u001b[39m_jrdd_deserializer))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 9.0 failed 4 times, most recent failure: Lost task 0.3 in stage 9.0 (TID 35) (worker-node-2 executor 1): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/worker.py\", line 1247, in main\n    process()\n  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/worker.py\", line 1239, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/home/hadoop/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 2849, in takeUpToNumLeft\n  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/util.py\", line 83, in wrapper\n    return f(*args, **kwargs)\n  File \"/tmp/ipykernel_110122/1105035867.py\", line 1, in <lambda>\nAttributeError: 'list' object has no attribute 'strip'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:181)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:181)\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/worker.py\", line 1247, in main\n    process()\n  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/worker.py\", line 1239, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/home/hadoop/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 2849, in takeUpToNumLeft\n  File \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1710430208522_0007/container_1710430208522_0007_01_000002/pyspark.zip/pyspark/util.py\", line 83, in wrapper\n    return f(*args, **kwargs)\n  File \"/tmp/ipykernel_110122/1105035867.py\", line 1, in <lambda>\nAttributeError: 'list' object has no attribute 'strip'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:181)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "# Collect a sample of the RDD and print it\n",
    "sample = rdd.take(5)  # Take 5 records as a sample\n",
    "for row in sample:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73fdaf85-990b-4af4-ab4b-c8568c9c2874",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 19:42:57 INFO FileInputFormat: Total input files to process : 11\n",
      "24/03/14 19:42:57 INFO SparkContext: Starting job: runJob at PythonRDD.scala:181\n",
      "24/03/14 19:42:57 INFO DAGScheduler: Got job 5 (runJob at PythonRDD.scala:181) with 1 output partitions\n",
      "24/03/14 19:42:57 INFO DAGScheduler: Final stage: ResultStage 5 (runJob at PythonRDD.scala:181)\n",
      "24/03/14 19:42:57 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 19:42:57 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 19:42:57 INFO DAGScheduler: Submitting ResultStage 5 (PythonRDD[25] at RDD at PythonRDD.scala:53), which has no missing parents\n",
      "24/03/14 19:42:57 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 9.0 KiB, free 365.1 MiB)\n",
      "24/03/14 19:42:57 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 365.1 MiB)\n",
      "24/03/14 19:42:57 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on master-node:33151 (size: 5.5 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:42:57 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 19:42:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (PythonRDD[25] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))\n",
      "24/03/14 19:42:57 INFO YarnScheduler: Adding task set 5.0 with 1 tasks resource profile 0\n",
      "24/03/14 19:42:57 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 8) (worker-node-2, executor 1, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 19:42:57 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on worker-node-2:34115 (size: 5.5 KiB, free: 366.3 MiB)\n",
      "24/03/14 19:42:57 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on worker-node-2:34115 (size: 33.1 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:42:59 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 8) in 1452 ms on worker-node-2 (executor 1) (1/1)\n",
      "24/03/14 19:42:59 INFO YarnScheduler: Removed TaskSet 5.0, whose tasks have all completed, from pool \n",
      "24/03/14 19:42:59 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 41989\n",
      "24/03/14 19:42:59 INFO DAGScheduler: ResultStage 5 (runJob at PythonRDD.scala:181) finished in 1.530 s\n",
      "24/03/14 19:42:59 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 19:42:59 INFO YarnScheduler: Killing all running tasks in stage 5: Stage finished\n",
      "24/03/14 19:42:59 INFO DAGScheduler: Job 5 finished: runJob at PythonRDD.scala:181, took 1.541905 s\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = rdd.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "daf89525-88b4-4244-96d9-2219a202f024",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"my_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "267993b3-d726-4b30-8c58-6c2e256ec16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 19:45:19 INFO DAGScheduler: Got job 7 (showString at NativeMethodAccessorImpl.java:0) with 11 output partitions\n",
      "24/03/14 19:45:19 INFO DAGScheduler: Final stage: ResultStage 7 (showString at NativeMethodAccessorImpl.java:0)\n",
      "24/03/14 19:45:19 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 19:45:19 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 19:45:19 INFO DAGScheduler: Submitting ResultStage 7 (*(1) Scan ExistingRDD[_1#67]\n",
      " MapPartitionsRDD[32] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/03/14 19:45:19 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 18.6 KiB, free 365.1 MiB)\n",
      "24/03/14 19:45:19 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 9.8 KiB, free 365.1 MiB)\n",
      "24/03/14 19:45:19 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on master-node:33151 (size: 9.8 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:45:19 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 19:45:19 INFO DAGScheduler: Submitting 11 missing tasks from ResultStage 7 (*(1) Scan ExistingRDD[_1#67]\n",
      " MapPartitionsRDD[32] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))\n",
      "24/03/14 19:45:19 INFO YarnScheduler: Adding task set 7.0 with 11 tasks resource profile 0\n",
      "24/03/14 19:45:19 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 17) (worker-node-1, executor 2, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 19:45:19 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 18) (worker-node-2, executor 1, partition 1, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 19:45:19 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on worker-node-1:44403 (size: 9.8 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:45:19 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on worker-node-2:34115 (size: 9.8 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:45:19 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 19) (worker-node-2, executor 1, partition 2, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 19:45:19 WARN TaskSetManager: Lost task 1.0 in stage 7.0 (TID 18) (worker-node-2 executor 1): java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:88)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:290)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:287)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1597)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "24/03/14 19:45:19 INFO TaskSetManager: Starting task 1.1 in stage 7.0 (TID 20) (worker-node-1, executor 2, partition 1, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 19:45:19 INFO TaskSetManager: Lost task 0.0 in stage 7.0 (TID 17) on worker-node-1, executor 2: java.lang.IllegalStateException (Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.) [duplicate 1]\n",
      "24/03/14 19:45:19 INFO TaskSetManager: Lost task 2.0 in stage 7.0 (TID 19) on worker-node-2, executor 1: java.lang.IllegalStateException (Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.) [duplicate 2]\n",
      "24/03/14 19:45:19 INFO TaskSetManager: Starting task 2.1 in stage 7.0 (TID 21) (worker-node-2, executor 1, partition 2, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 19:45:19 INFO TaskSetManager: Starting task 0.1 in stage 7.0 (TID 22) (worker-node-1, executor 2, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 19:45:19 INFO TaskSetManager: Lost task 1.1 in stage 7.0 (TID 20) on worker-node-1, executor 2: java.lang.IllegalStateException (Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.) [duplicate 3]\n",
      "24/03/14 19:45:19 INFO TaskSetManager: Starting task 1.2 in stage 7.0 (TID 23) (worker-node-2, executor 1, partition 1, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 19:45:19 INFO TaskSetManager: Lost task 2.1 in stage 7.0 (TID 21) on worker-node-2, executor 1: java.lang.IllegalStateException (Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.) [duplicate 4]\n",
      "24/03/14 19:45:19 INFO TaskSetManager: Lost task 0.1 in stage 7.0 (TID 22) on worker-node-1, executor 2: java.lang.IllegalStateException (Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.) [duplicate 5]\n",
      "24/03/14 19:45:19 INFO TaskSetManager: Starting task 0.2 in stage 7.0 (TID 24) (worker-node-1, executor 2, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 19:45:19 INFO TaskSetManager: Lost task 1.2 in stage 7.0 (TID 23) on worker-node-2, executor 1: java.lang.IllegalStateException (Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.) [duplicate 6]\n",
      "24/03/14 19:45:19 INFO TaskSetManager: Starting task 1.3 in stage 7.0 (TID 25) (worker-node-2, executor 1, partition 1, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 19:45:19 INFO TaskSetManager: Starting task 2.2 in stage 7.0 (TID 26) (worker-node-1, executor 2, partition 2, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 19:45:19 INFO TaskSetManager: Lost task 0.2 in stage 7.0 (TID 24) on worker-node-1, executor 2: java.lang.IllegalStateException (Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.) [duplicate 7]\n",
      "24/03/14 19:45:19 INFO TaskSetManager: Starting task 0.3 in stage 7.0 (TID 27) (worker-node-2, executor 1, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 19:45:19 INFO TaskSetManager: Lost task 1.3 in stage 7.0 (TID 25) on worker-node-2, executor 1: java.lang.IllegalStateException (Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.) [duplicate 8]\n",
      "24/03/14 19:45:19 ERROR TaskSetManager: Task 1 in stage 7.0 failed 4 times; aborting job\n",
      "24/03/14 19:45:19 INFO YarnScheduler: Cancelling stage 7\n",
      "24/03/14 19:45:19 INFO YarnScheduler: Killing all running tasks in stage 7: Stage cancelled: Job aborted due to stage failure: Task 1 in stage 7.0 failed 4 times, most recent failure: Lost task 1.3 in stage 7.0 (TID 25) (worker-node-2 executor 1): java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:88)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:290)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:287)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1597)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "Driver stacktrace:\n",
      "24/03/14 19:45:19 INFO YarnScheduler: Stage 7 was cancelled\n",
      "24/03/14 19:45:19 INFO DAGScheduler: ResultStage 7 (showString at NativeMethodAccessorImpl.java:0) failed in 0.309 s due to Job aborted due to stage failure: Task 1 in stage 7.0 failed 4 times, most recent failure: Lost task 1.3 in stage 7.0 (TID 25) (worker-node-2 executor 1): java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:88)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:290)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:287)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1597)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "Driver stacktrace:\n",
      "24/03/14 19:45:19 WARN TaskSetManager: Lost task 2.2 in stage 7.0 (TID 26) (worker-node-1 executor 2): TaskKilled (Stage cancelled: Job aborted due to stage failure: Task 1 in stage 7.0 failed 4 times, most recent failure: Lost task 1.3 in stage 7.0 (TID 25) (worker-node-2 executor 1): java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:88)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:290)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:287)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1597)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "Driver stacktrace:)\n",
      "24/03/14 19:45:19 WARN TaskSetManager: Lost task 0.3 in stage 7.0 (TID 27) (worker-node-2 executor 1): TaskKilled (Stage cancelled: Job aborted due to stage failure: Task 1 in stage 7.0 failed 4 times, most recent failure: Lost task 1.3 in stage 7.0 (TID 25) (worker-node-2 executor 1): java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:88)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:290)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:287)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1597)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "Driver stacktrace:)\n",
      "24/03/14 19:45:19 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool \n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o98.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 7.0 failed 4 times, most recent failure: Lost task 1.3 in stage 7.0 (TID 25) (worker-node-2 executor 1): java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:88)\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:290)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:287)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1597)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\nCaused by: java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:88)\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:290)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:287)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1597)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msqlContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSELECT * FROM my_table\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/dataframe.py:945\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow\u001b[39m(\u001b[38;5;28mself\u001b[39m, n: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, truncate: Union[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, vertical: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    886\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prints the first ``n`` rows to the console.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \n\u001b[1;32m    888\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;124;03m    name | Bob\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 945\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/dataframe.py:963\u001b[0m, in \u001b[0;36mDataFrame._show_string\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m    958\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    959\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(vertical)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m    960\u001b[0m     )\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[0;32m--> 963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o98.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 7.0 failed 4 times, most recent failure: Lost task 1.3 in stage 7.0 (TID 25) (worker-node-2 executor 1): java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:88)\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:290)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:287)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1597)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\nCaused by: java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:88)\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:290)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:287)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1597)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"SELECT * FROM my_table\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0287066-7811-4752-99a7-8dd08f25868c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_1: string]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3caeae6c-8181-4910-b27b-dca012d5261f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 19:43:20 INFO CodeGenerator: Code generated in 15.614654 ms\n",
      "24/03/14 19:43:20 INFO DAGScheduler: Got job 6 (showString at NativeMethodAccessorImpl.java:0) with 11 output partitions\n",
      "24/03/14 19:43:20 INFO DAGScheduler: Final stage: ResultStage 6 (showString at NativeMethodAccessorImpl.java:0)\n",
      "24/03/14 19:43:20 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 19:43:20 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 19:43:20 INFO DAGScheduler: Submitting ResultStage 6 (*(1) Scan ExistingRDD[_1#67]\n",
      " MapPartitionsRDD[32] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/03/14 19:43:20 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 18.6 KiB, free 365.1 MiB)\n",
      "24/03/14 19:43:20 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 9.8 KiB, free 365.1 MiB)\n",
      "24/03/14 19:43:20 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on master-node:33151 (size: 9.8 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:43:20 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 19:43:20 INFO DAGScheduler: Submitting 11 missing tasks from ResultStage 6 (*(1) Scan ExistingRDD[_1#67]\n",
      " MapPartitionsRDD[32] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))\n",
      "24/03/14 19:43:20 INFO YarnScheduler: Adding task set 6.0 with 11 tasks resource profile 0\n",
      "24/03/14 19:43:20 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 9) (worker-node-1, executor 2, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 19:43:20 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 10) (worker-node-2, executor 1, partition 1, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 19:43:20 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on worker-node-2:34115 (size: 9.8 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:43:20 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on worker-node-1:44403 (size: 9.8 KiB, free: 366.3 MiB)\n",
      "24/03/14 19:43:20 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on worker-node-1:44403 (size: 33.1 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:43:20 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 11) (worker-node-2, executor 1, partition 2, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 19:43:20 WARN TaskSetManager: Lost task 1.0 in stage 6.0 (TID 10) (worker-node-2 executor 1): java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:88)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:290)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:287)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1597)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "24/03/14 19:43:20 INFO TaskSetManager: Starting task 1.1 in stage 6.0 (TID 12) (worker-node-2, executor 1, partition 1, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 19:43:20 INFO TaskSetManager: Lost task 2.0 in stage 6.0 (TID 11) on worker-node-2, executor 1: java.lang.IllegalStateException (Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.) [duplicate 1]\n",
      "24/03/14 19:43:21 INFO TaskSetManager: Lost task 1.1 in stage 6.0 (TID 12) on worker-node-2, executor 1: java.lang.IllegalStateException (Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.) [duplicate 2]\n",
      "24/03/14 19:43:21 INFO TaskSetManager: Starting task 1.2 in stage 6.0 (TID 13) (worker-node-2, executor 1, partition 1, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 19:43:21 INFO TaskSetManager: Starting task 2.1 in stage 6.0 (TID 14) (worker-node-2, executor 1, partition 2, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 19:43:21 INFO TaskSetManager: Lost task 1.2 in stage 6.0 (TID 13) on worker-node-2, executor 1: java.lang.IllegalStateException (Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.) [duplicate 3]\n",
      "24/03/14 19:43:21 INFO TaskSetManager: Starting task 1.3 in stage 6.0 (TID 15) (worker-node-2, executor 1, partition 1, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 19:43:21 INFO TaskSetManager: Lost task 2.1 in stage 6.0 (TID 14) on worker-node-2, executor 1: java.lang.IllegalStateException (Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.) [duplicate 4]\n",
      "24/03/14 19:43:21 INFO TaskSetManager: Starting task 2.2 in stage 6.0 (TID 16) (worker-node-2, executor 1, partition 2, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 19:43:21 INFO TaskSetManager: Lost task 1.3 in stage 6.0 (TID 15) on worker-node-2, executor 1: java.lang.IllegalStateException (Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.) [duplicate 5]\n",
      "24/03/14 19:43:21 ERROR TaskSetManager: Task 1 in stage 6.0 failed 4 times; aborting job\n",
      "24/03/14 19:43:21 INFO YarnScheduler: Cancelling stage 6\n",
      "24/03/14 19:43:21 INFO YarnScheduler: Killing all running tasks in stage 6: Stage cancelled: Job aborted due to stage failure: Task 1 in stage 6.0 failed 4 times, most recent failure: Lost task 1.3 in stage 6.0 (TID 15) (worker-node-2 executor 1): java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:88)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:290)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:287)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1597)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "Driver stacktrace:\n",
      "24/03/14 19:43:21 INFO YarnScheduler: Stage 6 was cancelled\n",
      "24/03/14 19:43:21 INFO DAGScheduler: ResultStage 6 (showString at NativeMethodAccessorImpl.java:0) failed in 0.396 s due to Job aborted due to stage failure: Task 1 in stage 6.0 failed 4 times, most recent failure: Lost task 1.3 in stage 6.0 (TID 15) (worker-node-2 executor 1): java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:88)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:290)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:287)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1597)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "Driver stacktrace:\n",
      "24/03/14 19:43:21 WARN TaskSetManager: Lost task 2.2 in stage 6.0 (TID 16) (worker-node-2 executor 1): TaskKilled (Stage cancelled: Job aborted due to stage failure: Task 1 in stage 6.0 failed 4 times, most recent failure: Lost task 1.3 in stage 6.0 (TID 15) (worker-node-2 executor 1): java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:88)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:290)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:287)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1597)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "Driver stacktrace:)\n",
      "[Stage 6:>                                                         (0 + 1) / 11]\r"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o88.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 6.0 failed 4 times, most recent failure: Lost task 1.3 in stage 6.0 (TID 15) (worker-node-2 executor 1): java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:88)\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:290)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:287)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1597)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\nCaused by: java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:88)\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:290)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:287)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1597)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/dataframe.py:945\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow\u001b[39m(\u001b[38;5;28mself\u001b[39m, n: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, truncate: Union[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, vertical: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    886\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prints the first ``n`` rows to the console.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \n\u001b[1;32m    888\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;124;03m    name | Bob\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 945\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/dataframe.py:963\u001b[0m, in \u001b[0;36mDataFrame._show_string\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m    958\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    959\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(vertical)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m    960\u001b[0m     )\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[0;32m--> 963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o88.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 6.0 failed 4 times, most recent failure: Lost task 1.3 in stage 6.0 (TID 15) (worker-node-2 executor 1): java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:88)\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:290)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:287)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1597)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\nCaused by: java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:88)\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:290)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:287)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1597)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 19:43:23 WARN TaskSetManager: Lost task 0.0 in stage 6.0 (TID 9) (worker-node-1 executor 2): TaskKilled (Stage cancelled: Job aborted due to stage failure: Task 1 in stage 6.0 failed 4 times, most recent failure: Lost task 1.3 in stage 6.0 (TID 15) (worker-node-2 executor 1): java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:88)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:290)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:287)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1597)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "Driver stacktrace:)\n",
      "24/03/14 19:43:23 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool \n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1708cd-6653-4323-b99b-ba7c2a63ffae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32816216-3681-4487-9c67-af6e13fc7aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(directory_path + 'TRAAAAW128F429D538.asci', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f72586dd-41ed-4710-8c15-6cbbe47debcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use Spark to list files in HDFS directory\n",
    "# hdfs_files = spark_session._jvm.org.apache.hadoop.fs.FileSystem.get(spark._jsc.hadoopConfiguration()) \\\n",
    "#     .listStatus(spark_session._jvm.org.apache.hadoop.fs.Path(directory_path))\n",
    "#path = 'hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_songs/TRAAAAW128F429D538_songs.asci'\n",
    "path = 'hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_songs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1333b60e-ef05-446a-86ff-7c0cbcd0a7c7",
   "metadata": {},
   "source": [
    "# 1) Saving the paths to the HDF5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "82538b17-fdbc-4c52-9c59-23e67626d417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_h5_file_paths_hdfs(spark, hdfs_directory_path):\n",
    "    h5_file_paths = []\n",
    "\n",
    "    # Use Spark to list files in HDFS directory\n",
    "    hdfs_files = spark._jvm.org.apache.hadoop.fs.FileSystem.get(spark._jsc.hadoopConfiguration()) \\\n",
    "        .listStatus(spark._jvm.org.apache.hadoop.fs.Path(hdfs_directory_path))\n",
    "\n",
    "    # Extract file paths from HDFS file status\n",
    "    for hdfs_file_status in hdfs_files:\n",
    "        file_path = hdfs_file_status.getPath().toString()\n",
    "\n",
    "        if hdfs_file_status.isDirectory():\n",
    "            # If it's a directory, recursively gather paths\n",
    "            h5_file_paths.extend(get_h5_file_paths_hdfs(spark, file_path))\n",
    "        elif file_path.endswith(\".asci\"):\n",
    "            # If it's an HDF5 file, add to the list\n",
    "            h5_file_paths.append(file_path)\n",
    "\n",
    "    return h5_file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b1292d02-c77a-47b4-b0e1-b62f475f8679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 HDF5 file paths gathered (HDFS)\n",
      "hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_songs/TRAAAAW128F429D538_songs.asci\n",
      "hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_songs/TRAAABD128F429CF47_songs.asci\n",
      "hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_songs/TRAAADZ128F9348C2E_songs.asci\n",
      "hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_songs/TRAAAEF128F4273421_songs.asci\n",
      "hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_songs/TRAAAFD128F92F423A_songs.asci\n",
      "hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_songs/TRAAAMO128F1481E7F_songs.asci\n",
      "hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_songs/TRAAAMQ128F1460CD3_songs.asci\n",
      "hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_songs/TRAAAPK128E0786D96_songs.asci\n",
      "hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_songs/TRAAARJ128F9320760_songs.asci\n",
      "hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_songs/TRAAAVG12903CFA543_songs.asci\n",
      "hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_songs/TRAAAVO128F93133D4_songs.asci\n"
     ]
    }
   ],
   "source": [
    "h5_file_paths = get_h5_file_paths_hdfs(spark_session, path)\n",
    "\n",
    "print('{} HDF5 file paths gathered (HDFS)'.format(len(h5_file_paths)))\n",
    "for file_path in h5_file_paths[:50]:\n",
    "    print(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa39ddd-8486-42f6-86fd-dc7741270519",
   "metadata": {},
   "source": [
    "# 2) List h5_file_paths is converted to RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a776fd3f-ad71-4b9e-96a0-0d37cc0aad7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_songs/TRAAAAW128F429D538_songs.asci',\n",
       " 'hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_songs/TRAAABD128F429CF47_songs.asci',\n",
       " 'hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_songs/TRAAADZ128F9348C2E_songs.asci',\n",
       " 'hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_songs/TRAAAEF128F4273421_songs.asci',\n",
       " 'hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_songs/TRAAAFD128F92F423A_songs.asci',\n",
       " 'hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_songs/TRAAAMO128F1481E7F_songs.asci',\n",
       " 'hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_songs/TRAAAMQ128F1460CD3_songs.asci',\n",
       " 'hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_songs/TRAAAPK128E0786D96_songs.asci',\n",
       " 'hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_songs/TRAAARJ128F9320760_songs.asci',\n",
       " 'hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_songs/TRAAAVG12903CFA543_songs.asci',\n",
       " 'hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_songs/TRAAAVO128F93133D4_songs.asci']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5_file_paths[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cd1391e3-6cfe-4623-bc8e-d21ac0212b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[307] at readRDDFromFile at PythonRDD.scala:289"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_paths = spark_context.parallelize(h5_file_paths)\n",
    "file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dc5b8a3d-e994-4f86-8feb-e66f5105e5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 21:24:14 INFO SparkContext: Starting job: runJob at PythonRDD.scala:181\n",
      "24/03/14 21:24:14 INFO DAGScheduler: Got job 65 (runJob at PythonRDD.scala:181) with 1 output partitions\n",
      "24/03/14 21:24:14 INFO DAGScheduler: Final stage: ResultStage 70 (runJob at PythonRDD.scala:181)\n",
      "24/03/14 21:24:14 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 21:24:14 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 21:24:14 INFO DAGScheduler: Submitting ResultStage 70 (PythonRDD[308] at RDD at PythonRDD.scala:53), which has no missing parents\n",
      "24/03/14 21:24:14 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 5.9 KiB, free 362.6 MiB)\n",
      "24/03/14 21:24:14 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 362.6 MiB)\n",
      "24/03/14 21:24:14 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on master-node:35375 (size: 3.8 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:24:14 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 21:24:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 70 (PythonRDD[308] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))\n",
      "24/03/14 21:24:14 INFO YarnScheduler: Adding task set 70.0 with 1 tasks resource profile 0\n",
      "24/03/14 21:24:14 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 79) (worker-node-2, executor 2, partition 0, PROCESS_LOCAL, 8162 bytes) \n",
      "24/03/14 21:24:14 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on worker-node-2:39037 (size: 3.8 KiB, free: 366.0 MiB)\n",
      "24/03/14 21:24:14 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 79) in 50 ms on worker-node-2 (executor 2) (1/1)\n",
      "24/03/14 21:24:14 INFO YarnScheduler: Removed TaskSet 70.0, whose tasks have all completed, from pool \n",
      "24/03/14 21:24:14 INFO DAGScheduler: ResultStage 70 (runJob at PythonRDD.scala:181) finished in 0.060 s\n",
      "24/03/14 21:24:14 INFO DAGScheduler: Job 65 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 21:24:14 INFO YarnScheduler: Killing all running tasks in stage 70: Stage finished\n",
      "24/03/14 21:24:14 INFO DAGScheduler: Job 65 finished: runJob at PythonRDD.scala:181, took 0.064152 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_songs/TRAAAAW128F429D538_songs.asci'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_first = file_paths.first()\n",
    "file_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c5a877e2-6301-4dfe-8716-8dd0f4bd4d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 21:26:01 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 344.9 KiB, free 362.9 MiB)\n",
      "24/03/14 21:26:01 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 33.3 KiB, free 362.9 MiB)\n",
      "24/03/14 21:26:01 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on master-node:35375 (size: 33.3 KiB, free: 366.0 MiB)\n",
      "24/03/14 21:26:01 INFO SparkContext: Created broadcast 102 from wholeTextFiles at NativeMethodAccessorImpl.java:0\n",
      "24/03/14 21:26:01 INFO FileInputFormat: Total input files to process : 11\n",
      "24/03/14 21:26:01 INFO FileInputFormat: Total input files to process : 11\n",
      "24/03/14 21:26:01 INFO SparkContext: Starting job: collect at /tmp/ipykernel_112987/458329310.py:1\n",
      "24/03/14 21:26:01 INFO DAGScheduler: Got job 66 (collect at /tmp/ipykernel_112987/458329310.py:1) with 2 output partitions\n",
      "24/03/14 21:26:01 INFO DAGScheduler: Final stage: ResultStage 71 (collect at /tmp/ipykernel_112987/458329310.py:1)\n",
      "24/03/14 21:26:01 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 21:26:01 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 21:26:01 INFO DAGScheduler: Submitting ResultStage 71 (PythonRDD[311] at collect at /tmp/ipykernel_112987/458329310.py:1), which has no missing parents\n",
      "24/03/14 21:26:01 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 7.3 KiB, free 362.9 MiB)\n",
      "24/03/14 21:26:01 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 362.9 MiB)\n",
      "24/03/14 21:26:01 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on master-node:35375 (size: 4.5 KiB, free: 366.0 MiB)\n",
      "24/03/14 21:26:01 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 21:26:01 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 71 (PythonRDD[311] at collect at /tmp/ipykernel_112987/458329310.py:1) (first 15 tasks are for partitions Vector(0, 1))\n",
      "24/03/14 21:26:01 INFO YarnScheduler: Adding task set 71.0 with 2 tasks resource profile 0\n",
      "24/03/14 21:26:01 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 80) (worker-node-2, executor 2, partition 0, NODE_LOCAL, 8424 bytes) \n",
      "24/03/14 21:26:01 INFO TaskSetManager: Starting task 1.0 in stage 71.0 (TID 81) (worker-node-1, executor 1, partition 1, PROCESS_LOCAL, 8304 bytes) \n",
      "24/03/14 21:26:01 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on worker-node-2:39037 (size: 4.5 KiB, free: 366.0 MiB)\n",
      "24/03/14 21:26:01 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on worker-node-1:45391 (size: 4.5 KiB, free: 366.1 MiB)\n",
      "24/03/14 21:26:01 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on worker-node-2:39037 (size: 33.3 KiB, free: 366.0 MiB)\n",
      "24/03/14 21:26:01 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on worker-node-1:45391 (size: 33.3 KiB, free: 366.0 MiB)\n",
      "24/03/14 21:26:01 INFO TaskSetManager: Finished task 1.0 in stage 71.0 (TID 81) in 111 ms on worker-node-1 (executor 1) (1/2)\n",
      "24/03/14 21:26:01 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 80) in 114 ms on worker-node-2 (executor 2) (2/2)\n",
      "24/03/14 21:26:01 INFO YarnScheduler: Removed TaskSet 71.0, whose tasks have all completed, from pool \n",
      "24/03/14 21:26:01 INFO DAGScheduler: ResultStage 71 (collect at /tmp/ipykernel_112987/458329310.py:1) finished in 0.123 s\n",
      "24/03/14 21:26:01 INFO DAGScheduler: Job 66 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 21:26:01 INFO YarnScheduler: Killing all running tasks in stage 71: Stage finished\n",
      "24/03/14 21:26:01 INFO DAGScheduler: Job 66 finished: collect at /tmp/ipykernel_112987/458329310.py:1, took 0.129444 s\n"
     ]
    }
   ],
   "source": [
    "file_paths = spark_context.wholeTextFiles(path).map(lambda x: x[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "240d7005-be56-491a-9ab1-6e6171a19597",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 21:26:15 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 358.7 KiB, free 362.5 MiB)\n",
      "24/03/14 21:26:15 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 33.1 KiB, free 362.5 MiB)\n",
      "24/03/14 21:26:15 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on master-node:35375 (size: 33.1 KiB, free: 366.0 MiB)\n",
      "24/03/14 21:26:15 INFO SparkContext: Created broadcast 104 from textFile at NativeMethodAccessorImpl.java:0\n",
      "24/03/14 21:26:15 INFO FileInputFormat: Total input files to process : 1\n",
      "24/03/14 21:26:15 INFO SparkContext: Starting job: collect at /tmp/ipykernel_112987/694392133.py:6\n",
      "24/03/14 21:26:15 INFO DAGScheduler: Got job 67 (collect at /tmp/ipykernel_112987/694392133.py:6) with 2 output partitions\n",
      "24/03/14 21:26:15 INFO DAGScheduler: Final stage: ResultStage 72 (collect at /tmp/ipykernel_112987/694392133.py:6)\n",
      "24/03/14 21:26:15 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 21:26:15 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 21:26:15 INFO DAGScheduler: Submitting ResultStage 72 (PythonRDD[314] at collect at /tmp/ipykernel_112987/694392133.py:6), which has no missing parents\n",
      "24/03/14 21:26:15 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 7.7 KiB, free 362.5 MiB)\n",
      "24/03/14 21:26:15 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 362.5 MiB)\n",
      "24/03/14 21:26:15 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on master-node:35375 (size: 4.8 KiB, free: 366.0 MiB)\n",
      "24/03/14 21:26:15 INFO SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 21:26:15 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 72 (PythonRDD[314] at collect at /tmp/ipykernel_112987/694392133.py:6) (first 15 tasks are for partitions Vector(0, 1))\n",
      "24/03/14 21:26:15 INFO YarnScheduler: Adding task set 72.0 with 2 tasks resource profile 0\n",
      "24/03/14 21:26:15 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 82) (worker-node-1, executor 1, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 21:26:15 INFO TaskSetManager: Starting task 1.0 in stage 72.0 (TID 83) (worker-node-2, executor 2, partition 1, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 21:26:15 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on worker-node-2:39037 (size: 4.8 KiB, free: 366.0 MiB)\n",
      "24/03/14 21:26:15 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on worker-node-1:45391 (size: 4.8 KiB, free: 366.0 MiB)\n",
      "24/03/14 21:26:15 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on worker-node-2:39037 (size: 33.1 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:26:15 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on worker-node-1:45391 (size: 33.1 KiB, free: 366.0 MiB)\n",
      "24/03/14 21:26:15 INFO TaskSetManager: Finished task 1.0 in stage 72.0 (TID 83) in 64 ms on worker-node-2 (executor 2) (1/2)\n",
      "24/03/14 21:26:15 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 82) in 69 ms on worker-node-1 (executor 1) (2/2)\n",
      "24/03/14 21:26:15 INFO YarnScheduler: Removed TaskSet 72.0, whose tasks have all completed, from pool \n",
      "24/03/14 21:26:15 INFO DAGScheduler: ResultStage 72 (collect at /tmp/ipykernel_112987/694392133.py:6) finished in 0.080 s\n",
      "24/03/14 21:26:15 INFO DAGScheduler: Job 67 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 21:26:15 INFO YarnScheduler: Killing all running tasks in stage 72: Stage finished\n",
      "24/03/14 21:26:15 INFO DAGScheduler: Job 67 finished: collect at /tmp/ipykernel_112987/694392133.py:6, took 0.083359 s\n",
      "24/03/14 21:26:15 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 358.7 KiB, free 362.1 MiB)\n",
      "24/03/14 21:26:15 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 33.1 KiB, free 362.1 MiB)\n",
      "24/03/14 21:26:15 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on master-node:35375 (size: 33.1 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:26:15 INFO SparkContext: Created broadcast 106 from textFile at NativeMethodAccessorImpl.java:0\n",
      "24/03/14 21:26:15 INFO FileInputFormat: Total input files to process : 1\n",
      "24/03/14 21:26:15 INFO SparkContext: Starting job: collect at /tmp/ipykernel_112987/694392133.py:6\n",
      "24/03/14 21:26:15 INFO DAGScheduler: Got job 68 (collect at /tmp/ipykernel_112987/694392133.py:6) with 2 output partitions\n",
      "24/03/14 21:26:15 INFO DAGScheduler: Final stage: ResultStage 73 (collect at /tmp/ipykernel_112987/694392133.py:6)\n",
      "24/03/14 21:26:15 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 21:26:15 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 21:26:15 INFO DAGScheduler: Submitting ResultStage 73 (PythonRDD[317] at collect at /tmp/ipykernel_112987/694392133.py:6), which has no missing parents\n",
      "24/03/14 21:26:15 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 7.7 KiB, free 362.1 MiB)\n",
      "24/03/14 21:26:15 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 362.1 MiB)\n",
      "24/03/14 21:26:15 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on master-node:35375 (size: 4.8 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:26:15 INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 21:26:15 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 73 (PythonRDD[317] at collect at /tmp/ipykernel_112987/694392133.py:6) (first 15 tasks are for partitions Vector(0, 1))\n",
      "24/03/14 21:26:15 INFO YarnScheduler: Adding task set 73.0 with 2 tasks resource profile 0\n",
      "24/03/14 21:26:15 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 84) (worker-node-2, executor 2, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 21:26:15 INFO TaskSetManager: Starting task 1.0 in stage 73.0 (TID 85) (worker-node-1, executor 1, partition 1, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 21:26:15 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on worker-node-1:45391 (size: 4.8 KiB, free: 366.0 MiB)\n",
      "24/03/14 21:26:15 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on worker-node-2:39037 (size: 4.8 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:26:15 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on worker-node-1:45391 (size: 33.1 KiB, free: 366.0 MiB)\n",
      "24/03/14 21:26:15 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on worker-node-2:39037 (size: 33.1 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:26:15 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 84) in 47 ms on worker-node-2 (executor 2) (1/2)\n",
      "24/03/14 21:26:15 INFO TaskSetManager: Finished task 1.0 in stage 73.0 (TID 85) in 54 ms on worker-node-1 (executor 1) (2/2)\n",
      "24/03/14 21:26:15 INFO YarnScheduler: Removed TaskSet 73.0, whose tasks have all completed, from pool \n",
      "24/03/14 21:26:15 INFO DAGScheduler: ResultStage 73 (collect at /tmp/ipykernel_112987/694392133.py:6) finished in 0.063 s\n",
      "24/03/14 21:26:15 INFO DAGScheduler: Job 68 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 21:26:15 INFO YarnScheduler: Killing all running tasks in stage 73: Stage finished\n",
      "24/03/14 21:26:15 INFO DAGScheduler: Job 68 finished: collect at /tmp/ipykernel_112987/694392133.py:6, took 0.067090 s\n",
      "24/03/14 21:26:15 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 358.7 KiB, free 361.7 MiB)\n",
      "24/03/14 21:26:15 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 33.1 KiB, free 361.7 MiB)\n",
      "24/03/14 21:26:15 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on master-node:35375 (size: 33.1 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:26:15 INFO SparkContext: Created broadcast 108 from textFile at NativeMethodAccessorImpl.java:0\n",
      "24/03/14 21:26:15 INFO FileInputFormat: Total input files to process : 1\n",
      "24/03/14 21:26:15 INFO SparkContext: Starting job: collect at /tmp/ipykernel_112987/694392133.py:6\n",
      "24/03/14 21:26:15 INFO DAGScheduler: Got job 69 (collect at /tmp/ipykernel_112987/694392133.py:6) with 2 output partitions\n",
      "24/03/14 21:26:15 INFO DAGScheduler: Final stage: ResultStage 74 (collect at /tmp/ipykernel_112987/694392133.py:6)\n",
      "24/03/14 21:26:15 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 21:26:15 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 21:26:15 INFO DAGScheduler: Submitting ResultStage 74 (PythonRDD[320] at collect at /tmp/ipykernel_112987/694392133.py:6), which has no missing parents\n",
      "24/03/14 21:26:15 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 7.7 KiB, free 361.7 MiB)\n",
      "24/03/14 21:26:15 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 361.7 MiB)\n",
      "24/03/14 21:26:15 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on master-node:35375 (size: 4.8 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:26:15 INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 21:26:15 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 74 (PythonRDD[320] at collect at /tmp/ipykernel_112987/694392133.py:6) (first 15 tasks are for partitions Vector(0, 1))\n",
      "24/03/14 21:26:15 INFO YarnScheduler: Adding task set 74.0 with 2 tasks resource profile 0\n",
      "24/03/14 21:26:15 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 86) (worker-node-1, executor 1, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 21:26:15 INFO TaskSetManager: Starting task 1.0 in stage 74.0 (TID 87) (worker-node-2, executor 2, partition 1, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 21:26:15 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on worker-node-1:45391 (size: 4.8 KiB, free: 366.0 MiB)\n",
      "24/03/14 21:26:15 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on worker-node-2:39037 (size: 4.8 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:26:15 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on worker-node-1:45391 (size: 33.1 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:26:15 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on worker-node-2:39037 (size: 33.1 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:26:15 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 86) in 84 ms on worker-node-1 (executor 1) (1/2)\n",
      "24/03/14 21:26:15 INFO TaskSetManager: Finished task 1.0 in stage 74.0 (TID 87) in 91 ms on worker-node-2 (executor 2) (2/2)\n",
      "24/03/14 21:26:15 INFO YarnScheduler: Removed TaskSet 74.0, whose tasks have all completed, from pool \n",
      "24/03/14 21:26:15 INFO DAGScheduler: ResultStage 74 (collect at /tmp/ipykernel_112987/694392133.py:6) finished in 0.102 s\n",
      "24/03/14 21:26:15 INFO DAGScheduler: Job 69 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 21:26:15 INFO YarnScheduler: Killing all running tasks in stage 74: Stage finished\n",
      "24/03/14 21:26:15 INFO DAGScheduler: Job 69 finished: collect at /tmp/ipykernel_112987/694392133.py:6, took 0.104646 s\n",
      "24/03/14 21:26:15 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 358.7 KiB, free 361.3 MiB)\n",
      "24/03/14 21:26:15 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 33.1 KiB, free 361.3 MiB)\n",
      "24/03/14 21:26:15 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on master-node:35375 (size: 33.1 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:26:15 INFO SparkContext: Created broadcast 110 from textFile at NativeMethodAccessorImpl.java:0\n",
      "24/03/14 21:26:15 INFO FileInputFormat: Total input files to process : 1\n",
      "24/03/14 21:26:15 INFO SparkContext: Starting job: collect at /tmp/ipykernel_112987/694392133.py:6\n",
      "24/03/14 21:26:15 INFO DAGScheduler: Got job 70 (collect at /tmp/ipykernel_112987/694392133.py:6) with 2 output partitions\n",
      "24/03/14 21:26:15 INFO DAGScheduler: Final stage: ResultStage 75 (collect at /tmp/ipykernel_112987/694392133.py:6)\n",
      "24/03/14 21:26:15 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 21:26:15 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 21:26:15 INFO DAGScheduler: Submitting ResultStage 75 (PythonRDD[323] at collect at /tmp/ipykernel_112987/694392133.py:6), which has no missing parents\n",
      "24/03/14 21:26:15 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 7.7 KiB, free 361.3 MiB)\n",
      "24/03/14 21:26:15 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 361.3 MiB)\n",
      "24/03/14 21:26:15 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on master-node:35375 (size: 4.8 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:26:15 INFO SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 21:26:15 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 75 (PythonRDD[323] at collect at /tmp/ipykernel_112987/694392133.py:6) (first 15 tasks are for partitions Vector(0, 1))\n",
      "24/03/14 21:26:15 INFO YarnScheduler: Adding task set 75.0 with 2 tasks resource profile 0\n",
      "24/03/14 21:26:15 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 88) (worker-node-2, executor 2, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 21:26:15 INFO TaskSetManager: Starting task 1.0 in stage 75.0 (TID 89) (worker-node-1, executor 1, partition 1, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 21:26:15 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on worker-node-1:45391 (size: 4.8 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:26:15 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on worker-node-2:39037 (size: 4.8 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:26:15 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on worker-node-1:45391 (size: 33.1 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:26:15 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on worker-node-2:39037 (size: 33.1 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:26:16 INFO TaskSetManager: Finished task 1.0 in stage 75.0 (TID 89) in 51 ms on worker-node-1 (executor 1) (1/2)\n",
      "24/03/14 21:26:16 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 88) in 113 ms on worker-node-2 (executor 2) (2/2)\n",
      "24/03/14 21:26:16 INFO YarnScheduler: Removed TaskSet 75.0, whose tasks have all completed, from pool \n",
      "24/03/14 21:26:16 INFO DAGScheduler: ResultStage 75 (collect at /tmp/ipykernel_112987/694392133.py:6) finished in 0.120 s\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Job 70 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 21:26:16 INFO YarnScheduler: Killing all running tasks in stage 75: Stage finished\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Job 70 finished: collect at /tmp/ipykernel_112987/694392133.py:6, took 0.123628 s\n",
      "24/03/14 21:26:16 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 358.7 KiB, free 360.9 MiB)\n",
      "24/03/14 21:26:16 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 33.1 KiB, free 360.9 MiB)\n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on master-node:35375 (size: 33.1 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:26:16 INFO SparkContext: Created broadcast 112 from textFile at NativeMethodAccessorImpl.java:0\n",
      "24/03/14 21:26:16 INFO FileInputFormat: Total input files to process : 1\n",
      "24/03/14 21:26:16 INFO SparkContext: Starting job: collect at /tmp/ipykernel_112987/694392133.py:6\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Got job 71 (collect at /tmp/ipykernel_112987/694392133.py:6) with 2 output partitions\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Final stage: ResultStage 76 (collect at /tmp/ipykernel_112987/694392133.py:6)\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Submitting ResultStage 76 (PythonRDD[326] at collect at /tmp/ipykernel_112987/694392133.py:6), which has no missing parents\n",
      "24/03/14 21:26:16 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 7.7 KiB, free 360.9 MiB)\n",
      "24/03/14 21:26:16 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 360.9 MiB)\n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on master-node:35375 (size: 4.8 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:26:16 INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 76 (PythonRDD[326] at collect at /tmp/ipykernel_112987/694392133.py:6) (first 15 tasks are for partitions Vector(0, 1))\n",
      "24/03/14 21:26:16 INFO YarnScheduler: Adding task set 76.0 with 2 tasks resource profile 0\n",
      "24/03/14 21:26:16 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 90) (worker-node-2, executor 2, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 21:26:16 INFO TaskSetManager: Starting task 1.0 in stage 76.0 (TID 91) (worker-node-1, executor 1, partition 1, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on worker-node-1:45391 (size: 4.8 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on worker-node-2:39037 (size: 4.8 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on worker-node-2:39037 (size: 33.1 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on worker-node-1:45391 (size: 33.1 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:26:16 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 90) in 59 ms on worker-node-2 (executor 2) (1/2)\n",
      "24/03/14 21:26:16 INFO TaskSetManager: Finished task 1.0 in stage 76.0 (TID 91) in 68 ms on worker-node-1 (executor 1) (2/2)\n",
      "24/03/14 21:26:16 INFO YarnScheduler: Removed TaskSet 76.0, whose tasks have all completed, from pool \n",
      "24/03/14 21:26:16 INFO DAGScheduler: ResultStage 76 (collect at /tmp/ipykernel_112987/694392133.py:6) finished in 0.076 s\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Job 71 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 21:26:16 INFO YarnScheduler: Killing all running tasks in stage 76: Stage finished\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Job 71 finished: collect at /tmp/ipykernel_112987/694392133.py:6, took 0.080423 s\n",
      "24/03/14 21:26:16 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 358.7 KiB, free 360.5 MiB)\n",
      "24/03/14 21:26:16 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 33.1 KiB, free 360.5 MiB)\n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on master-node:35375 (size: 33.1 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:26:16 INFO SparkContext: Created broadcast 114 from textFile at NativeMethodAccessorImpl.java:0\n",
      "24/03/14 21:26:16 INFO FileInputFormat: Total input files to process : 1\n",
      "24/03/14 21:26:16 INFO SparkContext: Starting job: collect at /tmp/ipykernel_112987/694392133.py:6\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Got job 72 (collect at /tmp/ipykernel_112987/694392133.py:6) with 2 output partitions\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Final stage: ResultStage 77 (collect at /tmp/ipykernel_112987/694392133.py:6)\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Submitting ResultStage 77 (PythonRDD[329] at collect at /tmp/ipykernel_112987/694392133.py:6), which has no missing parents\n",
      "24/03/14 21:26:16 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 7.7 KiB, free 360.5 MiB)\n",
      "24/03/14 21:26:16 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 360.5 MiB)\n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on master-node:35375 (size: 4.8 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:26:16 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 77 (PythonRDD[329] at collect at /tmp/ipykernel_112987/694392133.py:6) (first 15 tasks are for partitions Vector(0, 1))\n",
      "24/03/14 21:26:16 INFO YarnScheduler: Adding task set 77.0 with 2 tasks resource profile 0\n",
      "24/03/14 21:26:16 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 92) (worker-node-1, executor 1, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 21:26:16 INFO TaskSetManager: Starting task 1.0 in stage 77.0 (TID 93) (worker-node-2, executor 2, partition 1, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on worker-node-2:39037 (size: 4.8 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on worker-node-1:45391 (size: 4.8 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on worker-node-1:45391 (size: 33.1 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on worker-node-2:39037 (size: 33.1 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:26:16 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 92) in 87 ms on worker-node-1 (executor 1) (1/2)\n",
      "24/03/14 21:26:16 INFO TaskSetManager: Finished task 1.0 in stage 77.0 (TID 93) in 92 ms on worker-node-2 (executor 2) (2/2)\n",
      "24/03/14 21:26:16 INFO YarnScheduler: Removed TaskSet 77.0, whose tasks have all completed, from pool \n",
      "24/03/14 21:26:16 INFO DAGScheduler: ResultStage 77 (collect at /tmp/ipykernel_112987/694392133.py:6) finished in 0.100 s\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Job 72 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 21:26:16 INFO YarnScheduler: Killing all running tasks in stage 77: Stage finished\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Job 72 finished: collect at /tmp/ipykernel_112987/694392133.py:6, took 0.101846 s\n",
      "24/03/14 21:26:16 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 358.7 KiB, free 360.2 MiB)\n",
      "24/03/14 21:26:16 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 33.1 KiB, free 360.1 MiB)\n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on master-node:35375 (size: 33.1 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:16 INFO SparkContext: Created broadcast 116 from textFile at NativeMethodAccessorImpl.java:0\n",
      "24/03/14 21:26:16 INFO FileInputFormat: Total input files to process : 1\n",
      "24/03/14 21:26:16 INFO SparkContext: Starting job: collect at /tmp/ipykernel_112987/694392133.py:6\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Got job 73 (collect at /tmp/ipykernel_112987/694392133.py:6) with 2 output partitions\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Final stage: ResultStage 78 (collect at /tmp/ipykernel_112987/694392133.py:6)\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Submitting ResultStage 78 (PythonRDD[332] at collect at /tmp/ipykernel_112987/694392133.py:6), which has no missing parents\n",
      "24/03/14 21:26:16 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 7.7 KiB, free 360.1 MiB)\n",
      "24/03/14 21:26:16 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 360.1 MiB)\n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on master-node:35375 (size: 4.8 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:16 INFO SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 78 (PythonRDD[332] at collect at /tmp/ipykernel_112987/694392133.py:6) (first 15 tasks are for partitions Vector(0, 1))\n",
      "24/03/14 21:26:16 INFO YarnScheduler: Adding task set 78.0 with 2 tasks resource profile 0\n",
      "24/03/14 21:26:16 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 94) (worker-node-2, executor 2, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 21:26:16 INFO TaskSetManager: Starting task 1.0 in stage 78.0 (TID 95) (worker-node-1, executor 1, partition 1, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on worker-node-1:45391 (size: 4.8 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on worker-node-2:39037 (size: 4.8 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on worker-node-1:45391 (size: 33.1 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on worker-node-2:39037 (size: 33.1 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:16 INFO TaskSetManager: Finished task 1.0 in stage 78.0 (TID 95) in 49 ms on worker-node-1 (executor 1) (1/2)\n",
      "24/03/14 21:26:16 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 94) in 60 ms on worker-node-2 (executor 2) (2/2)\n",
      "24/03/14 21:26:16 INFO YarnScheduler: Removed TaskSet 78.0, whose tasks have all completed, from pool \n",
      "24/03/14 21:26:16 INFO DAGScheduler: ResultStage 78 (collect at /tmp/ipykernel_112987/694392133.py:6) finished in 0.066 s\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Job 73 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 21:26:16 INFO YarnScheduler: Killing all running tasks in stage 78: Stage finished\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Job 73 finished: collect at /tmp/ipykernel_112987/694392133.py:6, took 0.068486 s\n",
      "24/03/14 21:26:16 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 358.7 KiB, free 359.8 MiB)\n",
      "24/03/14 21:26:16 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 33.1 KiB, free 359.7 MiB)\n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on master-node:35375 (size: 33.1 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:16 INFO SparkContext: Created broadcast 118 from textFile at NativeMethodAccessorImpl.java:0\n",
      "24/03/14 21:26:16 INFO FileInputFormat: Total input files to process : 1\n",
      "24/03/14 21:26:16 INFO SparkContext: Starting job: collect at /tmp/ipykernel_112987/694392133.py:6\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Got job 74 (collect at /tmp/ipykernel_112987/694392133.py:6) with 2 output partitions\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Final stage: ResultStage 79 (collect at /tmp/ipykernel_112987/694392133.py:6)\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Submitting ResultStage 79 (PythonRDD[335] at collect at /tmp/ipykernel_112987/694392133.py:6), which has no missing parents\n",
      "24/03/14 21:26:16 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 7.7 KiB, free 359.7 MiB)\n",
      "24/03/14 21:26:16 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 359.7 MiB)\n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on master-node:35375 (size: 4.8 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:16 INFO SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 79 (PythonRDD[335] at collect at /tmp/ipykernel_112987/694392133.py:6) (first 15 tasks are for partitions Vector(0, 1))\n",
      "24/03/14 21:26:16 INFO YarnScheduler: Adding task set 79.0 with 2 tasks resource profile 0\n",
      "24/03/14 21:26:16 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 96) (worker-node-2, executor 2, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 21:26:16 INFO TaskSetManager: Starting task 1.0 in stage 79.0 (TID 97) (worker-node-1, executor 1, partition 1, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on worker-node-1:45391 (size: 4.8 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on worker-node-2:39037 (size: 4.8 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on worker-node-1:45391 (size: 33.1 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on worker-node-2:39037 (size: 33.1 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:16 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 96) in 41 ms on worker-node-2 (executor 2) (1/2)\n",
      "24/03/14 21:26:16 INFO TaskSetManager: Finished task 1.0 in stage 79.0 (TID 97) in 49 ms on worker-node-1 (executor 1) (2/2)\n",
      "24/03/14 21:26:16 INFO YarnScheduler: Removed TaskSet 79.0, whose tasks have all completed, from pool \n",
      "24/03/14 21:26:16 INFO DAGScheduler: ResultStage 79 (collect at /tmp/ipykernel_112987/694392133.py:6) finished in 0.057 s\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Job 74 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 21:26:16 INFO YarnScheduler: Killing all running tasks in stage 79: Stage finished\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Job 74 finished: collect at /tmp/ipykernel_112987/694392133.py:6, took 0.060674 s\n",
      "24/03/14 21:26:16 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 358.7 KiB, free 359.4 MiB)\n",
      "24/03/14 21:26:16 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 33.1 KiB, free 359.3 MiB)\n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on master-node:35375 (size: 33.1 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:16 INFO SparkContext: Created broadcast 120 from textFile at NativeMethodAccessorImpl.java:0\n",
      "24/03/14 21:26:16 INFO FileInputFormat: Total input files to process : 1\n",
      "24/03/14 21:26:16 INFO SparkContext: Starting job: collect at /tmp/ipykernel_112987/694392133.py:6\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Got job 75 (collect at /tmp/ipykernel_112987/694392133.py:6) with 2 output partitions\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Final stage: ResultStage 80 (collect at /tmp/ipykernel_112987/694392133.py:6)\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Submitting ResultStage 80 (PythonRDD[338] at collect at /tmp/ipykernel_112987/694392133.py:6), which has no missing parents\n",
      "24/03/14 21:26:16 INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 7.7 KiB, free 359.3 MiB)\n",
      "24/03/14 21:26:16 INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 359.3 MiB)\n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on master-node:35375 (size: 4.8 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:16 INFO SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 80 (PythonRDD[338] at collect at /tmp/ipykernel_112987/694392133.py:6) (first 15 tasks are for partitions Vector(0, 1))\n",
      "24/03/14 21:26:16 INFO YarnScheduler: Adding task set 80.0 with 2 tasks resource profile 0\n",
      "24/03/14 21:26:16 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 98) (worker-node-2, executor 2, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 21:26:16 INFO TaskSetManager: Starting task 1.0 in stage 80.0 (TID 99) (worker-node-1, executor 1, partition 1, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on worker-node-2:39037 (size: 4.8 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on worker-node-1:45391 (size: 4.8 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on worker-node-2:39037 (size: 33.1 KiB, free: 365.6 MiB)\n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on worker-node-1:45391 (size: 33.1 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:16 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 98) in 84 ms on worker-node-2 (executor 2) (1/2)\n",
      "24/03/14 21:26:16 INFO TaskSetManager: Finished task 1.0 in stage 80.0 (TID 99) in 91 ms on worker-node-1 (executor 1) (2/2)\n",
      "24/03/14 21:26:16 INFO YarnScheduler: Removed TaskSet 80.0, whose tasks have all completed, from pool \n",
      "24/03/14 21:26:16 INFO DAGScheduler: ResultStage 80 (collect at /tmp/ipykernel_112987/694392133.py:6) finished in 0.100 s\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Job 75 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 21:26:16 INFO YarnScheduler: Killing all running tasks in stage 80: Stage finished\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Job 75 finished: collect at /tmp/ipykernel_112987/694392133.py:6, took 0.103745 s\n",
      "24/03/14 21:26:16 INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 358.7 KiB, free 359.0 MiB)\n",
      "24/03/14 21:26:16 INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 33.1 KiB, free 358.9 MiB)\n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on master-node:35375 (size: 33.1 KiB, free: 365.6 MiB)\n",
      "24/03/14 21:26:16 INFO SparkContext: Created broadcast 122 from textFile at NativeMethodAccessorImpl.java:0\n",
      "24/03/14 21:26:16 INFO FileInputFormat: Total input files to process : 1\n",
      "24/03/14 21:26:16 INFO SparkContext: Starting job: collect at /tmp/ipykernel_112987/694392133.py:6\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Got job 76 (collect at /tmp/ipykernel_112987/694392133.py:6) with 2 output partitions\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Final stage: ResultStage 81 (collect at /tmp/ipykernel_112987/694392133.py:6)\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Submitting ResultStage 81 (PythonRDD[341] at collect at /tmp/ipykernel_112987/694392133.py:6), which has no missing parents\n",
      "24/03/14 21:26:16 INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 7.7 KiB, free 358.9 MiB)\n",
      "24/03/14 21:26:16 INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 358.9 MiB)\n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on master-node:35375 (size: 4.8 KiB, free: 365.6 MiB)\n",
      "24/03/14 21:26:16 INFO SparkContext: Created broadcast 123 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 81 (PythonRDD[341] at collect at /tmp/ipykernel_112987/694392133.py:6) (first 15 tasks are for partitions Vector(0, 1))\n",
      "24/03/14 21:26:16 INFO YarnScheduler: Adding task set 81.0 with 2 tasks resource profile 0\n",
      "24/03/14 21:26:16 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 100) (worker-node-2, executor 2, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 21:26:16 INFO TaskSetManager: Starting task 1.0 in stage 81.0 (TID 101) (worker-node-1, executor 1, partition 1, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on worker-node-2:39037 (size: 4.8 KiB, free: 365.6 MiB)\n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on worker-node-1:45391 (size: 4.8 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on worker-node-1:45391 (size: 33.1 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on worker-node-2:39037 (size: 33.1 KiB, free: 365.6 MiB)\n",
      "24/03/14 21:26:16 INFO TaskSetManager: Finished task 1.0 in stage 81.0 (TID 101) in 47 ms on worker-node-1 (executor 1) (1/2)\n",
      "24/03/14 21:26:16 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 100) in 53 ms on worker-node-2 (executor 2) (2/2)\n",
      "24/03/14 21:26:16 INFO YarnScheduler: Removed TaskSet 81.0, whose tasks have all completed, from pool \n",
      "24/03/14 21:26:16 INFO DAGScheduler: ResultStage 81 (collect at /tmp/ipykernel_112987/694392133.py:6) finished in 0.062 s\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Job 76 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 21:26:16 INFO YarnScheduler: Killing all running tasks in stage 81: Stage finished\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Job 76 finished: collect at /tmp/ipykernel_112987/694392133.py:6, took 0.067261 s\n",
      "24/03/14 21:26:16 INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 358.7 KiB, free 358.6 MiB)\n",
      "24/03/14 21:26:16 INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 33.1 KiB, free 358.5 MiB)\n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on master-node:35375 (size: 33.1 KiB, free: 365.6 MiB)\n",
      "24/03/14 21:26:16 INFO SparkContext: Created broadcast 124 from textFile at NativeMethodAccessorImpl.java:0\n",
      "24/03/14 21:26:16 INFO FileInputFormat: Total input files to process : 1\n",
      "24/03/14 21:26:16 INFO SparkContext: Starting job: collect at /tmp/ipykernel_112987/694392133.py:6\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Got job 77 (collect at /tmp/ipykernel_112987/694392133.py:6) with 2 output partitions\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Final stage: ResultStage 82 (collect at /tmp/ipykernel_112987/694392133.py:6)\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Submitting ResultStage 82 (PythonRDD[344] at collect at /tmp/ipykernel_112987/694392133.py:6), which has no missing parents\n",
      "24/03/14 21:26:16 INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 7.7 KiB, free 358.5 MiB)\n",
      "24/03/14 21:26:16 INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 358.5 MiB)\n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on master-node:35375 (size: 4.8 KiB, free: 365.6 MiB)\n",
      "24/03/14 21:26:16 INFO SparkContext: Created broadcast 125 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 21:26:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 82 (PythonRDD[344] at collect at /tmp/ipykernel_112987/694392133.py:6) (first 15 tasks are for partitions Vector(0, 1))\n",
      "24/03/14 21:26:16 INFO YarnScheduler: Adding task set 82.0 with 2 tasks resource profile 0\n",
      "24/03/14 21:26:16 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 102) (worker-node-1, executor 1, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 21:26:16 INFO TaskSetManager: Starting task 1.0 in stage 82.0 (TID 103) (worker-node-2, executor 2, partition 1, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on worker-node-2:39037 (size: 4.8 KiB, free: 365.6 MiB)\n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on worker-node-1:45391 (size: 4.8 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on worker-node-2:39037 (size: 33.1 KiB, free: 365.6 MiB)\n",
      "24/03/14 21:26:16 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on worker-node-1:45391 (size: 33.1 KiB, free: 365.6 MiB)\n",
      "24/03/14 21:26:17 INFO TaskSetManager: Finished task 1.0 in stage 82.0 (TID 103) in 63 ms on worker-node-2 (executor 2) (1/2)\n",
      "24/03/14 21:26:17 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 102) in 68 ms on worker-node-1 (executor 1) (2/2)\n",
      "24/03/14 21:26:17 INFO YarnScheduler: Removed TaskSet 82.0, whose tasks have all completed, from pool \n",
      "24/03/14 21:26:17 INFO DAGScheduler: ResultStage 82 (collect at /tmp/ipykernel_112987/694392133.py:6) finished in 0.077 s\n",
      "24/03/14 21:26:17 INFO DAGScheduler: Job 77 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 21:26:17 INFO YarnScheduler: Killing all running tasks in stage 82: Stage finished\n",
      "24/03/14 21:26:17 INFO DAGScheduler: Job 77 finished: collect at /tmp/ipykernel_112987/694392133.py:6, took 0.079166 s\n"
     ]
    }
   ],
   "source": [
    "all_rows = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "    # Lese die Datei und bereinige den Inhalt\n",
    "    rdd = spark_context.textFile(file_path)\n",
    "    content = rdd.map(lambda line: line.replace('\\n', '').replace(' ', '').replace(',', '')).collect()\n",
    "    \n",
    "    # Erstelle Zeilen fr jede Datei\n",
    "    rows = [Row(column1=data[5], column2=data[6], column3=data[25], column4=data[28], column5=data[29]) for data in [content]]\n",
    "    \n",
    "    # Fge die Zeilen zur gemeinsamen Liste hinzu\n",
    "    all_rows.extend(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "58fa953d-1217-4544-b6b4-84cdb30021fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 21:26:42 INFO SparkContext: Starting job: showString at <unknown>:0\n",
      "24/03/14 21:26:42 INFO DAGScheduler: Got job 78 (showString at <unknown>:0) with 1 output partitions\n",
      "24/03/14 21:26:42 INFO DAGScheduler: Final stage: ResultStage 83 (showString at <unknown>:0)\n",
      "24/03/14 21:26:42 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 21:26:42 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 21:26:42 INFO DAGScheduler: Submitting ResultStage 83 (MapPartitionsRDD[351] at showString at <unknown>:0), which has no missing parents\n",
      "24/03/14 21:26:42 INFO MemoryStore: Block broadcast_126 stored as values in memory (estimated size 13.6 KiB, free 358.5 MiB)\n",
      "24/03/14 21:26:42 INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 358.5 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on master-node:35375 (size: 6.8 KiB, free: 365.6 MiB)\n",
      "24/03/14 21:26:42 INFO SparkContext: Created broadcast 126 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 21:26:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 83 (MapPartitionsRDD[351] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/03/14 21:26:42 INFO YarnScheduler: Adding task set 83.0 with 1 tasks resource profile 0\n",
      "24/03/14 21:26:42 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 104) (worker-node-1, executor 1, partition 0, PROCESS_LOCAL, 7877 bytes) \n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on worker-node-1:45391 (size: 6.8 KiB, free: 365.6 MiB)\n",
      "24/03/14 21:26:42 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 104) in 92 ms on worker-node-1 (executor 1) (1/1)\n",
      "24/03/14 21:26:42 INFO YarnScheduler: Removed TaskSet 83.0, whose tasks have all completed, from pool \n",
      "24/03/14 21:26:42 INFO DAGScheduler: ResultStage 83 (showString at <unknown>:0) finished in 0.102 s\n",
      "24/03/14 21:26:42 INFO DAGScheduler: Job 78 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 21:26:42 INFO YarnScheduler: Killing all running tasks in stage 83: Stage finished\n",
      "24/03/14 21:26:42 INFO DAGScheduler: Job 78 finished: showString at <unknown>:0, took 0.105821 s\n",
      "24/03/14 21:26:42 INFO SparkContext: Starting job: showString at <unknown>:0\n",
      "24/03/14 21:26:42 INFO DAGScheduler: Got job 79 (showString at <unknown>:0) with 1 output partitions\n",
      "24/03/14 21:26:42 INFO DAGScheduler: Final stage: ResultStage 84 (showString at <unknown>:0)\n",
      "24/03/14 21:26:42 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 21:26:42 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 21:26:42 INFO DAGScheduler: Submitting ResultStage 84 (MapPartitionsRDD[351] at showString at <unknown>:0), which has no missing parents\n",
      "24/03/14 21:26:42 INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 13.6 KiB, free 358.5 MiB)\n",
      "24/03/14 21:26:42 INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 358.5 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on master-node:35375 (size: 6.8 KiB, free: 365.6 MiB)\n",
      "24/03/14 21:26:42 INFO SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 21:26:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 84 (MapPartitionsRDD[351] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(1))\n",
      "24/03/14 21:26:42 INFO YarnScheduler: Adding task set 84.0 with 1 tasks resource profile 0\n",
      "24/03/14 21:26:42 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 105) (worker-node-2, executor 2, partition 1, PROCESS_LOCAL, 7954 bytes) \n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on worker-node-2:39037 (size: 6.8 KiB, free: 365.6 MiB)\n",
      "24/03/14 21:26:42 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 105) in 75 ms on worker-node-2 (executor 2) (1/1)\n",
      "24/03/14 21:26:42 INFO YarnScheduler: Removed TaskSet 84.0, whose tasks have all completed, from pool \n",
      "24/03/14 21:26:42 INFO DAGScheduler: ResultStage 84 (showString at <unknown>:0) finished in 0.081 s\n",
      "24/03/14 21:26:42 INFO DAGScheduler: Job 79 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 21:26:42 INFO YarnScheduler: Killing all running tasks in stage 84: Stage finished\n",
      "24/03/14 21:26:42 INFO DAGScheduler: Job 79 finished: showString at <unknown>:0, took 0.083043 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+\n",
      "|column1|column2|column3|column4|column5|\n",
      "+-------+-------+-------+-------+-------+\n",
      "|218.932|  0.247|-11.197|218.932| 92.198|\n",
      "|148.035|  0.148| -9.843|137.915|121.274|\n",
      "|177.475|  0.282| -9.689|172.304| 100.07|\n",
      "|233.404|      0| -9.013|217.124|119.293|\n",
      "|209.606|  0.066| -4.501|198.699|129.738|\n",
      "|267.702|  2.264| -9.323| 254.27|147.782|\n",
      "|114.782|  0.096|-17.302|114.782|111.787|\n",
      "| 189.57|  0.319|-11.642|181.023| 101.43|\n",
      "|269.818|    5.3|-13.496| 258.99| 86.643|\n",
      "|266.396|  0.084| -6.697|261.747|114.041|\n",
      "|218.775|  2.125|-10.021|207.012|146.765|\n",
      "+-------+-------+-------+-------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_104_piece0 on worker-node-1:45391 in memory (size: 33.1 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_104_piece0 on worker-node-2:39037 in memory (size: 33.1 KiB, free: 365.6 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_104_piece0 on master-node:35375 in memory (size: 33.1 KiB, free: 365.6 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_106_piece0 on worker-node-2:39037 in memory (size: 33.1 KiB, free: 365.6 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_106_piece0 on worker-node-1:45391 in memory (size: 33.1 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_106_piece0 on master-node:35375 in memory (size: 33.1 KiB, free: 365.6 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_123_piece0 on worker-node-1:45391 in memory (size: 4.8 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_123_piece0 on master-node:35375 in memory (size: 4.8 KiB, free: 365.6 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_123_piece0 on worker-node-2:39037 in memory (size: 4.8 KiB, free: 365.6 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_126_piece0 on master-node:35375 in memory (size: 6.8 KiB, free: 365.6 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_126_piece0 on worker-node-1:45391 in memory (size: 6.8 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_121_piece0 on master-node:35375 in memory (size: 4.8 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_121_piece0 on worker-node-2:39037 in memory (size: 4.8 KiB, free: 365.6 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_121_piece0 on worker-node-1:45391 in memory (size: 4.8 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_125_piece0 on master-node:35375 in memory (size: 4.8 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_125_piece0 on worker-node-2:39037 in memory (size: 4.8 KiB, free: 365.6 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_125_piece0 on worker-node-1:45391 in memory (size: 4.8 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_119_piece0 on master-node:35375 in memory (size: 4.8 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_119_piece0 on worker-node-2:39037 in memory (size: 4.8 KiB, free: 365.6 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_119_piece0 on worker-node-1:45391 in memory (size: 4.8 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_111_piece0 on master-node:35375 in memory (size: 4.8 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_111_piece0 on worker-node-1:45391 in memory (size: 4.8 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_111_piece0 on worker-node-2:39037 in memory (size: 4.8 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_105_piece0 on master-node:35375 in memory (size: 4.8 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_105_piece0 on worker-node-1:45391 in memory (size: 4.8 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_105_piece0 on worker-node-2:39037 in memory (size: 4.8 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_113_piece0 on master-node:35375 in memory (size: 4.8 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_113_piece0 on worker-node-1:45391 in memory (size: 4.8 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_113_piece0 on worker-node-2:39037 in memory (size: 4.8 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_109_piece0 on master-node:35375 in memory (size: 4.8 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_109_piece0 on worker-node-1:45391 in memory (size: 4.8 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_109_piece0 on worker-node-2:39037 in memory (size: 4.8 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_115_piece0 on master-node:35375 in memory (size: 4.8 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_115_piece0 on worker-node-1:45391 in memory (size: 4.8 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_115_piece0 on worker-node-2:39037 in memory (size: 4.8 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_117_piece0 on master-node:35375 in memory (size: 4.8 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_117_piece0 on worker-node-1:45391 in memory (size: 4.8 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_117_piece0 on worker-node-2:39037 in memory (size: 4.8 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_102_piece0 on worker-node-1:45391 in memory (size: 33.3 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_102_piece0 on master-node:35375 in memory (size: 33.3 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_102_piece0 on worker-node-2:39037 in memory (size: 33.3 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_110_piece0 on master-node:35375 in memory (size: 33.1 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_110_piece0 on worker-node-1:45391 in memory (size: 33.1 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_110_piece0 on worker-node-2:39037 in memory (size: 33.1 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_103_piece0 on worker-node-1:45391 in memory (size: 4.5 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_103_piece0 on worker-node-2:39037 in memory (size: 4.5 KiB, free: 365.7 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_103_piece0 on master-node:35375 in memory (size: 4.5 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_108_piece0 on master-node:35375 in memory (size: 33.1 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_108_piece0 on worker-node-2:39037 in memory (size: 33.1 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_108_piece0 on worker-node-1:45391 in memory (size: 33.1 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_107_piece0 on master-node:35375 in memory (size: 4.8 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_107_piece0 on worker-node-1:45391 in memory (size: 4.8 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:26:42 INFO BlockManagerInfo: Removed broadcast_107_piece0 on worker-node-2:39037 in memory (size: 4.8 KiB, free: 365.8 MiB)\n"
     ]
    }
   ],
   "source": [
    "# Erstelle DataFrame aus den gesammelten Zeilen\n",
    "schema = sqlContext.createDataFrame(all_rows)\n",
    "\n",
    "# Register the DataFrame as a table\n",
    "schema.registerTempTable(\"combined_data_table\")\n",
    "\n",
    "# Zeige das Ergebnis\n",
    "result = sqlContext.sql(\"SELECT * FROM combined_data_table\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8b95f853-0bf6-46d7-8a28-a634a4d32824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle DataFrame aus den gesammelten Zeilen\n",
    "df = sqlContext.createDataFrame(all_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "91e7d473-5abb-4b5c-b3d4-b19015240039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the DataFrame: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 21:31:47 INFO DAGScheduler: Registering RDD 370 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 5\n",
      "24/03/14 21:31:47 INFO DAGScheduler: Got map stage job 86 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions\n",
      "24/03/14 21:31:47 INFO DAGScheduler: Final stage: ShuffleMapStage 93 (count at NativeMethodAccessorImpl.java:0)\n",
      "24/03/14 21:31:47 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 21:31:47 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 21:31:47 INFO DAGScheduler: Submitting ShuffleMapStage 93 (MapPartitionsRDD[370] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/03/14 21:31:47 INFO MemoryStore: Block broadcast_134 stored as values in memory (estimated size 16.0 KiB, free 362.4 MiB)\n",
      "24/03/14 21:31:47 INFO MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 362.4 MiB)\n",
      "24/03/14 21:31:47 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on master-node:35375 (size: 8.3 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:31:47 INFO SparkContext: Created broadcast 134 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 21:31:47 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 93 (MapPartitionsRDD[370] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))\n",
      "24/03/14 21:31:47 INFO YarnScheduler: Adding task set 93.0 with 2 tasks resource profile 0\n",
      "24/03/14 21:31:47 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 114) (worker-node-1, executor 1, partition 0, PROCESS_LOCAL, 7866 bytes) \n",
      "24/03/14 21:31:47 INFO TaskSetManager: Starting task 1.0 in stage 93.0 (TID 115) (worker-node-2, executor 2, partition 1, PROCESS_LOCAL, 7943 bytes) \n",
      "24/03/14 21:31:47 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on worker-node-1:45391 (size: 8.3 KiB, free: 366.0 MiB)\n",
      "24/03/14 21:31:47 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on worker-node-2:39037 (size: 8.3 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:31:47 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 114) in 33 ms on worker-node-1 (executor 1) (1/2)\n",
      "24/03/14 21:31:47 INFO TaskSetManager: Finished task 1.0 in stage 93.0 (TID 115) in 48 ms on worker-node-2 (executor 2) (2/2)\n",
      "24/03/14 21:31:47 INFO YarnScheduler: Removed TaskSet 93.0, whose tasks have all completed, from pool \n",
      "24/03/14 21:31:47 INFO DAGScheduler: ShuffleMapStage 93 (count at NativeMethodAccessorImpl.java:0) finished in 0.059 s\n",
      "24/03/14 21:31:47 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/03/14 21:31:47 INFO DAGScheduler: running: Set()\n",
      "24/03/14 21:31:47 INFO DAGScheduler: waiting: Set()\n",
      "24/03/14 21:31:47 INFO DAGScheduler: failed: Set()\n",
      "24/03/14 21:31:47 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0\n",
      "24/03/14 21:31:47 INFO DAGScheduler: Got job 87 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/03/14 21:31:47 INFO DAGScheduler: Final stage: ResultStage 95 (count at NativeMethodAccessorImpl.java:0)\n",
      "24/03/14 21:31:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 94)\n",
      "24/03/14 21:31:47 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 21:31:47 INFO DAGScheduler: Submitting ResultStage 95 (MapPartitionsRDD[373] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/03/14 21:31:47 INFO MemoryStore: Block broadcast_135 stored as values in memory (estimated size 12.5 KiB, free 362.4 MiB)\n",
      "24/03/14 21:31:47 INFO MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 362.4 MiB)\n",
      "24/03/14 21:31:47 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on master-node:35375 (size: 5.9 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:31:47 INFO SparkContext: Created broadcast 135 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 21:31:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 95 (MapPartitionsRDD[373] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/03/14 21:31:47 INFO YarnScheduler: Adding task set 95.0 with 1 tasks resource profile 0\n",
      "24/03/14 21:31:47 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 116) (worker-node-2, executor 2, partition 0, NODE_LOCAL, 7626 bytes) \n",
      "24/03/14 21:31:47 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on worker-node-2:39037 (size: 5.9 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:31:47 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 192.168.2.40:47924\n",
      "24/03/14 21:31:47 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 116) in 24 ms on worker-node-2 (executor 2) (1/1)\n",
      "24/03/14 21:31:47 INFO YarnScheduler: Removed TaskSet 95.0, whose tasks have all completed, from pool \n",
      "24/03/14 21:31:47 INFO DAGScheduler: ResultStage 95 (count at NativeMethodAccessorImpl.java:0) finished in 0.031 s\n",
      "24/03/14 21:31:47 INFO DAGScheduler: Job 87 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 21:31:47 INFO YarnScheduler: Killing all running tasks in stage 95: Stage finished\n",
      "24/03/14 21:31:47 INFO DAGScheduler: Job 87 finished: count at NativeMethodAccessorImpl.java:0, took 0.033488 s\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows in the DataFrame:\", df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8841cb17-41ab-499c-93e9-699421e8635f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+\n",
      "|column1|column2|column3|column4|column5|\n",
      "+-------+-------+-------+-------+-------+\n",
      "|218.932|  0.247|-11.197|218.932| 92.198|\n",
      "|148.035|  0.148| -9.843|137.915|121.274|\n",
      "|177.475|  0.282| -9.689|172.304| 100.07|\n",
      "|233.404|      0| -9.013|217.124|119.293|\n",
      "|209.606|  0.066| -4.501|198.699|129.738|\n",
      "|267.702|  2.264| -9.323| 254.27|147.782|\n",
      "|114.782|  0.096|-17.302|114.782|111.787|\n",
      "| 189.57|  0.319|-11.642|181.023| 101.43|\n",
      "|269.818|    5.3|-13.496| 258.99| 86.643|\n",
      "|266.396|  0.084| -6.697|261.747|114.041|\n",
      "|218.775|  2.125|-10.021|207.012|146.765|\n",
      "+-------+-------+-------+-------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 21:29:13 INFO SparkContext: Starting job: showString at <unknown>:0\n",
      "24/03/14 21:29:13 INFO DAGScheduler: Got job 80 (showString at <unknown>:0) with 1 output partitions\n",
      "24/03/14 21:29:13 INFO DAGScheduler: Final stage: ResultStage 85 (showString at <unknown>:0)\n",
      "24/03/14 21:29:13 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 21:29:13 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 21:29:13 INFO DAGScheduler: Submitting ResultStage 85 (MapPartitionsRDD[358] at showString at <unknown>:0), which has no missing parents\n",
      "24/03/14 21:29:13 INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 13.6 KiB, free 360.5 MiB)\n",
      "24/03/14 21:29:13 INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 360.5 MiB)\n",
      "24/03/14 21:29:13 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on master-node:35375 (size: 6.8 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:29:13 INFO SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 21:29:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 85 (MapPartitionsRDD[358] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/03/14 21:29:13 INFO YarnScheduler: Adding task set 85.0 with 1 tasks resource profile 0\n",
      "24/03/14 21:29:13 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 106) (worker-node-1, executor 1, partition 0, PROCESS_LOCAL, 7877 bytes) \n",
      "24/03/14 21:29:13 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on worker-node-1:45391 (size: 6.8 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:29:14 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 106) in 50 ms on worker-node-1 (executor 1) (1/1)\n",
      "24/03/14 21:29:14 INFO YarnScheduler: Removed TaskSet 85.0, whose tasks have all completed, from pool \n",
      "24/03/14 21:29:14 INFO DAGScheduler: ResultStage 85 (showString at <unknown>:0) finished in 0.057 s\n",
      "24/03/14 21:29:14 INFO DAGScheduler: Job 80 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 21:29:14 INFO YarnScheduler: Killing all running tasks in stage 85: Stage finished\n",
      "24/03/14 21:29:14 INFO DAGScheduler: Job 80 finished: showString at <unknown>:0, took 0.060231 s\n",
      "24/03/14 21:29:14 INFO SparkContext: Starting job: showString at <unknown>:0\n",
      "24/03/14 21:29:14 INFO DAGScheduler: Got job 81 (showString at <unknown>:0) with 1 output partitions\n",
      "24/03/14 21:29:14 INFO DAGScheduler: Final stage: ResultStage 86 (showString at <unknown>:0)\n",
      "24/03/14 21:29:14 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 21:29:14 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 21:29:14 INFO DAGScheduler: Submitting ResultStage 86 (MapPartitionsRDD[358] at showString at <unknown>:0), which has no missing parents\n",
      "24/03/14 21:29:14 INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 13.6 KiB, free 360.5 MiB)\n",
      "24/03/14 21:29:14 INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 360.5 MiB)\n",
      "24/03/14 21:29:14 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on master-node:35375 (size: 6.8 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:29:14 INFO SparkContext: Created broadcast 129 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 21:29:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 86 (MapPartitionsRDD[358] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(1))\n",
      "24/03/14 21:29:14 INFO YarnScheduler: Adding task set 86.0 with 1 tasks resource profile 0\n",
      "24/03/14 21:29:14 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 107) (worker-node-1, executor 1, partition 1, PROCESS_LOCAL, 7954 bytes) \n",
      "24/03/14 21:29:14 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on worker-node-1:45391 (size: 6.8 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:29:14 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 107) in 27 ms on worker-node-1 (executor 1) (1/1)\n",
      "24/03/14 21:29:14 INFO YarnScheduler: Removed TaskSet 86.0, whose tasks have all completed, from pool \n",
      "24/03/14 21:29:14 INFO DAGScheduler: ResultStage 86 (showString at <unknown>:0) finished in 0.034 s\n",
      "24/03/14 21:29:14 INFO DAGScheduler: Job 81 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 21:29:14 INFO YarnScheduler: Killing all running tasks in stage 86: Stage finished\n",
      "24/03/14 21:29:14 INFO DAGScheduler: Job 81 finished: showString at <unknown>:0, took 0.038419 s\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0c8fbf83-5cac-4709-8307-91d008195c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 21:29:24 INFO CodeGenerator: Code generated in 59.376809 ms\n",
      "24/03/14 21:29:24 INFO DAGScheduler: Registering RDD 360 (collect at /tmp/ipykernel_112987/502504937.py:2) as input to shuffle 3\n",
      "24/03/14 21:29:24 INFO DAGScheduler: Got map stage job 82 (collect at /tmp/ipykernel_112987/502504937.py:2) with 2 output partitions\n",
      "24/03/14 21:29:24 INFO DAGScheduler: Final stage: ShuffleMapStage 87 (collect at /tmp/ipykernel_112987/502504937.py:2)\n",
      "24/03/14 21:29:24 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 21:29:24 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 21:29:24 INFO DAGScheduler: Submitting ShuffleMapStage 87 (MapPartitionsRDD[360] at collect at /tmp/ipykernel_112987/502504937.py:2), which has no missing parents\n",
      "24/03/14 21:29:24 INFO MemoryStore: Block broadcast_130 stored as values in memory (estimated size 30.7 KiB, free 360.5 MiB)\n",
      "24/03/14 21:29:24 INFO MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 12.1 KiB, free 360.5 MiB)\n",
      "24/03/14 21:29:24 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on master-node:35375 (size: 12.1 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:29:24 INFO SparkContext: Created broadcast 130 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 21:29:24 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 87 (MapPartitionsRDD[360] at collect at /tmp/ipykernel_112987/502504937.py:2) (first 15 tasks are for partitions Vector(0, 1))\n",
      "24/03/14 21:29:24 INFO YarnScheduler: Adding task set 87.0 with 2 tasks resource profile 0\n",
      "24/03/14 21:29:24 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 108) (worker-node-2, executor 2, partition 0, PROCESS_LOCAL, 7866 bytes) \n",
      "24/03/14 21:29:24 INFO TaskSetManager: Starting task 1.0 in stage 87.0 (TID 109) (worker-node-1, executor 1, partition 1, PROCESS_LOCAL, 7943 bytes) \n",
      "24/03/14 21:29:24 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on worker-node-1:45391 (size: 12.1 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:29:24 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on worker-node-2:39037 (size: 12.1 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:29:24 INFO TaskSetManager: Finished task 1.0 in stage 87.0 (TID 109) in 93 ms on worker-node-1 (executor 1) (1/2)\n",
      "24/03/14 21:29:24 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 108) in 134 ms on worker-node-2 (executor 2) (2/2)\n",
      "24/03/14 21:29:24 INFO YarnScheduler: Removed TaskSet 87.0, whose tasks have all completed, from pool \n",
      "24/03/14 21:29:24 INFO DAGScheduler: ShuffleMapStage 87 (collect at /tmp/ipykernel_112987/502504937.py:2) finished in 0.146 s\n",
      "24/03/14 21:29:24 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/03/14 21:29:24 INFO DAGScheduler: running: Set()\n",
      "24/03/14 21:29:24 INFO DAGScheduler: waiting: Set()\n",
      "24/03/14 21:29:24 INFO DAGScheduler: failed: Set()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchschnittswerte:\n",
      "avg(column3): -10.247636363636362\n",
      "avg(column1): 210.40863636363636\n",
      "avg(column2): 0.9937272727272727\n",
      "avg(column5): 115.54736363636363\n",
      "avg(column4): 202.07254545454543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 21:29:24 INFO CodeGenerator: Code generated in 36.702799 ms\n",
      "24/03/14 21:29:24 INFO SparkContext: Starting job: collect at /tmp/ipykernel_112987/502504937.py:2\n",
      "24/03/14 21:29:24 INFO DAGScheduler: Got job 83 (collect at /tmp/ipykernel_112987/502504937.py:2) with 1 output partitions\n",
      "24/03/14 21:29:24 INFO DAGScheduler: Final stage: ResultStage 89 (collect at /tmp/ipykernel_112987/502504937.py:2)\n",
      "24/03/14 21:29:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 88)\n",
      "24/03/14 21:29:24 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 21:29:24 INFO DAGScheduler: Submitting ResultStage 89 (MapPartitionsRDD[363] at collect at /tmp/ipykernel_112987/502504937.py:2), which has no missing parents\n",
      "24/03/14 21:29:24 INFO MemoryStore: Block broadcast_131 stored as values in memory (estimated size 23.4 KiB, free 360.5 MiB)\n",
      "24/03/14 21:29:24 INFO MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 360.4 MiB)\n",
      "24/03/14 21:29:24 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on master-node:35375 (size: 8.8 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:29:24 INFO SparkContext: Created broadcast 131 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 21:29:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 89 (MapPartitionsRDD[363] at collect at /tmp/ipykernel_112987/502504937.py:2) (first 15 tasks are for partitions Vector(0))\n",
      "24/03/14 21:29:24 INFO YarnScheduler: Adding task set 89.0 with 1 tasks resource profile 0\n",
      "24/03/14 21:29:24 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 110) (worker-node-2, executor 2, partition 0, NODE_LOCAL, 7626 bytes) \n",
      "24/03/14 21:29:24 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on worker-node-2:39037 (size: 8.8 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:29:24 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 192.168.2.40:47924\n",
      "24/03/14 21:29:24 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 110) in 75 ms on worker-node-2 (executor 2) (1/1)\n",
      "24/03/14 21:29:24 INFO YarnScheduler: Removed TaskSet 89.0, whose tasks have all completed, from pool \n",
      "24/03/14 21:29:24 INFO DAGScheduler: ResultStage 89 (collect at /tmp/ipykernel_112987/502504937.py:2) finished in 0.084 s\n",
      "24/03/14 21:29:24 INFO DAGScheduler: Job 83 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 21:29:24 INFO YarnScheduler: Killing all running tasks in stage 89: Stage finished\n",
      "24/03/14 21:29:24 INFO DAGScheduler: Job 83 finished: collect at /tmp/ipykernel_112987/502504937.py:2, took 0.087730 s\n",
      "24/03/14 21:31:20 INFO BlockManagerInfo: Removed broadcast_116_piece0 on master-node:35375 in memory (size: 33.1 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:31:20 INFO BlockManagerInfo: Removed broadcast_116_piece0 on worker-node-1:45391 in memory (size: 33.1 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:31:20 INFO BlockManagerInfo: Removed broadcast_116_piece0 on worker-node-2:39037 in memory (size: 33.1 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:31:20 INFO BlockManagerInfo: Removed broadcast_130_piece0 on worker-node-1:45391 in memory (size: 12.1 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:31:20 INFO BlockManagerInfo: Removed broadcast_130_piece0 on master-node:35375 in memory (size: 12.1 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:31:20 INFO BlockManagerInfo: Removed broadcast_130_piece0 on worker-node-2:39037 in memory (size: 12.1 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:31:20 INFO BlockManagerInfo: Removed broadcast_114_piece0 on master-node:35375 in memory (size: 33.1 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:31:20 INFO BlockManagerInfo: Removed broadcast_114_piece0 on worker-node-1:45391 in memory (size: 33.1 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:31:20 INFO BlockManagerInfo: Removed broadcast_114_piece0 on worker-node-2:39037 in memory (size: 33.1 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:31:20 INFO BlockManagerInfo: Removed broadcast_129_piece0 on master-node:35375 in memory (size: 6.8 KiB, free: 365.8 MiB)\n",
      "24/03/14 21:31:20 INFO BlockManagerInfo: Removed broadcast_129_piece0 on worker-node-1:45391 in memory (size: 6.8 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:31:20 INFO BlockManagerInfo: Removed broadcast_122_piece0 on master-node:35375 in memory (size: 33.1 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:31:20 INFO BlockManagerInfo: Removed broadcast_122_piece0 on worker-node-1:45391 in memory (size: 33.1 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:31:20 INFO BlockManagerInfo: Removed broadcast_122_piece0 on worker-node-2:39037 in memory (size: 33.1 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:31:20 INFO BlockManagerInfo: Removed broadcast_118_piece0 on master-node:35375 in memory (size: 33.1 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:31:20 INFO BlockManagerInfo: Removed broadcast_118_piece0 on worker-node-1:45391 in memory (size: 33.1 KiB, free: 366.0 MiB)\n",
      "24/03/14 21:31:20 INFO BlockManagerInfo: Removed broadcast_118_piece0 on worker-node-2:39037 in memory (size: 33.1 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:31:20 INFO BlockManagerInfo: Removed broadcast_131_piece0 on master-node:35375 in memory (size: 8.8 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:31:20 INFO BlockManagerInfo: Removed broadcast_131_piece0 on worker-node-2:39037 in memory (size: 8.8 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:31:20 INFO BlockManagerInfo: Removed broadcast_127_piece0 on master-node:35375 in memory (size: 6.8 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:31:20 INFO BlockManagerInfo: Removed broadcast_127_piece0 on worker-node-2:39037 in memory (size: 6.8 KiB, free: 365.9 MiB)\n",
      "24/03/14 21:31:20 INFO BlockManagerInfo: Removed broadcast_120_piece0 on master-node:35375 in memory (size: 33.1 KiB, free: 366.0 MiB)\n",
      "24/03/14 21:31:20 INFO BlockManagerInfo: Removed broadcast_120_piece0 on worker-node-2:39037 in memory (size: 33.1 KiB, free: 366.0 MiB)\n",
      "24/03/14 21:31:20 INFO BlockManagerInfo: Removed broadcast_120_piece0 on worker-node-1:45391 in memory (size: 33.1 KiB, free: 366.0 MiB)\n",
      "24/03/14 21:31:20 INFO BlockManagerInfo: Removed broadcast_128_piece0 on master-node:35375 in memory (size: 6.8 KiB, free: 366.0 MiB)\n",
      "24/03/14 21:31:20 INFO BlockManagerInfo: Removed broadcast_128_piece0 on worker-node-1:45391 in memory (size: 6.8 KiB, free: 366.0 MiB)\n"
     ]
    }
   ],
   "source": [
    "# Fhre die angegebene Abfrage aus, um durchschnittliche Werte zu berechnen\n",
    "average_values = df.agg({'column1': 'avg', 'column2': 'avg', 'column3': 'avg', 'column4': 'avg', 'column5': 'avg'}).collect()[0]\n",
    "print(\"Durchschnittswerte:\")\n",
    "for col_name, avg_value in average_values.asDict().items():\n",
    "    print(f\"{col_name}: {avg_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9a7ab67-3b12-4a91-9de7-d1403277d3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 19:51:41 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 358.7 KiB, free 364.7 MiB)\n",
      "24/03/14 19:51:41 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 33.1 KiB, free 364.7 MiB)\n",
      "24/03/14 19:51:41 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on master-node:33151 (size: 33.1 KiB, free: 366.1 MiB)\n",
      "24/03/14 19:51:41 INFO SparkContext: Created broadcast 17 from textFile at NativeMethodAccessorImpl.java:0\n",
      "24/03/14 19:51:44 INFO BlockManagerInfo: Removed broadcast_13_piece0 on worker-node-1:44403 in memory (size: 9.8 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:51:44 INFO BlockManagerInfo: Removed broadcast_13_piece0 on master-node:33151 in memory (size: 9.8 KiB, free: 366.1 MiB)\n",
      "24/03/14 19:51:44 INFO BlockManagerInfo: Removed broadcast_13_piece0 on worker-node-2:34115 in memory (size: 9.8 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:51:44 INFO BlockManagerInfo: Removed broadcast_9_piece0 on master-node:33151 in memory (size: 35.5 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:51:44 INFO BlockManagerInfo: Removed broadcast_11_piece0 on master-node:33151 in memory (size: 5.5 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:51:44 INFO BlockManagerInfo: Removed broadcast_11_piece0 on worker-node-2:34115 in memory (size: 5.5 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:51:44 INFO BlockManagerInfo: Removed broadcast_15_piece0 on master-node:33151 in memory (size: 5.5 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:51:44 INFO BlockManagerInfo: Removed broadcast_15_piece0 on worker-node-2:34115 in memory (size: 5.5 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:51:44 INFO BlockManagerInfo: Removed broadcast_16_piece0 on master-node:33151 in memory (size: 3.8 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:51:44 INFO BlockManagerInfo: Removed broadcast_16_piece0 on worker-node-1:44403 in memory (size: 3.8 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:51:44 INFO BlockManagerInfo: Removed broadcast_12_piece0 on master-node:33151 in memory (size: 9.8 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:51:44 INFO BlockManagerInfo: Removed broadcast_12_piece0 on worker-node-1:44403 in memory (size: 9.8 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:51:44 INFO BlockManagerInfo: Removed broadcast_12_piece0 on worker-node-2:34115 in memory (size: 9.8 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:51:44 INFO BlockManagerInfo: Removed broadcast_14_piece0 on master-node:33151 in memory (size: 5.4 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:51:44 INFO BlockManagerInfo: Removed broadcast_14_piece0 on worker-node-1:44403 in memory (size: 5.4 KiB, free: 366.2 MiB)\n"
     ]
    }
   ],
   "source": [
    "rdd = spark_context.textFile('hdfs://master-node:9000/user/hadoop/MillionSongSubset_ASCI_analysis_songs/TRAAAAW128F429D538_songs.asci')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90b0f8f6-d57a-4aae-afdf-c2624c382129",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = rdd.map(lambda line: line.strip('{}').split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d327c752-ccef-44fe-ad52-57828e887c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = rdd.map(lambda row: [str(elem) for elem in row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f22a541-74d1-4986-814d-1a087a4d5d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 19:52:18 INFO FileInputFormat: Total input files to process : 1\n",
      "24/03/14 19:52:18 INFO SparkContext: Starting job: runJob at PythonRDD.scala:181\n",
      "24/03/14 19:52:18 INFO DAGScheduler: Got job 11 (runJob at PythonRDD.scala:181) with 1 output partitions\n",
      "24/03/14 19:52:18 INFO DAGScheduler: Final stage: ResultStage 11 (runJob at PythonRDD.scala:181)\n",
      "24/03/14 19:52:18 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 19:52:18 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 19:52:18 INFO DAGScheduler: Submitting ResultStage 11 (PythonRDD[39] at RDD at PythonRDD.scala:53), which has no missing parents\n",
      "24/03/14 19:52:18 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 9.5 KiB, free 365.1 MiB)\n",
      "24/03/14 19:52:18 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 365.1 MiB)\n",
      "24/03/14 19:52:18 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on master-node:33151 (size: 5.7 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:52:18 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 19:52:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (PythonRDD[39] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))\n",
      "24/03/14 19:52:18 INFO YarnScheduler: Adding task set 11.0 with 1 tasks resource profile 0\n",
      "24/03/14 19:52:18 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 37) (worker-node-2, executor 1, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 19:52:18 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on worker-node-2:34115 (size: 5.7 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:52:18 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on worker-node-2:34115 (size: 33.1 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:52:18 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 37) in 98 ms on worker-node-2 (executor 1) (1/1)\n",
      "24/03/14 19:52:18 INFO YarnScheduler: Removed TaskSet 11.0, whose tasks have all completed, from pool \n",
      "24/03/14 19:52:18 INFO DAGScheduler: ResultStage 11 (runJob at PythonRDD.scala:181) finished in 0.113 s\n",
      "24/03/14 19:52:18 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/14 19:52:18 INFO YarnScheduler: Killing all running tasks in stage 11: Stage finished\n",
      "24/03/14 19:52:18 INFO DAGScheduler: Job 11 finished: runJob at PythonRDD.scala:181, took 0.122429 s\n"
     ]
    }
   ],
   "source": [
    "df = rdd.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "210e258a-7dfd-4940-a6ae-8bb091eeea8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 19:52:29 INFO CodeGenerator: Code generated in 15.636463 ms\n",
      "24/03/14 19:52:29 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "24/03/14 19:52:29 INFO DAGScheduler: Got job 12 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/03/14 19:52:29 INFO DAGScheduler: Final stage: ResultStage 12 (showString at NativeMethodAccessorImpl.java:0)\n",
      "24/03/14 19:52:29 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/14 19:52:29 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/14 19:52:29 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[45] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/03/14 19:52:29 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 16.9 KiB, free 365.1 MiB)\n",
      "24/03/14 19:52:29 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 8.9 KiB, free 365.1 MiB)\n",
      "24/03/14 19:52:29 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on master-node:33151 (size: 8.9 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:52:29 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/14 19:52:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[45] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/03/14 19:52:29 INFO YarnScheduler: Adding task set 12.0 with 1 tasks resource profile 0\n",
      "24/03/14 19:52:29 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 38) (worker-node-2, executor 1, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 19:52:30 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on worker-node-2:34115 (size: 8.9 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:52:30 WARN TaskSetManager: Lost task 0.0 in stage 12.0 (TID 38) (worker-node-2 executor 1): java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "24/03/14 19:52:30 INFO TaskSetManager: Starting task 0.1 in stage 12.0 (TID 39) (worker-node-1, executor 2, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 19:52:30 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on worker-node-1:44403 (size: 8.9 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:52:30 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on worker-node-1:44403 (size: 33.1 KiB, free: 366.2 MiB)\n",
      "24/03/14 19:52:30 INFO TaskSetManager: Lost task 0.1 in stage 12.0 (TID 39) on worker-node-1, executor 2: java.lang.IllegalStateException (Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.) [duplicate 1]\n",
      "24/03/14 19:52:30 INFO TaskSetManager: Starting task 0.2 in stage 12.0 (TID 40) (worker-node-2, executor 1, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 19:52:30 INFO TaskSetManager: Lost task 0.2 in stage 12.0 (TID 40) on worker-node-2, executor 1: java.lang.IllegalStateException (Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.) [duplicate 2]\n",
      "24/03/14 19:52:30 INFO TaskSetManager: Starting task 0.3 in stage 12.0 (TID 41) (worker-node-1, executor 2, partition 0, NODE_LOCAL, 7745 bytes) \n",
      "24/03/14 19:52:30 INFO TaskSetManager: Lost task 0.3 in stage 12.0 (TID 41) on worker-node-1, executor 2: java.lang.IllegalStateException (Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.) [duplicate 3]\n",
      "24/03/14 19:52:30 ERROR TaskSetManager: Task 0 in stage 12.0 failed 4 times; aborting job\n",
      "24/03/14 19:52:30 INFO YarnScheduler: Removed TaskSet 12.0, whose tasks have all completed, from pool \n",
      "24/03/14 19:52:30 INFO YarnScheduler: Cancelling stage 12\n",
      "24/03/14 19:52:30 INFO YarnScheduler: Killing all running tasks in stage 12: Stage cancelled: Job aborted due to stage failure: Task 0 in stage 12.0 failed 4 times, most recent failure: Lost task 0.3 in stage 12.0 (TID 41) (worker-node-1 executor 2): java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "Driver stacktrace:\n",
      "24/03/14 19:52:30 INFO DAGScheduler: ResultStage 12 (showString at NativeMethodAccessorImpl.java:0) failed in 0.331 s due to Job aborted due to stage failure: Task 0 in stage 12.0 failed 4 times, most recent failure: Lost task 0.3 in stage 12.0 (TID 41) (worker-node-1 executor 2): java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "Driver stacktrace:\n",
      "24/03/14 19:52:30 INFO DAGScheduler: Job 12 failed: showString at NativeMethodAccessorImpl.java:0, took 0.339405 s\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o297.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 12.0 failed 4 times, most recent failure: Lost task 0.3 in stage 12.0 (TID 41) (worker-node-1 executor 2): java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4332)\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3314)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4322)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4320)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4320)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:3314)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:3537)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:280)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:315)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/dataframe.py:945\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow\u001b[39m(\u001b[38;5;28mself\u001b[39m, n: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, truncate: Union[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, vertical: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    886\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prints the first ``n`` rows to the console.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \n\u001b[1;32m    888\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;124;03m    name | Bob\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 945\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/dataframe.py:963\u001b[0m, in \u001b[0;36mDataFrame._show_string\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m    958\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    959\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(vertical)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m    960\u001b[0m     )\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[0;32m--> 963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o297.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 12.0 failed 4 times, most recent failure: Lost task 0.3 in stage 12.0 (TID 41) (worker-node-1 executor 2): java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4332)\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3314)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4322)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4320)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4320)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:3314)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:3537)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:280)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:315)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. 1 fields are required while 2 values are provided.\n\tat org.apache.spark.sql.execution.python.EvaluatePython$$anonfun$$nestedInanonfun$makeFromJava$16$1.applyOrElse(EvaluatePython.scala:188)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.nullSafeConvert(EvaluatePython.scala:213)\n\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$makeFromJava$16(EvaluatePython.scala:182)\n\tat org.apache.spark.sql.SparkSession.$anonfun$applySchemaToPythonRDD$2(SparkSession.scala:875)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5f78bb-e817-474d-acf5-c0c33bed8740",
   "metadata": {},
   "source": [
    "# 3) H5Py file object file creation from the H5 file "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e74778-0a7d-4324-8ec2-209858a66edc",
   "metadata": {},
   "source": [
    "# Debug: Only one h5File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683ba988-e260-47c7-b9b3-d5d5c9b910ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_file_paths = ['hdfs://master-node:9000/user/hadoop/MillionSongSubset/A/A/A/TRAAAAW128F429D538.h5']\n",
    "h5_file_path = 'hdfs://master-node:9000/user/hadoop/MillionSongSubset/A/A/A/TRAAAAW128F429D538.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf37181a-309b-419c-964e-d48d275fa6d1",
   "metadata": {},
   "source": [
    "# Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6da36c-82e1-4874-af26-f0d9bcbb5800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(file_path):\n",
    "    with h5py.File(file_path, 'r') as file:\n",
    "        song = file['analysis']['songs']\n",
    "        np_song = np.array(song[0])\n",
    "        selected_features = np_song[['danceability', 'duration', 'tempo', 'energy', 'loudness']].ravel()\n",
    "        return selected_features.tolist()\n",
    "        #print(f\"File found: {file_path}\")\n",
    "         #return file_path\n",
    "    # except FileNotFoundError:\n",
    "    #     print(f\"File not found: {file_path}\")\n",
    "    #     return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffc9696-8ccd-476e-8fe4-867491f32e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = spark_context.parallelize(h5_file_path)\n",
    "files_infos_rdd = file_paths.map(extract_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e29e487-ef1d-46c0-829f-708203dafb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(files_infos_rdd.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897df25a-b182-41a3-92a1-f61f9492ddbe",
   "metadata": {},
   "source": [
    "# 4) Create Spark Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6348bf-0f3e-455e-af23-1bf886a2e451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiere das Schema fr den DataFrame\n",
    "schema = StructType([\n",
    "    StructField(\"danceability\", FloatType(), True),\n",
    "    StructField(\"duration\", FloatType(), True),\n",
    "    StructField(\"tempo\", FloatType(), True),\n",
    "    StructField(\"energy\", FloatType(), True),\n",
    "    StructField(\"loudness\", FloatType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e51be1c-caa7-4443-8ecc-e0dece7f6603",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = sqlContext.createDataFrame(files_infos_rdd.flatMap(lambda x: x), schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da17ea8-b186-406f-bf62-f36affa66f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zeige den DataFrame-Inhalt\n",
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75edaf8-3e1f-4173-8f65-b8852bb3b27e",
   "metadata": {},
   "source": [
    "# Calculation (Average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17d4735-196d-40f3-87be-b41dcdabfafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_values = spark_df.agg({'danceability': 'avg', 'duration': 'avg', 'tempo': 'avg', 'energy': 'avg', 'loudness': 'avg'}).collect()[0]\n",
    "print(\"Average Values::\")\n",
    "for col_name, avg_value in average_values.asDict().items():\n",
    "    print(f\"{col_name}: {avg_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805ca167-67d5-4b4e-857c-b11709b1698e",
   "metadata": {},
   "source": [
    "# STOP SPARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23825d7-4cce-458e-82bc-b4dc6995cf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# release the cores\n",
    "spark_context.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39436e22-7c9e-4b0d-ab08-95942846a58c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
