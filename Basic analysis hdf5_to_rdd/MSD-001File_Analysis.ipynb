{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2ed10a-10d1-4734-bbdf-1d54a99fd33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PYTHON\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pyspark\n",
    "\n",
    "#SPARK\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import *\n",
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cfadc70-d70a-45c1-bdd4-99b163eec5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/hadoop/MSD_Project/DataEngineeringProject/Basic analysis hdf5_to_rdd'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_dir = os.getcwd()\n",
    "cur_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3096f2-39bc-4025-9c2c-a216255bdf3f",
   "metadata": {},
   "source": [
    "Spark Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fb6d6aa-4b8d-4c65-8dc1-a61c5d94018d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/14 15:33:59 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n",
      "/home/hadoop/.local/lib/python3.8/site-packages/pyspark/sql/context.py:113: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Spark Session - 2 cores\n",
    "spark_session = SparkSession.builder \\\n",
    "    .appName(\"Test_1File\") \\\n",
    "    .master(\"yarn\") \\\n",
    "    .config(\"spark.executor.instances\", \"2\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# RDD API\n",
    "spark_context = spark_session.sparkContext\n",
    "spark_context.setLogLevel(\"INFO\")\n",
    "\n",
    "sqlContext = SQLContext(spark_session.sparkContext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44667861-4446-4677-adf9-5acf17142cc4",
   "metadata": {},
   "source": [
    "File Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85b6e7bf-1a3a-4aab-af97-04bad4192b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_roots = ['hdfs://130.238.29.183:9000//input/millionsongsubset.tar.gz']\n",
    "#directory_path = \"data/B/A/A\"\n",
    "#directory_path = \"/home/hadoop/MillionSongSubset/A/A/A\"\n",
    "directory_path = \"/MillionSongSubset/A/A/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c16c95d-fef0-4b3e-8444-ffc6b148f490",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = spark_session.read.text(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69175af8-e2c0-44d8-a99c-39d57f3c4b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/07 21:46:46 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\n",
      "24/03/07 21:46:46 INFO SharedState: Warehouse path is 'file:/home/hadoop/MSD_Project/DataEngineeringProject/Basic%20analysis%20hdf5_to_rdd/spark-warehouse'.\n",
      "24/03/07 21:46:46 INFO ServerInfo: Adding filter to /SQL: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter\n",
      "24/03/07 21:46:46 INFO ServerInfo: Adding filter to /SQL/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter\n",
      "24/03/07 21:46:46 INFO ServerInfo: Adding filter to /SQL/execution: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter\n",
      "24/03/07 21:46:46 INFO ServerInfo: Adding filter to /SQL/execution/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter\n",
      "24/03/07 21:46:46 INFO ServerInfo: Adding filter to /static/sql: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter\n",
      "24/03/07 21:46:47 INFO InMemoryFileIndex: It took 55 ms to list leaf files for 1 paths.\n"
     ]
    }
   ],
   "source": [
    "textFile = spark_session.read.text(\"test_hdfs.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdd69e39-f403-457e-a19b-397e881d1768",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/07 21:47:15 INFO FileSourceStrategy: Pushed Filters: \n",
      "24/03/07 21:47:15 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "24/03/07 21:47:15 INFO CodeGenerator: Code generated in 296.142606 ms\n",
      "24/03/07 21:47:15 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 353.5 KiB, free 366.0 MiB)\n",
      "24/03/07 21:47:15 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 35.7 KiB, free 365.9 MiB)\n",
      "24/03/07 21:47:15 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on master-node:44843 (size: 35.7 KiB, free: 366.3 MiB)\n",
      "24/03/07 21:47:15 INFO SparkContext: Created broadcast 0 from showString at NativeMethodAccessorImpl.java:0\n",
      "24/03/07 21:47:15 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "24/03/07 21:47:16 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "24/03/07 21:47:16 INFO DAGScheduler: Got job 0 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/03/07 21:47:16 INFO DAGScheduler: Final stage: ResultStage 0 (showString at NativeMethodAccessorImpl.java:0)\n",
      "24/03/07 21:47:16 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/07 21:47:16 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/07 21:47:16 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/03/07 21:47:16 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.9 KiB, free 365.9 MiB)\n",
      "24/03/07 21:47:16 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 365.9 MiB)\n",
      "24/03/07 21:47:16 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on master-node:44843 (size: 6.1 KiB, free: 366.3 MiB)\n",
      "24/03/07 21:47:16 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/07 21:47:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/03/07 21:47:16 INFO YarnScheduler: Adding task set 0.0 with 1 tasks resource profile 0\n",
      "24/03/07 21:47:16 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (worker-node-1, executor 1, partition 0, NODE_LOCAL, 8238 bytes) \n",
      "24/03/07 21:47:16 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on worker-node-1:34511 (size: 6.1 KiB, free: 366.3 MiB)\n",
      "24/03/07 21:47:18 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on worker-node-1:34511 (size: 35.7 KiB, free: 366.3 MiB)\n",
      "24/03/07 21:47:18 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2516 ms on worker-node-1 (executor 1) (1/1)\n",
      "24/03/07 21:47:18 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "24/03/07 21:47:18 INFO DAGScheduler: ResultStage 0 (showString at NativeMethodAccessorImpl.java:0) finished in 2.668 s\n",
      "24/03/07 21:47:18 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/07 21:47:18 INFO YarnScheduler: Killing all running tasks in stage 0: Stage finished\n",
      "24/03/07 21:47:18 INFO DAGScheduler: Job 0 finished: showString at NativeMethodAccessorImpl.java:0, took 2.750998 s\n",
      "24/03/07 21:47:19 INFO BlockManagerInfo: Removed broadcast_1_piece0 on master-node:44843 in memory (size: 6.1 KiB, free: 366.3 MiB)\n",
      "24/03/07 21:47:19 INFO BlockManagerInfo: Removed broadcast_1_piece0 on worker-node-1:34511 in memory (size: 6.1 KiB, free: 366.3 MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|        value|\n",
      "+-------------+\n",
      "|test for hdfs|\n",
      "+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/07 21:47:20 INFO CodeGenerator: Code generated in 21.868835 ms\n"
     ]
    }
   ],
   "source": [
    "textFile.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1333b60e-ef05-446a-86ff-7c0cbcd0a7c7",
   "metadata": {},
   "source": [
    "# 1) Saving the paths to the HDF5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60b92eef-ad69-49de-8bb6-fc9907ff326f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 filenames gathered (PYTHON)\n"
     ]
    }
   ],
   "source": [
    "# GET .H5 FILENAMES\n",
    "h5_file_paths = []\n",
    "for root, _, files in os.walk(directory_path):\n",
    "    for name in files:\n",
    "        h5_file_paths.append(os.path.join(root, name))\n",
    "\n",
    "print('{} filenames gathered (PYTHON)'.format(len(h5_file_paths)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa39ddd-8486-42f6-86fd-dc7741270519",
   "metadata": {},
   "source": [
    "# 2) List h5_file_paths is converted to RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd1391e3-6cfe-4623-bc8e-d21ac0212b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = spark_context.parallelize(h5_file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc5b8a3d-e994-4f86-8feb-e66f5105e5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/07 21:27:36 INFO SparkContext: Starting job: runJob at PythonRDD.scala:181\n",
      "24/03/07 21:27:36 INFO DAGScheduler: Got job 0 (runJob at PythonRDD.scala:181) with 1 output partitions\n",
      "24/03/07 21:27:36 INFO DAGScheduler: Final stage: ResultStage 0 (runJob at PythonRDD.scala:181)\n",
      "24/03/07 21:27:36 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/07 21:27:36 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/07 21:27:36 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[1] at RDD at PythonRDD.scala:53), which has no missing parents\n",
      "24/03/07 21:27:36 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.9 KiB, free 366.3 MiB)\n",
      "24/03/07 21:27:36 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 366.3 MiB)\n",
      "24/03/07 21:27:36 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on master-node:41003 (size: 3.8 KiB, free: 366.3 MiB)\n",
      "24/03/07 21:27:36 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/07 21:27:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (PythonRDD[1] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))\n",
      "24/03/07 21:27:36 INFO YarnScheduler: Adding task set 0.0 with 1 tasks resource profile 0\n",
      "24/03/07 21:27:36 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (worker-node-1, executor 1, partition 0, PROCESS_LOCAL, 7606 bytes) \n",
      "24/03/07 21:27:36 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on worker-node-1:36215 (size: 3.8 KiB, free: 366.3 MiB)\n",
      "24/03/07 21:27:37 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1203 ms on worker-node-1 (executor 1) (1/1)\n",
      "24/03/07 21:27:37 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "24/03/07 21:27:37 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 36943\n",
      "24/03/07 21:27:37 INFO DAGScheduler: ResultStage 0 (runJob at PythonRDD.scala:181) finished in 1.414 s\n",
      "24/03/07 21:27:37 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/07 21:27:37 INFO YarnScheduler: Killing all running tasks in stage 0: Stage finished\n",
      "24/03/07 21:27:37 INFO DAGScheduler: Job 0 finished: runJob at PythonRDD.scala:181, took 1.477685 s\n",
      "24/03/07 21:27:37 INFO SparkContext: Starting job: runJob at PythonRDD.scala:181\n",
      "24/03/07 21:27:37 INFO DAGScheduler: Got job 1 (runJob at PythonRDD.scala:181) with 1 output partitions\n",
      "24/03/07 21:27:37 INFO DAGScheduler: Final stage: ResultStage 1 (runJob at PythonRDD.scala:181)\n",
      "24/03/07 21:27:37 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/07 21:27:37 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/07 21:27:37 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[2] at RDD at PythonRDD.scala:53), which has no missing parents\n",
      "24/03/07 21:27:37 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 5.9 KiB, free 366.3 MiB)\n",
      "24/03/07 21:27:37 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 366.3 MiB)\n",
      "24/03/07 21:27:37 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on master-node:41003 (size: 3.8 KiB, free: 366.3 MiB)\n",
      "24/03/07 21:27:37 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585\n",
      "24/03/07 21:27:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (PythonRDD[2] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(1))\n",
      "24/03/07 21:27:37 INFO YarnScheduler: Adding task set 1.0 with 1 tasks resource profile 0\n",
      "24/03/07 21:27:37 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (worker-node-2, executor 2, partition 1, PROCESS_LOCAL, 7606 bytes) \n",
      "24/03/07 21:27:37 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on worker-node-2:38777 (size: 3.8 KiB, free: 366.3 MiB)\n",
      "24/03/07 21:27:38 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1196 ms on worker-node-2 (executor 2) (1/1)\n",
      "24/03/07 21:27:38 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool \n",
      "24/03/07 21:27:38 INFO DAGScheduler: ResultStage 1 (runJob at PythonRDD.scala:181) finished in 1.215 s\n",
      "24/03/07 21:27:38 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/07 21:27:38 INFO YarnScheduler: Killing all running tasks in stage 1: Stage finished\n",
      "24/03/07 21:27:38 INFO DAGScheduler: Job 1 finished: runJob at PythonRDD.scala:181, took 1.226505 s\n",
      "                                                                                \r"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "RDD is empty",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m file_first \u001b[38;5;241m=\u001b[39m \u001b[43mfile_paths\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfirst\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/rdd.py:2891\u001b[0m, in \u001b[0;36mRDD.first\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2889\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rs:\n\u001b[1;32m   2890\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 2891\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRDD is empty\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: RDD is empty"
     ]
    }
   ],
   "source": [
    "file_first = file_paths.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5f78bb-e817-474d-acf5-c0c33bed8740",
   "metadata": {},
   "source": [
    "# 3) H5Py file object file creation from the H5 file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ffc9696-8ccd-476e-8fe4-867491f32e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = h5py.File(file_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f6e36e6-b1d6-4908-b884-224a526a1ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['analysis', 'metadata', 'musicbrainz']>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e302b550-397d-49d0-906b-80bdd8a63917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 group \"/analysis\" (16 members)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file['analysis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89bdb238-f333-4c6b-9d0b-b7a1c5f4761d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bars_confidence', 'bars_start', 'beats_confidence', 'beats_start', 'sections_confidence', 'sections_start', 'segments_confidence', 'segments_loudness_max', 'segments_loudness_max_time', 'segments_loudness_start', 'segments_pitches', 'segments_start', 'segments_timbre', 'songs', 'tatums_confidence', 'tatums_start']\n",
      "['artist_terms', 'artist_terms_freq', 'artist_terms_weight', 'similar_artists', 'songs']\n",
      "['artist_mbtags', 'artist_mbtags_count', 'songs']\n"
     ]
    }
   ],
   "source": [
    "print(list(file['analysis']))\n",
    "print(list(file['metadata']))\n",
    "print(list(file['musicbrainz']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c15f116e-1617-429d-8d2f-f465ec83d05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(22050, b'9938b27e93cf7a47816625bc53ab7920', 0., 210.75546, 0.153, 0., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0.401, -4.188, 0, 0.471, 203.122, 150.03, 4, 0.57, b'TRBAASG128F92FBB7C')]\n",
      "[(b'', 457243, 0.45537186, 0.3138666, b'AROLMXS1241B9C6915', nan, b'', nan, b'', b'An Cafe', -1, b'', 0, 0, b'Magnya Carta', 395941, nan, b'SOPIHNL12A8C13B28D', b'Pipopapo Telpathy', 4393959)]\n",
      "[(0, 0)]\n"
     ]
    }
   ],
   "source": [
    "print(list(file['analysis']['songs']))\n",
    "print(list(file['metadata']['songs']))\n",
    "print(list(file['musicbrainz']['songs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e37fc33-3a20-4ecb-842f-d5aaaf434065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"songs\": shape (1,), type \"|V220\">"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song = file['analysis']['songs']\n",
    "song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f4b337e-ea90-452c-addc-ce4e8f73d891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array((22050, b'9938b27e93cf7a47816625bc53ab7920', 0., 210.75546, 0.153, 0., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0.401, -4.188, 0, 0.471, 203.122, 150.03, 4, 0.57, b'TRBAASG128F92FBB7C'),\n",
       "      dtype=[('analysis_sample_rate', '<i4'), ('audio_md5', 'S32'), ('danceability', '<f8'), ('duration', '<f8'), ('end_of_fade_in', '<f8'), ('energy', '<f8'), ('idx_bars_confidence', '<i4'), ('idx_bars_start', '<i4'), ('idx_beats_confidence', '<i4'), ('idx_beats_start', '<i4'), ('idx_sections_confidence', '<i4'), ('idx_sections_start', '<i4'), ('idx_segments_confidence', '<i4'), ('idx_segments_loudness_max', '<i4'), ('idx_segments_loudness_max_time', '<i4'), ('idx_segments_loudness_start', '<i4'), ('idx_segments_pitches', '<i4'), ('idx_segments_start', '<i4'), ('idx_segments_timbre', '<i4'), ('idx_tatums_confidence', '<i4'), ('idx_tatums_start', '<i4'), ('key', '<i4'), ('key_confidence', '<f8'), ('loudness', '<f8'), ('mode', '<i4'), ('mode_confidence', '<f8'), ('start_of_fade_out', '<f8'), ('tempo', '<f8'), ('time_signature', '<i4'), ('time_signature_confidence', '<f8'), ('track_id', 'S32')])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_song = np.array(song[0])\n",
    "np_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8290b680-df0b-4e3c-b82f-854d0fabe1c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(0., 210.75546, 150.03, 0., -4.188)],\n",
       "      dtype={'names': ['danceability', 'duration', 'tempo', 'energy', 'loudness'], 'formats': ['<f8', '<f8', '<f8', '<f8', '<f8'], 'offsets': [36, 44, 168, 60, 140], 'itemsize': 220})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features = np_song[['danceability', 'duration', 'tempo', 'energy', 'loudness']].ravel()\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf3def56-715b-48a6-82b1-e2725876b7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/01 10:37:58 INFO SparkContext: Starting job: runJob at PythonRDD.scala:181\n",
      "24/03/01 10:37:58 INFO DAGScheduler: Got job 1 (runJob at PythonRDD.scala:181) with 1 output partitions\n",
      "24/03/01 10:37:58 INFO DAGScheduler: Final stage: ResultStage 1 (runJob at PythonRDD.scala:181)\n",
      "24/03/01 10:37:58 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/01 10:37:58 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/01 10:37:59 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[3] at RDD at PythonRDD.scala:53), which has no missing parents\n",
      "24/03/01 10:37:59 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 5.8 KiB, free 413.9 MiB)\n",
      "24/03/01 10:37:59 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 413.9 MiB)\n",
      "24/03/01 10:37:59 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on host-192-168-2-34-de1:46587 (size: 3.8 KiB, free: 413.9 MiB)\n",
      "24/03/01 10:37:59 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1580\n",
      "24/03/01 10:37:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (PythonRDD[3] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))\n",
      "24/03/01 10:37:59 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0\n",
      "24/03/01 10:37:59 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (host-192-168-2-34-de1, executor driver, partition 0, PROCESS_LOCAL, 7595 bytes) \n",
      "24/03/01 10:37:59 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)\n",
      "24/03/01 10:37:59 INFO BlockManagerInfo: Removed broadcast_0_piece0 on host-192-168-2-34-de1:46587 in memory (size: 3.8 KiB, free: 413.9 MiB)\n",
      "24/03/01 10:37:59 INFO PythonRunner: Times: total = 58, boot = 47, init = 10, finish = 1\n",
      "24/03/01 10:37:59 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1326 bytes result sent to driver\n",
      "24/03/01 10:37:59 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 138 ms on host-192-168-2-34-de1 (executor driver) (1/1)\n",
      "24/03/01 10:37:59 INFO DAGScheduler: ResultStage 1 (runJob at PythonRDD.scala:181) finished in 0.220 s\n",
      "24/03/01 10:37:59 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/01 10:37:59 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool \n",
      "24/03/01 10:37:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished\n",
      "24/03/01 10:37:59 INFO DAGScheduler: Job 1 finished: runJob at PythonRDD.scala:181, took 0.245689 s\n",
      "24/03/01 10:37:59 INFO SparkContext: Starting job: runJob at PythonRDD.scala:181\n",
      "24/03/01 10:37:59 INFO DAGScheduler: Got job 2 (runJob at PythonRDD.scala:181) with 1 output partitions\n",
      "24/03/01 10:37:59 INFO DAGScheduler: Final stage: ResultStage 2 (runJob at PythonRDD.scala:181)\n",
      "24/03/01 10:37:59 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/01 10:37:59 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/01 10:37:59 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[4] at RDD at PythonRDD.scala:53), which has no missing parents\n",
      "24/03/01 10:37:59 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.8 KiB, free 413.9 MiB)\n",
      "24/03/01 10:37:59 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 413.9 MiB)\n",
      "24/03/01 10:37:59 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on host-192-168-2-34-de1:46587 (size: 3.8 KiB, free: 413.9 MiB)\n",
      "24/03/01 10:37:59 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1580\n",
      "24/03/01 10:37:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (PythonRDD[4] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(1))\n",
      "24/03/01 10:37:59 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0\n",
      "24/03/01 10:37:59 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (host-192-168-2-34-de1, executor driver, partition 1, PROCESS_LOCAL, 8205 bytes) \n",
      "24/03/01 10:37:59 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)\n",
      "24/03/01 10:37:59 INFO PythonRunner: Times: total = 16, boot = 1, init = 15, finish = 0\n",
      "24/03/01 10:37:59 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1909 bytes result sent to driver\n",
      "24/03/01 10:37:59 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 76 ms on host-192-168-2-34-de1 (executor driver) (1/1)\n",
      "24/03/01 10:37:59 INFO DAGScheduler: ResultStage 2 (runJob at PythonRDD.scala:181) finished in 0.121 s\n",
      "24/03/01 10:37:59 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/01 10:37:59 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool \n",
      "24/03/01 10:37:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished\n",
      "24/03/01 10:37:59 INFO DAGScheduler: Job 2 finished: runJob at PythonRDD.scala:181, took 0.133822 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0., 210.75546, 150.03, 0., -4.188),)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_data = spark_context.parallelize([tuple(selected_features)])\n",
    "rdd_data.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc09173-b5b1-4e90-8930-81931b14507d",
   "metadata": {},
   "source": [
    "# Convertion to pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3ca5964-0221-4f4f-8bd0-1bde758f4942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration</th>\n",
       "      <th>tempo</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>210.75546</td>\n",
       "      <td>150.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   danceability   duration   tempo  energy  loudness\n",
       "0           0.0  210.75546  150.03     0.0    -4.188"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.DataFrame(selected_features)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75018dbf-9c85-4938-afff-200e5dc096e4",
   "metadata": {},
   "source": [
    "# Convertion to Spark - Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b92a29b-6c68-45f4-a2f9-e29c36e5533c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/01 10:40:20 INFO BlockManagerInfo: Removed broadcast_2_piece0 on host-192-168-2-34-de1:46587 in memory (size: 3.8 KiB, free: 413.9 MiB)\n",
      "24/03/01 10:40:20 INFO BlockManagerInfo: Removed broadcast_1_piece0 on host-192-168-2-34-de1:46587 in memory (size: 3.8 KiB, free: 413.9 MiB)\n",
      "24/03/01 10:40:20 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\n",
      "24/03/01 10:40:20 INFO SharedState: Warehouse path is 'file:/home/ubuntu/dataeng1/Project/spark-warehouse'.\n"
     ]
    }
   ],
   "source": [
    "columns = ['danceability', 'duration', 'tempo', 'energy', 'loudness']\n",
    "df = sqlContext.createDataFrame(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa21248-8de1-4626-90e2-aac670bda962",
   "metadata": {},
   "source": [
    "# Calculation of statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "842772e8-7abe-4bd9-9b6c-0f05d25cdbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/01 10:40:30 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "24/03/01 10:40:32 INFO CodeGenerator: Code generated in 1103.189511 ms\n",
      "24/03/01 10:40:32 INFO DAGScheduler: Registering RDD 11 (collect at /tmp/ipykernel_52445/3345987588.py:1) as input to shuffle 0\n",
      "24/03/01 10:40:32 INFO DAGScheduler: Got map stage job 3 (collect at /tmp/ipykernel_52445/3345987588.py:1) with 2 output partitions\n",
      "24/03/01 10:40:32 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (collect at /tmp/ipykernel_52445/3345987588.py:1)\n",
      "24/03/01 10:40:32 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/01 10:40:32 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/01 10:40:32 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[11] at collect at /tmp/ipykernel_52445/3345987588.py:1), which has no missing parents\n",
      "24/03/01 10:40:32 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 63.0 KiB, free 413.9 MiB)\n",
      "24/03/01 10:40:32 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 20.3 KiB, free 413.8 MiB)\n",
      "24/03/01 10:40:32 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on host-192-168-2-34-de1:46587 (size: 20.3 KiB, free: 413.9 MiB)\n",
      "24/03/01 10:40:32 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1580\n",
      "24/03/01 10:40:32 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[11] at collect at /tmp/ipykernel_52445/3345987588.py:1) (first 15 tasks are for partitions Vector(0, 1))\n",
      "24/03/01 10:40:32 INFO TaskSchedulerImpl: Adding task set 3.0 with 2 tasks resource profile 0\n",
      "24/03/01 10:40:32 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (host-192-168-2-34-de1, executor driver, partition 0, PROCESS_LOCAL, 7584 bytes) \n",
      "24/03/01 10:40:32 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 4) (host-192-168-2-34-de1, executor driver, partition 1, PROCESS_LOCAL, 7657 bytes) \n",
      "24/03/01 10:40:32 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)\n",
      "24/03/01 10:40:32 INFO Executor: Running task 1.0 in stage 3.0 (TID 4)\n",
      "24/03/01 10:40:33 INFO CodeGenerator: Code generated in 462.743358 ms0 + 2) / 2]\n",
      "24/03/01 10:40:33 INFO PythonRunner: Times: total = 33, boot = 25, init = 8, finish = 0\n",
      "24/03/01 10:40:33 INFO PythonRunner: Times: total = 63, boot = 44, init = 19, finish = 0\n",
      "24/03/01 10:40:33 INFO Executor: Finished task 1.0 in stage 3.0 (TID 4). 2328 bytes result sent to driver\n",
      "24/03/01 10:40:33 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2371 bytes result sent to driver\n",
      "24/03/01 10:40:33 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 1074 ms on host-192-168-2-34-de1 (executor driver) (1/2)\n",
      "24/03/01 10:40:33 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 4) in 1075 ms on host-192-168-2-34-de1 (executor driver) (2/2)\n",
      "24/03/01 10:40:33 INFO DAGScheduler: ShuffleMapStage 3 (collect at /tmp/ipykernel_52445/3345987588.py:1) finished in 1.197 s\n",
      "24/03/01 10:40:33 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/03/01 10:40:33 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool \n",
      "24/03/01 10:40:33 INFO DAGScheduler: running: Set()\n",
      "24/03/01 10:40:33 INFO DAGScheduler: waiting: Set()\n",
      "24/03/01 10:40:33 INFO DAGScheduler: failed: Set()\n",
      "24/03/01 10:40:34 INFO CodeGenerator: Code generated in 299.972228 ms\n",
      "24/03/01 10:40:34 INFO SparkContext: Starting job: collect at /tmp/ipykernel_52445/3345987588.py:1\n",
      "24/03/01 10:40:34 INFO DAGScheduler: Got job 4 (collect at /tmp/ipykernel_52445/3345987588.py:1) with 1 output partitions\n",
      "24/03/01 10:40:34 INFO DAGScheduler: Final stage: ResultStage 5 (collect at /tmp/ipykernel_52445/3345987588.py:1)\n",
      "24/03/01 10:40:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)\n",
      "24/03/01 10:40:34 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/01 10:40:34 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[14] at collect at /tmp/ipykernel_52445/3345987588.py:1), which has no missing parents\n",
      "24/03/01 10:40:34 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 65.0 KiB, free 413.8 MiB)\n",
      "24/03/01 10:40:34 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 413.8 MiB)\n",
      "24/03/01 10:40:34 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on host-192-168-2-34-de1:46587 (size: 19.8 KiB, free: 413.9 MiB)\n",
      "24/03/01 10:40:34 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1580\n",
      "24/03/01 10:40:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[14] at collect at /tmp/ipykernel_52445/3345987588.py:1) (first 15 tasks are for partitions Vector(0))\n",
      "24/03/01 10:40:34 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0\n",
      "24/03/01 10:40:34 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (host-192-168-2-34-de1, executor driver, partition 0, NODE_LOCAL, 7615 bytes) \n",
      "24/03/01 10:40:34 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)\n",
      "24/03/01 10:40:34 INFO ShuffleBlockFetcherIterator: Getting 2 (237.0 B) non-empty blocks including 2 (237.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/03/01 10:40:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 31 ms\n",
      "24/03/01 10:40:34 INFO CodeGenerator: Code generated in 222.841544 ms\n",
      "24/03/01 10:40:34 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 4081 bytes result sent to driver\n",
      "24/03/01 10:40:34 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 428 ms on host-192-168-2-34-de1 (executor driver) (1/1)\n",
      "24/03/01 10:40:34 INFO DAGScheduler: ResultStage 5 (collect at /tmp/ipykernel_52445/3345987588.py:1) finished in 0.464 s\n",
      "24/03/01 10:40:34 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/01 10:40:34 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool \n",
      "24/03/01 10:40:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished\n",
      "24/03/01 10:40:34 INFO DAGScheduler: Job 4 finished: collect at /tmp/ipykernel_52445/3345987588.py:1, took 0.496634 s\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "summary = df.select(\n",
    "    mean('danceability').alias('mean_danceability'),\n",
    "    min('danceability').alias('min_danceability'),\n",
    "    max('danceability').alias('max_danceability'),\n",
    "    stddev('danceability').alias('stddev_danceability'),\n",
    "    \n",
    "    mean('duration').alias('mean_duration'),\n",
    "    min('duration').alias('min_duration'),\n",
    "    max('duration').alias('max_duration'),\n",
    "    stddev('duration').alias('stddev_duration'),\n",
    "    \n",
    "    mean('tempo').alias('mean_tempo'),\n",
    "    min('tempo').alias('min_tempo'),\n",
    "    max('tempo').alias('max_tempo'),\n",
    "    stddev('tempo').alias('stddev_tempo'),\n",
    "    \n",
    "    mean('energy').alias('mean_energy'),\n",
    "    min('energy').alias('min_energy'),\n",
    "    max('energy').alias('max_energy'),\n",
    "    stddev('energy').alias('stddev_energy'),\n",
    "    \n",
    "    mean('loudness').alias('mean_loudness'),\n",
    "    min('loudness').alias('min_loudness'),\n",
    "    max('loudness').alias('max_loudness'),\n",
    "    stddev('loudness').alias('stddev_loudness')\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "38716974-8f49-44d3-988f-77c0bccfad55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/01 10:48:16 INFO DAGScheduler: Registering RDD 76 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 13\n",
      "24/03/01 10:48:16 INFO DAGScheduler: Got map stage job 29 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions\n",
      "24/03/01 10:48:16 INFO DAGScheduler: Final stage: ShuffleMapStage 42 (count at NativeMethodAccessorImpl.java:0)\n",
      "24/03/01 10:48:16 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/01 10:48:16 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/01 10:48:16 INFO DAGScheduler: Submitting ShuffleMapStage 42 (MapPartitionsRDD[76] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/03/01 10:48:16 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 15.9 KiB, free 413.8 MiB)\n",
      "24/03/01 10:48:16 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 413.8 MiB)\n",
      "24/03/01 10:48:16 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on host-192-168-2-34-de1:46587 (size: 8.3 KiB, free: 413.9 MiB)\n",
      "24/03/01 10:48:16 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1580\n",
      "24/03/01 10:48:16 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[76] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))\n",
      "24/03/01 10:48:16 INFO TaskSchedulerImpl: Adding task set 42.0 with 2 tasks resource profile 0\n",
      "24/03/01 10:48:16 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 42) (host-192-168-2-34-de1, executor driver, partition 0, PROCESS_LOCAL, 7584 bytes) \n",
      "24/03/01 10:48:16 INFO TaskSetManager: Starting task 1.0 in stage 42.0 (TID 43) (host-192-168-2-34-de1, executor driver, partition 1, PROCESS_LOCAL, 7657 bytes) \n",
      "24/03/01 10:48:16 INFO Executor: Running task 0.0 in stage 42.0 (TID 42)\n",
      "24/03/01 10:48:16 INFO Executor: Running task 1.0 in stage 42.0 (TID 43)\n",
      "24/03/01 10:48:16 INFO PythonRunner: Times: total = 15, boot = -11775, init = 11789, finish = 1\n",
      "24/03/01 10:48:16 INFO Executor: Finished task 0.0 in stage 42.0 (TID 42). 2328 bytes result sent to driver\n",
      "24/03/01 10:48:16 INFO PythonRunner: Times: total = 7, boot = -11767, init = 11774, finish = 0\n",
      "24/03/01 10:48:16 INFO Executor: Finished task 1.0 in stage 42.0 (TID 43). 2285 bytes result sent to driver\n",
      "24/03/01 10:48:16 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 42) in 63 ms on host-192-168-2-34-de1 (executor driver) (1/2)\n",
      "24/03/01 10:48:16 INFO TaskSetManager: Finished task 1.0 in stage 42.0 (TID 43) in 66 ms on host-192-168-2-34-de1 (executor driver) (2/2)\n",
      "24/03/01 10:48:16 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool \n",
      "24/03/01 10:48:16 INFO DAGScheduler: ShuffleMapStage 42 (count at NativeMethodAccessorImpl.java:0) finished in 0.088 s\n",
      "24/03/01 10:48:16 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/03/01 10:48:16 INFO DAGScheduler: running: Set()\n",
      "24/03/01 10:48:16 INFO DAGScheduler: waiting: Set()\n",
      "24/03/01 10:48:16 INFO DAGScheduler: failed: Set()\n",
      "24/03/01 10:48:16 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0\n",
      "24/03/01 10:48:16 INFO DAGScheduler: Got job 30 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/03/01 10:48:16 INFO DAGScheduler: Final stage: ResultStage 44 (count at NativeMethodAccessorImpl.java:0)\n",
      "24/03/01 10:48:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 43)\n",
      "24/03/01 10:48:16 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/01 10:48:16 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[79] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/03/01 10:48:16 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 12.5 KiB, free 413.8 MiB)\n",
      "24/03/01 10:48:17 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 413.8 MiB)\n",
      "24/03/01 10:48:17 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on host-192-168-2-34-de1:46587 (size: 5.9 KiB, free: 413.9 MiB)\n",
      "24/03/01 10:48:17 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1580\n",
      "24/03/01 10:48:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[79] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/03/01 10:48:17 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks resource profile 0\n",
      "24/03/01 10:48:17 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 44) (host-192-168-2-34-de1, executor driver, partition 0, NODE_LOCAL, 7615 bytes) \n",
      "24/03/01 10:48:17 INFO Executor: Running task 0.0 in stage 44.0 (TID 44)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of songs contributing to the calculation: 1\n",
      "\n",
      "mean_danceability:\t0.0\n",
      "min_danceability:\t0.0\n",
      "max_danceability:\t0.0\n",
      "stddev_danceability:\tNone\n",
      "mean_duration:\t210.75546\n",
      "min_duration:\t210.75546\n",
      "max_duration:\t210.75546\n",
      "stddev_duration:\tNone\n",
      "mean_tempo:\t150.03\n",
      "min_tempo:\t150.03\n",
      "max_tempo:\t150.03\n",
      "stddev_tempo:\tNone\n",
      "mean_energy:\t0.0\n",
      "min_energy:\t0.0\n",
      "max_energy:\t0.0\n",
      "stddev_energy:\tNone\n",
      "mean_loudness:\t-4.188\n",
      "min_loudness:\t-4.188\n",
      "max_loudness:\t-4.188\n",
      "stddev_loudness:\tNone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/01 10:48:17 INFO ShuffleBlockFetcherIterator: Getting 2 (120.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/03/01 10:48:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms\n",
      "24/03/01 10:48:17 INFO Executor: Finished task 0.0 in stage 44.0 (TID 44). 4038 bytes result sent to driver\n",
      "24/03/01 10:48:17 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 44) in 47 ms on host-192-168-2-34-de1 (executor driver) (1/1)\n",
      "24/03/01 10:48:17 INFO DAGScheduler: ResultStage 44 (count at NativeMethodAccessorImpl.java:0) finished in 0.064 s\n",
      "24/03/01 10:48:17 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/01 10:48:17 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool \n",
      "24/03/01 10:48:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 44: Stage finished\n",
      "24/03/01 10:48:17 INFO DAGScheduler: Job 30 finished: count at NativeMethodAccessorImpl.java:0, took 0.078712 s\n",
      "24/03/01 10:48:17 INFO BlockManagerInfo: Removed broadcast_29_piece0 on host-192-168-2-34-de1:46587 in memory (size: 8.3 KiB, free: 413.9 MiB)\n",
      "24/03/01 10:48:17 INFO BlockManagerInfo: Removed broadcast_28_piece0 on host-192-168-2-34-de1:46587 in memory (size: 5.9 KiB, free: 413.9 MiB)\n"
     ]
    }
   ],
   "source": [
    "# Anzahl der Songs im DataFrame\n",
    "num_songs = df.count()\n",
    "print(f\"\\nNumber of songs contributing to the calculation: {num_songs}\")\n",
    "print()\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "for i, row in enumerate(summary, start=1):\n",
    "    for col in row.asDict():\n",
    "        print(f\"{col}:\\t{row[col]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9720ab9e-2743-4ab4-86a6-5e4d7d999d5e",
   "metadata": {},
   "source": [
    "# ----------------- Other contents of the song data ------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ab9721b1-2937-4bfc-aa2c-7ed33339ae9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'dance rock']\n",
      "Length: 1\n"
     ]
    }
   ],
   "source": [
    "dataset_value = file['metadata']['artist_terms'][:]\n",
    "print(dataset_value)\n",
    "print(\"Length:\", len(dataset_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6b122103-26fa-45a4-899a-647cb1caac1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n",
      "Length: 1\n"
     ]
    }
   ],
   "source": [
    "dataset_value = file['metadata']['artist_terms_freq'][:]\n",
    "print(dataset_value)\n",
    "print(\"Length:\", len(dataset_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "204bb940-9073-40b3-bb89-f76270fa3cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'AR7XLQX1187B99A7EA' b'AREVXEQ12086C1134E' b'AR47RE6119B8668F53'\n",
      " b'ARQ1Q9X1187FB47A97' b'ART5G6A1187FB501EF' b'AR8B0LB1187B9B9A00'\n",
      " b'ARSFIZV12509415792' b'ARFBMCW122988FF6AB' b'ARQYLGZ12AF7DA825B'\n",
      " b'ARN0OPB1187FB3BB94' b'ARYQSVT123526A064F' b'AR83XCX1187B9AEED2'\n",
      " b'ARJUPUZ12802FDEAA6' b'ARGUT1W1187FB5AF5B' b'ARMMNNW12AA61C90AA'\n",
      " b'ARZISWL11F4C844108' b'ARJAAWU1187FB55EAC' b'ARJF4HD1187FB3731B'\n",
      " b'ARAVUNG1269FB31D22' b'ARHFRME122988FCF98' b'AR9NHBO119B86678BB'\n",
      " b'ARF08S41187B992B72' b'ARKMR711187FB3CA5A' b'AR4M5UL11C8A4160FE'\n",
      " b'AR9SU0S1187FB53D0F' b'ARHV8FW1187FB452AA' b'ARXPZTL1257509E207'\n",
      " b'ARAAC0U1187FB59BA9' b'AR8EE6Q1187B9978E7' b'ARXTEEE1269FCD7AF6'\n",
      " b'ARD8L7F1187FB430B3' b'ARVPUOZ12AF7D8E25B' b'ARAGYDJ11F50C4DE49'\n",
      " b'ARQHRLD1187FB38A89' b'ARGAT011187FB4FB90' b'ARLBNSN122988ED42B'\n",
      " b'ARRQ2TB1187B9A9890' b'AR85JLJ1187B98A3C4' b'ARXZTVV11F43A69F15'\n",
      " b'AR5Y3W01187FB47D6F' b'AR324A81187B9A8EDF' b'AR3U9B41187FB3B1A9'\n",
      " b'ARZA3WL11C8A42C824' b'AR19UAA1187FB3BDFA' b'ARTJ7RD1187FB4AEAF'\n",
      " b'ARYQTKZ12420781B58' b'ARKFPPT122988F55D6' b'ARCBT9D1187FB38309'\n",
      " b'ARY11F11187FB4A27D' b'ARMUIYM11E2835D7BE' b'AR4MRF41187FB5B646'\n",
      " b'ARNFXPT1187FB39D5B' b'ARJSR8D1187B9976E0' b'ARGM9ZK1187FB3F1A1'\n",
      " b'ARRY23Q1187B9B4083' b'ARN01351187FB5A6F0' b'ARV3ZTV1187B9A4E52'\n",
      " b'ARQC89A1187B9B04BC' b'AR90B5D1187B9B3F74' b'ARBS0X11187B99D0D9'\n",
      " b'ARJP8UJ1187B9A5092' b'ARMIUSY1241B9C9A64' b'ARK7O2E1187B9A4D2D'\n",
      " b'ARFGPVP12AA0D90321' b'ARAIJG51187B9B97A4' b'AR2X3B01187FB3CD47'\n",
      " b'AR30YY91187FB5912A' b'ARQZ4T11187FB41FCD' b'ARJ977H1187B9A23AC'\n",
      " b'ARSVWNR11EB9C810C6' b'ARZU8861187B98B720' b'AREUMFL120AB9682A8'\n",
      " b'ARHGERE1187B99B00A' b'ARBVXQO1241B9C7847' b'ARRP39Q1187FB53C09'\n",
      " b'ARUKM8F1187FB55005' b'ARXTR2X11C8A42260C' b'ARMQITS1187B99A4D7'\n",
      " b'ARVJNWG1241B9C77E2' b'ARUQDTS12AF7D9AB3D' b'AR56YK91187FB4C15C'\n",
      " b'ARQDTKS125094149EF' b'ARJTGYP1187B9AC9D6' b'AREV2VH1187FB4A78E'\n",
      " b'ARK6R6S1187FB3E891' b'ARTOSCT12AF7DA29D7' b'ARZBLQJ12AF7D9537F'\n",
      " b'ARLIUES1187B9B22BA' b'ARP4J741187B98D05E' b'AROTZXU126FC9C0DE7'\n",
      " b'ARPVLLS12086C14F82' b'ARDBVYB1187B99ACE5' b'AR038BJ1187FB36AF6'\n",
      " b'ARQZ44K1187FB4159E' b'AR5ARC31187B993B46' b'ARCG47N1187B99D8A8'\n",
      " b'AR0RUXM1187B998BA0' b'ARIMFUG11E2835D109' b'AR7F0EA1187B999896'\n",
      " b'ARHNOMB1269FB327E9']\n",
      "Length: 100\n"
     ]
    }
   ],
   "source": [
    "dataset_value = file['metadata']['similar_artists'][:]\n",
    "print(dataset_value)\n",
    "print(\"Length:\", len(dataset_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "53074396-4acc-4117-ae3a-5ec46480a47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(22050, b'9938b27e93cf7a47816625bc53ab7920', 0., 210.75546, 0.153, 0., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0.401, -4.188, 0, 0.471, 203.122, 150.03, 4, 0.57, b'TRBAASG128F92FBB7C')]\n",
      "Length: 1\n"
     ]
    }
   ],
   "source": [
    "dataset_value = file['analysis']['songs'][:]\n",
    "print(dataset_value)\n",
    "print(\"Length:\", len(dataset_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9fd45249-c9fd-422c-9d0c-643ff068e6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(b'', 457243, 0.45537186, 0.3138666, b'AROLMXS1241B9C6915', nan, b'', nan, b'', b'An Cafe', -1, b'', 0, 0, b'Magnya Carta', 395941, nan, b'SOPIHNL12A8C13B28D', b'Pipopapo Telpathy', 4393959)]\n",
      "Length: 1\n"
     ]
    }
   ],
   "source": [
    "dataset_value = file['metadata']['songs'][:]\n",
    "print(dataset_value)\n",
    "print(\"Length:\", len(dataset_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ba32f2f4-3704-432c-b321-be07341c0b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0)]\n",
      "Length: 1\n"
     ]
    }
   ],
   "source": [
    "dataset_value = file['musicbrainz']['songs'][:]\n",
    "print(dataset_value)\n",
    "print(\"Length:\", len(dataset_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "14378f66-c2ec-454b-97ca-def24c088234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.002 0.153 0.016 0.199 0.174 0.018 0.115 0.3   0.018 0.12  0.582 0.036\n",
      " 0.005 0.031 0.101 0.004 0.007 0.352 0.324 0.07  0.085 0.273 0.025 0.273\n",
      " 0.047 0.102 0.383 0.04  0.002 0.242 0.056 0.038 0.082 0.218 0.078 0.005\n",
      " 0.27  0.005 0.109 0.05  0.166 0.038 0.009 0.301 0.133 0.082 0.073 0.026\n",
      " 0.022 0.178 0.098 0.428 0.276 0.171 0.63  0.003 0.106 0.131 0.518 0.026\n",
      " 0.026 0.208 0.059 0.065 0.01  0.085 0.083 0.244 0.165 0.252 0.004 0.18\n",
      " 0.703 0.207 0.425 0.034 0.06  0.003 0.01  0.07  0.019 0.047 0.045 0.02\n",
      " 0.151 0.006 0.078 0.043 0.008 0.153 0.001 0.14  0.02  0.009 0.011 0.036\n",
      " 0.033 0.014 0.155 0.011 0.376 0.251 0.106 0.007 0.071 0.184 0.018 0.238\n",
      " 0.005 0.001 0.069 0.113 0.137 0.001 0.028 0.211 0.03  0.023 0.084 0.033\n",
      " 0.054 0.05  0.171 0.008 0.026 0.006 0.024 0.   ]\n",
      "Length: 128\n"
     ]
    }
   ],
   "source": [
    "dataset_value = file['analysis']['bars_confidence'][:]\n",
    "print(dataset_value)\n",
    "print(\"Length:\", len(dataset_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6a0b4e30-d37a-4b9e-84ff-21650d7ee96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.60646   2.2007    3.80092   5.39466   6.98712   8.58864  10.19087\n",
      "  11.78712  13.38832  14.98951  16.58824  18.18993  19.78535  21.384\n",
      "  22.98502  24.58846  26.1942   27.80012  29.40439  31.00516  32.60641\n",
      "  34.2086   35.81714  37.41738  39.00284  40.5968   42.20063  43.80482\n",
      "  45.40648  47.00735  48.60078  50.20179  51.79572  53.39508  54.99478\n",
      "  56.597    58.20143  59.80227  61.39652  62.99814  64.59227  66.18748\n",
      "  67.78402  69.38897  70.99026  72.59427  74.19724  75.79915  77.39534\n",
      "  79.00029  80.60989  82.21514  83.816    85.41266  87.01549  88.61081\n",
      "  90.19729  91.79204  93.39821  95.00438  96.60963  98.2031   99.7976\n",
      " 101.39496 102.99886 104.59913 106.19286 107.79878 109.40192 111.00497\n",
      " 112.60384 114.19554 115.79468 117.39894 119.00121 120.60796 122.2106\n",
      " 123.81686 125.41215 126.99845 128.61968 130.00943 131.60719 133.21429\n",
      " 134.8268  136.41299 138.00936 139.60249 141.19589 142.78573 144.38555\n",
      " 145.99335 147.60352 149.20855 150.80905 152.40916 154.00758 155.60812\n",
      " 157.20748 158.80704 160.40814 162.00791 163.60283 165.20106 166.80386\n",
      " 168.40341 170.00697 171.6091  173.20521 174.8058  176.40454 177.99715\n",
      " 179.58508 181.17393 182.77674 184.37755 185.97837 187.5839  189.18638\n",
      " 190.80099 192.40246 194.00432 195.60523 197.20854 198.80473 200.40303\n",
      " 201.99938 203.5963 ]\n",
      "Length: 128\n"
     ]
    }
   ],
   "source": [
    "dataset_value = file['analysis']['bars_start'][:]\n",
    "print(dataset_value)\n",
    "print(\"Length:\", len(dataset_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a4b34c3c-77e7-4683-acf5-882da0c9b0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(22050, b'9938b27e93cf7a47816625bc53ab7920', 0., 210.75546, 0.153, 0., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0.401, -4.188, 0, 0.471, 203.122, 150.03, 4, 0.57, b'TRBAASG128F92FBB7C')]\n",
      "Length: 1\n"
     ]
    }
   ],
   "source": [
    "dataset_value = file['analysis']['songs'][:]\n",
    "print(dataset_value)\n",
    "print(\"Length:\", len(dataset_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e2673fa2-d695-4339-8c3b-916db9d84fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(b'', 457243, 0.45537186, 0.3138666, b'AROLMXS1241B9C6915', nan, b'', nan, b'', b'An Cafe', -1, b'', 0, 0, b'Magnya Carta', 395941, nan, b'SOPIHNL12A8C13B28D', b'Pipopapo Telpathy', 4393959)]\n",
      "Length: 1\n"
     ]
    }
   ],
   "source": [
    "dataset_value = file['metadata']['songs'][:]\n",
    "print(dataset_value)\n",
    "print(\"Length:\", len(dataset_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0faeb4d0-728f-48c8-ac95-2162abba119c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0000000e+00 1.5329000e-01 3.8032000e-01 5.7778000e-01 9.8408000e-01\n",
      " 1.3727900e+00 1.6226800e+00 1.7735100e+00 2.1789600e+00 2.5512000e+00\n",
      " 2.6499300e+00 2.7487100e+00 3.1318800e+00 3.5498000e+00 3.7532000e+00\n",
      " 4.3390900e+00 4.5597300e+00 4.9949700e+00 5.3550600e+00 6.1331500e+00\n",
      " 6.2956900e+00 6.5451700e+00 6.9266700e+00 7.3518800e+00 7.7409500e+00\n",
      " 8.1355100e+00 8.5398600e+00 8.9429900e+00 9.2328800e+00 9.3430800e+00\n",
      " 9.7432200e+00 1.0149930e+01 1.0567660e+01 1.0939410e+01 1.1352150e+01\n",
      " 1.1571750e+01 1.1676050e+01 1.1873970e+01 1.1973740e+01 1.2267350e+01\n",
      " 1.2366120e+01 1.2657780e+01 1.3314510e+01 1.3841900e+01 1.3964170e+01\n",
      " 1.4358870e+01 1.4521180e+01 1.4764900e+01 1.5159730e+01 1.5426800e+01\n",
      " 1.5921090e+01 1.6337870e+01 1.6540410e+01 1.6732740e+01 1.7127890e+01\n",
      " 1.7341320e+01 1.7539680e+01 1.7928300e+01 1.8341000e+01 1.8451160e+01\n",
      " 1.8636830e+01 1.8950520e+01 1.9147710e+01 1.9751790e+01 1.9937410e+01\n",
      " 2.0343170e+01 2.0552380e+01 2.0744040e+01 2.1121500e+01 2.1342220e+01\n",
      " 2.1538190e+01 2.1798870e+01 2.2137100e+01 2.2305620e+01 2.2613200e+01\n",
      " 2.2729430e+01 2.2933330e+01 2.3136240e+01 2.3550290e+01 2.3745400e+01\n",
      " 2.3943080e+01 2.4348930e+01 2.4546350e+01 2.4743540e+01 2.5150750e+01\n",
      " 2.5353110e+01 2.5544900e+01 2.5939950e+01 2.6276730e+01 2.6369160e+01\n",
      " 2.6639950e+01 2.6752340e+01 2.6937870e+01 2.7338460e+01 2.7530610e+01\n",
      " 2.7740630e+01 2.7936640e+01 2.8138050e+01 2.8540230e+01 2.8947440e+01\n",
      " 2.9951790e+01 3.0150880e+01 3.0527620e+01 3.0758550e+01 3.1126710e+01\n",
      " 3.1344440e+01 3.1524940e+01 3.1750290e+01 3.1923220e+01 3.2156330e+01\n",
      " 3.2626620e+01 3.2777640e+01 3.2885670e+01 3.3051290e+01 3.3156050e+01\n",
      " 3.3353920e+01 3.3756960e+01 3.4196640e+01 3.4305260e+01 3.4553740e+01\n",
      " 3.4959640e+01 3.5362770e+01 3.5459370e+01 3.6338590e+01 3.6411470e+01\n",
      " 3.6568890e+01 3.6775010e+01 3.6952290e+01 3.7563360e+01 3.7772930e+01\n",
      " 3.7944810e+01 3.8164040e+01 3.8558910e+01 3.9001130e+01 3.9140540e+01\n",
      " 3.9593060e+01 3.9744580e+01 3.9950340e+01 4.0098870e+01 4.0457550e+01\n",
      " 4.0561950e+01 4.0759680e+01 4.0958320e+01 4.1351970e+01 4.1734880e+01\n",
      " 4.2361950e+01 4.2910110e+01 4.3145030e+01 4.3353060e+01 4.3650610e+01\n",
      " 4.3743580e+01 4.3952560e+01 4.4155370e+01 4.4538590e+01 4.4914920e+01\n",
      " 4.5015100e+01 4.5554650e+01 4.5955060e+01 4.6171160e+01 4.6350390e+01\n",
      " 4.6565030e+01 4.6750520e+01 4.6965260e+01 4.7151200e+01 4.7545800e+01\n",
      " 4.7755280e+01 4.7946080e+01 4.8155920e+01 4.8544260e+01 4.8943760e+01\n",
      " 4.9130160e+01 4.9322310e+01 4.9560090e+01 5.0158320e+01 5.0512200e+01\n",
      " 5.0947390e+01 5.1330610e+01 5.1719180e+01 5.2166170e+01 5.2921360e+01\n",
      " 5.3344850e+01 5.3495690e+01 5.3931470e+01 5.4135150e+01 5.4349390e+01\n",
      " 5.4749570e+01 5.5143990e+01 5.5561720e+01 5.5730700e+01 5.5917370e+01\n",
      " 5.6152740e+01 5.6339590e+01 5.6735010e+01 5.7019950e+01 5.7343630e+01\n",
      " 5.7763990e+01 5.8151380e+01 5.8343170e+01 5.8552020e+01 5.8946530e+01\n",
      " 5.9328530e+01 5.9794200e+01 5.9950880e+01 6.0322450e+01 6.0937780e+01\n",
      " 6.1152700e+01 6.1361500e+01 6.1540410e+01 6.1658050e+01 6.1941860e+01\n",
      " 6.2146490e+01 6.2347530e+01 6.2639140e+01 6.2749250e+01 6.2946670e+01\n",
      " 6.3155460e+01 6.3422950e+01 6.4235060e+01 6.4536780e+01 6.4746080e+01\n",
      " 6.5141270e+01 6.5342990e+01 6.5536420e+01 6.5935920e+01 6.6139050e+01\n",
      " 6.6342180e+01 6.6614830e+01 6.6946170e+01 6.7137730e+01 6.7526170e+01\n",
      " 6.7746980e+01 6.7932650e+01 6.8205850e+01 6.8339180e+01 6.8548440e+01\n",
      " 6.8739820e+01 6.9151700e+01 6.9360730e+01 6.9552290e+01 6.9661720e+01\n",
      " 6.9831110e+01 7.0150520e+01 7.0341500e+01 7.0898550e+01 7.1549210e+01\n",
      " 7.1758640e+01 7.1949750e+01 7.2327890e+01 7.2560450e+01 7.2751290e+01\n",
      " 7.3040910e+01 7.3138410e+01 7.3354510e+01 7.3551840e+01 7.3952650e+01\n",
      " 7.4148930e+01 7.4352830e+01 7.4759270e+01 7.4950700e+01 7.5148120e+01\n",
      " 7.5549430e+01 7.5757510e+01 7.5967070e+01 7.6355740e+01 7.6559230e+01\n",
      " 7.6732880e+01 7.7133740e+01 7.7360000e+01 7.7866670e+01 7.7953740e+01\n",
      " 7.8544350e+01 7.8722900e+01 7.9347030e+01 7.9727800e+01 8.0146390e+01\n",
      " 8.0965990e+01 8.1133290e+01 8.1365580e+01 8.1582860e+01 8.1754830e+01\n",
      " 8.1969070e+01 8.2212930e+01 8.2370160e+01 8.2573610e+01 8.2757410e+01\n",
      " 8.2956420e+01 8.3158190e+01 8.3356730e+01 8.3525220e+01 8.4355150e+01\n",
      " 8.4568390e+01 8.4956150e+01 8.5327300e+01 8.5767480e+01 8.6156730e+01\n",
      " 8.6559050e+01 8.7756730e+01 8.7958000e+01 8.8163220e+01 8.8566260e+01\n",
      " 8.8735370e+01 8.8963990e+01 8.9160180e+01 8.9358410e+01 8.9713740e+01\n",
      " 9.0339680e+01 9.0903720e+01 9.1134010e+01 9.1293060e+01 9.1750660e+01\n",
      " 9.1964540e+01 9.2180140e+01 9.2366260e+01 9.2936600e+01 9.3544220e+01\n",
      " 9.4118910e+01 9.4356870e+01 9.4597010e+01 9.4920140e+01 9.5152430e+01\n",
      " 9.5407890e+01 9.5773790e+01 9.6139230e+01 9.6563450e+01 9.6766800e+01\n",
      " 9.7156240e+01 9.7358590e+01 9.7538550e+01 9.7747660e+01 9.7956420e+01\n",
      " 9.8147350e+01 9.8343540e+01 9.8721180e+01 9.8947440e+01 9.9128660e+01\n",
      " 9.9375010e+01 9.9744130e+01 1.0011991e+02 1.0033546e+02 1.0052227e+02\n",
      " 1.0073782e+02 1.0110753e+02 1.0134644e+02 1.0173642e+02 1.0190948e+02\n",
      " 1.0214068e+02 1.0255170e+02 1.0294299e+02 1.0337814e+02 1.0414993e+02\n",
      " 1.0457379e+02 1.0474168e+02 1.0513116e+02 1.0531683e+02 1.0553211e+02\n",
      " 1.0571170e+02 1.0593800e+02 1.0614785e+02 1.0634413e+02 1.0674499e+02\n",
      " 1.0720912e+02 1.0755098e+02 1.0774322e+02 1.0854989e+02 1.0893973e+02\n",
      " 1.0933333e+02 1.0980494e+02 1.1014086e+02 1.1054190e+02 1.1079710e+02\n",
      " 1.1093605e+02 1.1152259e+02 1.1175456e+02 1.1194104e+02 1.1214889e+02\n",
      " 1.1230603e+02 1.1255574e+02 1.1274757e+02 1.1314190e+02 1.1354957e+02\n",
      " 1.1373946e+02 1.1394331e+02 1.1414091e+02 1.1434390e+02 1.1458757e+02\n",
      " 1.1504608e+02 1.1542757e+02 1.1634426e+02 1.1675270e+02 1.1714145e+02\n",
      " 1.1754703e+02 1.1794939e+02 1.1834739e+02 1.1876122e+02 1.1896104e+02\n",
      " 1.1916195e+02 1.1954848e+02 1.1975338e+02 1.1996376e+02 1.2038177e+02\n",
      " 1.2066617e+02 1.2075941e+02 1.2096744e+02 1.2145537e+02 1.2177497e+02\n",
      " 1.2237197e+02 1.2277864e+02 1.2308018e+02 1.2317420e+02 1.2356712e+02\n",
      " 1.2396376e+02 1.2426327e+02 1.2436558e+02 1.2457941e+02 1.2467664e+02\n",
      " 1.2506014e+02 1.2520463e+02 1.2596036e+02 1.2610467e+02 1.2636630e+02\n",
      " 1.2656834e+02 1.2666204e+02 1.2716803e+02 1.2745800e+02 1.2755020e+02\n",
      " 1.2785769e+02 1.2803755e+02 1.2853710e+02 1.2900132e+02 1.2914689e+02\n",
      " 1.2942494e+02 1.2984912e+02 1.2996517e+02 1.3035438e+02 1.3061492e+02\n",
      " 1.3110313e+02 1.3153202e+02 1.3173551e+02 1.3193329e+02 1.3235719e+02\n",
      " 1.3276304e+02 1.3315184e+02 1.3358154e+02 1.3384875e+02 1.3417351e+02\n",
      " 1.3435891e+02 1.3460875e+02 1.3517161e+02 1.3553773e+02 1.3576399e+02\n",
      " 1.3595592e+02 1.3619256e+02 1.3675696e+02 1.3702948e+02 1.3793519e+02\n",
      " 1.3813220e+02 1.3833596e+02 1.3874177e+02 1.3915447e+02 1.3998435e+02\n",
      " 1.4025152e+02 1.4035020e+02 1.4055882e+02 1.4077392e+02 1.4096540e+02\n",
      " 1.4153506e+02 1.4164989e+02 1.4192807e+02 1.4210367e+02 1.4234308e+02\n",
      " 1.4253633e+02 1.4293905e+02 1.4314685e+02 1.4333850e+02 1.4374063e+02\n",
      " 1.4412939e+02 1.4471488e+02 1.4530263e+02 1.4553383e+02 1.4574912e+02\n",
      " 1.4605651e+02 1.4635832e+02 1.4660068e+02 1.4693932e+02 1.4732399e+02\n",
      " 1.4742050e+02 1.4775179e+02 1.4795605e+02 1.4836100e+02 1.4856417e+02\n",
      " 1.4876327e+02 1.4895887e+02 1.4915528e+02 1.4936467e+02 1.4955592e+02\n",
      " 1.4992807e+02 1.5015483e+02 1.5035238e+02 1.5054921e+02 1.5096159e+02\n",
      " 1.5135678e+02 1.5154816e+02 1.5174685e+02 1.5192535e+02 1.5227388e+02\n",
      " 1.5255234e+02 1.5293102e+02 1.5336472e+02 1.5373628e+02 1.5414834e+02\n",
      " 1.5455488e+02 1.5494390e+02 1.5541442e+02 1.5576240e+02 1.5636045e+02\n",
      " 1.5653438e+02 1.5673791e+02 1.5713220e+02 1.5755592e+02 1.5795669e+02\n",
      " 1.5814794e+02 1.5834136e+02 1.5858921e+02 1.5875628e+02 1.5894381e+02\n",
      " 1.5910612e+02 1.5947764e+02 1.5975592e+02 1.6015034e+02 1.6055696e+02\n",
      " 1.6099882e+02 1.6135247e+02 1.6174118e+02 1.6181669e+02 1.6216562e+02\n",
      " 1.6272884e+02 1.6315175e+02 1.6333909e+02 1.6355964e+02 1.6376159e+02\n",
      " 1.6393583e+02 1.6434830e+02 1.6455197e+02 1.6496898e+02 1.6513147e+02\n",
      " 1.6555002e+02 1.6595025e+02 1.6613574e+02 1.6634417e+02 1.6655370e+02\n",
      " 1.6693814e+02 1.6734907e+02 1.6774363e+02 1.6809224e+02 1.6874789e+02\n",
      " 1.6914893e+02 1.6933429e+02 1.6978150e+02 1.6992685e+02 1.7014127e+02\n",
      " 1.7041977e+02 1.7098943e+02 1.7115129e+02 1.7133116e+02 1.7163878e+02\n",
      " 1.7195161e+02 1.7224853e+02 1.7274204e+02 1.7294449e+02 1.7335746e+02\n",
      " 1.7454735e+02 1.7555574e+02 1.7576014e+02 1.7595193e+02 1.7634617e+02\n",
      " 1.7654426e+02 1.7674884e+02 1.7689161e+02 1.7713977e+02 1.7735120e+02\n",
      " 1.7752508e+02 1.7794322e+02 1.7841918e+02 1.7913887e+02 1.7971937e+02\n",
      " 1.8072399e+02 1.8113642e+02 1.8153020e+02 1.8180957e+02 1.8213410e+02\n",
      " 1.8233179e+02 1.8263388e+02 1.8273247e+02 1.8316776e+02 1.8353937e+02\n",
      " 1.8393447e+02 1.8432884e+02 1.8453782e+02 1.8472925e+02 1.8504816e+02\n",
      " 1.8533302e+02 1.8553624e+02 1.8674943e+02 1.8714454e+02 1.8753891e+02\n",
      " 1.8774186e+02 1.8798594e+02 1.8823955e+02 1.8852503e+02 1.8874050e+02\n",
      " 1.8916404e+02 1.8933964e+02 1.8955315e+02 1.8973315e+02 1.8994748e+02\n",
      " 1.9015710e+02 1.9035460e+02 1.9074345e+02 1.9094617e+02 1.9114948e+02\n",
      " 1.9145138e+02 1.9176499e+02 1.9196825e+02 1.9221184e+02 1.9254866e+02\n",
      " 1.9277478e+02 1.9302463e+02 1.9316376e+02 1.9336172e+02 1.9355887e+02\n",
      " 1.9397070e+02 1.9415651e+02 1.9435927e+02 1.9463751e+02 1.9474218e+02\n",
      " 1.9494576e+02 1.9516141e+02 1.9546308e+02 1.9556127e+02 1.9576454e+02\n",
      " 1.9598503e+02 1.9633351e+02 1.9657120e+02 1.9676299e+02 1.9716340e+02\n",
      " 1.9734367e+02 1.9757592e+02 1.9767433e+02 1.9787116e+02 1.9797565e+02\n",
      " 1.9816757e+02 1.9836503e+02 1.9866608e+02 1.9917134e+02 1.9956698e+02\n",
      " 1.9977175e+02 1.9995560e+02 2.0032159e+02 2.0056454e+02 2.0074485e+02\n",
      " 2.0105800e+02 2.0136077e+02 2.0153497e+02 2.0196458e+02 2.0216621e+02\n",
      " 2.0235338e+02 2.0274177e+02 2.0296807e+02 2.0340295e+02 2.0385678e+02\n",
      " 2.0425215e+02 2.0455905e+02 2.0496544e+02 2.0524698e+02 2.0555197e+02\n",
      " 2.0669528e+02]\n",
      "Length: 676\n"
     ]
    }
   ],
   "source": [
    "dataset_value = file['analysis']['segments_start'][:]\n",
    "print(dataset_value)\n",
    "print(\"Length:\", len(dataset_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c23825d7-4cce-458e-82bc-b4dc6995cf06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 15:36:53 INFO SparkContext: SparkContext is stopping with exitCode 0.\n",
      "24/03/14 15:36:53 INFO SparkUI: Stopped Spark web UI at http://master-node:4040\n",
      "24/03/14 15:36:53 INFO YarnClientSchedulerBackend: Interrupting monitor thread\n",
      "24/03/14 15:36:53 INFO YarnClientSchedulerBackend: Shutting down all executors\n",
      "24/03/14 15:36:53 INFO YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down\n",
      "24/03/14 15:36:53 INFO YarnClientSchedulerBackend: YARN client scheduler backend Stopped\n",
      "24/03/14 15:36:54 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\n",
      "24/03/14 15:36:54 INFO MemoryStore: MemoryStore cleared\n",
      "24/03/14 15:36:54 INFO BlockManager: BlockManager stopped\n",
      "24/03/14 15:36:54 INFO BlockManagerMaster: BlockManagerMaster stopped\n",
      "24/03/14 15:36:54 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\n",
      "24/03/14 15:36:54 INFO SparkContext: Successfully stopped SparkContext\n"
     ]
    }
   ],
   "source": [
    "# release the cores\n",
    "spark_context.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783597b9-d69e-490f-a694-ceae73ba0403",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
